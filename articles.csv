link,title,text
https://towardsdatascience.com/the-4-hats-of-a-full-stack-data-scientist-5b916bd2f079,The 4 Hats of a Full-Stack Data Scientist,"This is the first article in a larger series on “Full Stack Data Science” (FSDS). Although there are distinct roles for different aspects of a machine learning (ML) project, there is often a need for someone who can manage and implement projects end-to-end. This is what we can call a full-stack data scientist. In this article, I…"
https://www.kdnuggets.com/5-free-courses-to-master-math-for-data-science,5 Free Courses to Master Math for Data Science,"Image by storyset on Freepik

When you’re learning data science, building a good foundation in math will make your learning journey easier and much more effective. Even if you’ve already landed your first data role, learning math fundamentals for data science will only take your skills further.

From exploratory data analysis to building machine learning models, having a good foundation in math topics like linear algebra and statistics will give you a better understanding of why you do what you do. So even if you are a beginner, this list of courses will help you learn:

Basic math skills

Calculus

Linear Algebra

Probability and Statistics

Optimization

Sounds interesting, yes? Let’s get started!

1. Data Science Math Skills – Duke University

Data science courses require you to be comfortable with math as a prerequisite. To be specific, most courses assume that you're comfortable with high school algebra and calculus. But no worries if you are not there yet.

The Data Science Math Skills course, offered by Duke University on Coursera will help you get up and running with math fundamentals in as little time as possible. The topics covered in this course include:

Problem solving

Functions and graphs

Intro to calculus

Intro to probability

It’s recommended that you go through this course before you start the other courses that explore specific math topics in greater depth.

Link: Data Science Math Skills – Duke University on Coursera

2. Calculus – 3Blue1Brown

When we talk about math for data science, calculus is definitely something you should be comfortable with. But most learners find high school calculus intimidating (I’ve been there, too!). This, however, is partly because of how we learn—mostly focusing on concepts, a small number of illustrative examples, and a ton of practice exercises.

But you’ll understand and learn calculus much better if there are helpful visualizations—to help go from intuition to equation—focusing on the why.

The Calculus course by Grant Sanderson of 3Blue1Brown is exactly what all of us need! Through a series of lessons with super helpful visualizations—going from geometry to formula wherever possible—this course will help you learn the following and more:

Limits and derivatives

Power rule, chain rule, product rule

Implicit differentiation

Higher order derivatives

Taylor series

Integration

Link: Calculus - 3Blue1Brown

3. Linear Algebra – 3Blue1Brown

As a data scientist, the datasets that you work are essentially matrices of dimensions num_samples x num_features. You can, therefore, think of each data point as a vector in the feature space. So understanding how matrices work, common operations on matrices, matrix decomposition techniques are all important.

If you loved the calculus course from 3Blue1Brown, you’ll probably enjoy the linear algebra course from Grant Sanderson just as much if not more. The Linear Algebra course from 3Blue1Brown will help you learn help you learn the following:

Fundamentals of vectors and vector spaces

Linear combinations, span, and basis

Linear transformation and matrices

Matrix multiplication

3D linear transformation

Determinant

Inverses, column space, and null space

Dot and cross products

Eigenvalues and eigenvectors

Abstract vector spaces

Link: Linear Algebra - 3Blue1Brown

4. Probability and Statistics – Khan Academy

Statistics and probability are great skills to add to your data science toolbox. But they are by no means easy to master. However, it’s relatively easier to get your fundamentals down and build on them.

The Statistics and Probability course from Khan Academy will help you learn the probability and statistics you need to start working with data more effectively. Here is an overview of the topics covered:

Analyzing categorical and quantitative data

Modeling data distributions

Probability

Counting, permutations, and combinations

Random variables

Sampling distribution

Confidence interval

Hypothesis testing

Chi-square test

ANOVA

If you’re interested in diving deep into statistics, also check out 5 Free Courses to Master Statistics for Data Science.

Link: Statistics and Probability - Khan Academy

5. Optimization for Machine Learning – ML Mastery

If you’ve ever trained a machine learning model, you know that the algorithm learns the optimal values of the parameters of the model. Under the hood, it runs an optimization algorithm to find the optimal value.

The Optimization for Machine Learning Crash Course from Machine Learning Mastery is a comprehensive resource to learn optimization for machine learning.

This course takes a code-first approach using Python. So after understanding the importance of optimization, you’ll write Python code to see popular optimization algorithms in action. Here’s an overview of the topics covered:

The need for optimization

Grid search

Optimization algorithms in SciPy

BFGS algorithm

Hill climbing algorithm

Simulated annealing

Gradient descent

Link: Optimization for Machine Learning Crash Course - MachineLearningMastery.com

Wrapping Up

I hope you found these resources helpful. Because most of these courses are tailored towards beginners, you should be able to pick up all the essential math without feeling overwhelmed.

If you’re looking for courses to learn Python for data science, read 5 Free Courses to Master Python for Data Science.

Happy learning!"
https://consumergoods.com/nestle-uses-ai-and-data-science-battle-environmental-challenges-coffee-production,Nestlé Uses AI and Data Science to Battle Environmental Challenges in Coffee Production,"Nestlé is brewing up data science- and artificial intelligence-powered innovations to breed climate-resilient plants in an environmentally challenged landscape.

With climate change reducing the amount of land that can grow hardy and weather-resilient coffee plants, Nestlé plant scientists have looked to data science to better identify a combination of factors that will yield healthy crops.

Using AI, the company scans a publicly available digital database of coffee traits including cherry size, flavor and aroma characteristics, and yield to create more sustainable coffee cultivation and plant more disease- and drought-resistant beans.

Also read:Keurig Dr Pepper Tests Plastic-Free Pods, Powers Innovation With Consumer Learnings

""In simple terms, our new reference is like a high-quality map of a big city. It will help us identify key genetic markers in the Arabica genome that are responsible for specific traits in adult plants,” said Jeroen Dijkman, head of Nestlé's Institute of Agricultural Sciences, in a statement. “This will help our plant scientists and other experts to better identify, select, and breed new and improved arabica coffee varieties.""

Genome Sequencing of Arabica Coffee Strains

The company has focused on Arabica because it makes up 70% of the world’s coffee production among the existing 120 species. This has posed a challenge, however, as it is more susceptible to disease and has a lower heat tolerance, making it harder to plant successfully amid water shortages and a reduction of arable land.

Also read:Starbucks Reinvention: New Leadership and Green Store Expansion

The company sought a solution to this challenge alongside the French National Institute for Sustainable Development and academic partners, members of a global consortium.

Co-author of a research paper on this effort, Patrick Descombes, who is the senior expert in genomics at Nestlé Research, said the company used state-of-the-art genomics approaches to create an advanced, complete, and continuous arabica reference.

The initiative is part of Nestlé's regenerative agriculture plan, Nescafé Plan 2030.

The coffee segment has been steadily growing. According to research from Circana, coffee outpaced both tea (+4%) and carbonated soft drinks (+3%) in year-over-year servings growth, making it one of the fastest-growing beverage categories globally.

Nestlé reports that coffee is part of five growth platforms that make up 50% of its revenue. Within powdered and liquid beverages, coffee sales grew at a high single-digit rate, per the last call with investors.

The company’s coffee brands include Nescafe, Nespresso, Dolce Gusto, Starbucks Coffee at Home, and Blue Bottle Coffee."
https://fortune.com/education/articles/free-data-analytics-courses/,10 free data analytics courses you can take online,"“It’s not hyperbole to say that data analytics has really taken over the world,” says Brian Caffo, professor of biostatistics at Johns Hopkins University’s Bloomberg School of Public Health and director of academic programs for the university’s Data Science and AI Institute. “Every domain has become increasingly quantitative to inform decision making.”

And this space isn’t slowing down anytime soon: The U.S. Bureau of Labor Statistics projects that employment for data scientists will grow 35% from 2022 to 2032, with 17,700 new job openings projected each year on average during that decade.

Interested in becoming a data analyst? Below, we’ve compiled ten free data analytics courses to help give you a firmer grasp of this rapidly growing field.

A/B Testing

About: This course covers the design and analysis of A/B tests, which are online experiments that compare two versions of content to see which one appeals to viewers more. A/B tests are used throughout the tech industry by companies like Amazon and Google. This course is offered through Udacity.

Course length: Six self-paced modules

Who this course is for: Beginners

What you’ll learn: In this course you’ll learn about A/B testing, experiment ethics, how to choose metrics, design an experiment, and analyze results.

Prerequisites: None

Data Analytics Short Course

About: In this quick, five-tutorial course you’ll get a broad overview of data analytics. You’ll learn about the different types of roles in data analytics, a summary of the tools and skills you’ll need to develop, and a hands-on introduction to the field. This course is offered by CareerFoundry.

Course length: 75 minutes, divided into five 15-minute lessons

Who this course is for: Beginners

What you’ll learn: In this course you’ll get an introduction to data analytics. You’ll also analyze a real dataset to solve a business problem through data cleaning, visualizations, and garnering final insights.

Prerequisites: None

Data Science: R Basics

About: This program gives you a foundational knowledge of programming language R. Offered by HarvardX through the EdX platform, this course is offered for free; the paid version includes a credential. It’s the first of ten courses HarvardX offers as part of its Professional Certificate in Data Science.

Course length: Eight weeks, 1–2 hours per week

Who this course is for: Beginners

What you’ll learn: In this course you’ll learn basic R syntax and foundational R programming concepts, including data types, vectors arithmetic, and indexing. You’ll also perform operations that include sorting, data wrangling using dplyr, and making plots.

“It’s the basics of how to wrangle, analyze, and visualize data in R,” says Dustin Tingley, Harvard University’s deputy vice provost for advances in learning and a professor of government in the school’s government department. “That gets you writing a little bit of code, but you’re not doing anything that heavy.”

Prerequisites: HarvardX recommends having an up-to-date browser to enable programming directly in a browser-based interface

Fundamentals of Qualitative Research Methods

About: This course will teach you the fundamentals of qualitative research methods. Qualitative research provides deeper insights into real-world problems that might not always be immediately evident. This course is offered through Yale University on YouTube.

Course length: 90 minutes spread out over six modules

Who this course is for: Beginners

What you’ll learn: In this course you’ll learn how qualitative research is a way to systematically collect, organize, and interpret information that is difficult to measure quantitatively. This includes developing qualitative research questions, gathering data through interviews and focus groups, and analyzing this data.

“Qualitative research is the systematic, rigorous application of narratives and tools to better understand a complex phenomenon,” says Leslie Curry, a professor of public health and management at the Yale School of Public Health and a professor of management at the Yale School of Management. She adds that this approach can help understand flaws in large data sets. “It can be used as an adjunct to a lot of the really important work that’s happening in large data analysis.”

Prerequisites: None

Getting and Cleaning Data

About: This course covers the basic ways that data can be obtained and how that data can be cleaned to make it “tidy.” It will also teach you the components of a complete data set, such as raw data, codebooks, processing instructions, and processed data. This course is offered by Johns Hopkins University through Coursera, and is part of a 10-course Data Science Specialization series.

Course length: Four weeks, totaling approximately 19 hours

Who this course is for: Beginners

What you’ll learn: Through this course you’ll learn about common data storage systems, how to use R for text and date manipulation, how to use data cleaning basics to make data “tidy,” and how to obtain useable data from the web, application programming interfaces (APIs), and databases.

“It’s the starting point” when it comes to data analysis, Caffo says. “Without a good data set that is cleaned and appropriate for use, you have nothing. You can talk all you want about doing models or whatnot—underlying that has to be the data to support it.”

Prerequisites: None

Introduction to Data Science with Python

About: This course teaches you concepts and techniques to give you a foundational understanding of data science and machine learning. Offered by HarvardX through the EdX platform, this course can be taken for free. The paid version offers a credential.

Course length: Eight weeks, 3–4 hours a week

Who this course is for: Intermediate

What you’ll learn: This course will give you hands-on experience using Python to solve real data science challenges. You’ll use Python programming and coding for modeling, statistics, and storytelling.

“It gets you up and running with the main workhorse tools of data analytics,” says Tingley. “It helps to set people up to take more advanced courses in things like machine learning and artificial intelligence.”

Prerequisites: None, but Tingley says having a basic background in high school-level algebra and basic probability is helpful. Some programming experience—particularly in Python—is recommended

Introduction to Databases and SQL Querying

About: In this course you’ll learn how to query a database, create tables and databases, and be proficient in basic SQL querying. This free course is offered through Udemy.

Course length: Two hours and 17 minutes

Who this course is for: Beginners

What you’ll learn: This course will acquaint you with the basic concepts of databases and queries. This course will walk you through setting up your environment, creating your first table, and writing your first query. By the course’s conclusion, you should be able to write simple queries related to dates, string manipulation, and aggregation.

Prerequisites: None

Introduction to Data Analytics

About: This course offers an introduction to data analysis, the role of a data analyst, and the various tools used for data analytics. This course is offered by IBM through Coursera.

Course length: Five modules totaling roughly 10 hours

Who this course is for: Beginners

What you’ll learn: This course will teach you about data analytics and the different types of data structures, file formats, and sources of data. You’ll learn about the data analysis process, including collecting, wrangling, mining, and visualizing data. And you’ll learn about the different roles within the field of data analysis.

Prerequisites: None

Learn to Code for Data Analysis

About: This course will teach you how to write your own computer programs, access open data, clean and analyze data, and produce visualizations. You’ll code in Python, write analyses and do coding exercises using the Jupyter Notebooks platform. This course is offered through the United Kingdom’s Open University on its OpenLearn platform.

Course length: Eight weeks, totaling 24 hours

Who this course is for: Intermediate

What you’ll learn: In this course you’ll learn basic programming and data analysis concepts, recognize open data sources, use a programming environment to develop programs, and write simple programs to analyze large datasets and produce results.

Prerequisites: A background in coding—especially Python—is helpful

The Data Scientist’s Toolbox

About: This course will give you an introduction to the main tools and concepts of data science. You will learn the ideas behind turning data into actionable knowledge and get an introduction to tools like version control, markdown, git, GitHub, R, and RStudio. This course is offered by Johns Hopkins University through Coursera, and is part of a 10-course Data Science Specialization series.

Course length: 18 hours

Who this course is for: Beginners

What you’ll learn: This course will teach you how to set up R, RStudio, GitHub, and other tools. You will learn essential study design concepts, as well as how to understand the data, problems, and tools that data analysts use.

“That course is a very accessible introduction for anyone who wants to get started in this,” Caffo says. “It’s an overview that covers the full pipeline, from things like collecting and arranging data to asking good questions, all the way to creating a data deliverable.”

Prerequisites: None

The takeaway

From businesses estimating demand for their products to political campaigns figuring out where they should run advertisements to health care professionals running clinical trials to judge a drug’s efficacy, data analytics has a wide variety of applications. Getting a better understanding of the field on your own time can be done easily and freely. And the field is only growing.

“Just about every field is having a revolution in data analytics,” Caffo says. “In fields like medicine that have always been data driven, it’s become more data-driven.”"
https://towardsdatascience.com/simulated-data-real-learnings-simulating-systems-79374a9379fd,"Simulated Data, Real Learnings : Simulating Systems","INTRODUCTION

Simulation is a powerful tool in the data science tool box. In this article, we’ll talk about how simulating systems can help us formulate better strategies and make better decisions."
https://towardsdatascience.com/how-do-we-know-if-ai-is-smoke-and-mirrors-16ed5b6877aa,How Do We Know if AI Is Smoke and Mirrors?,"I am not nearly the first person to sit down and really think about what the advent of AI means for our world, but it’s a question that I still find being asked and talked about. However, I think most of these conversations seem to miss key factors.

Before I begin, let me give you three anecdotes that illustrate different aspects of this issue that have shaped my thinking lately.

I had a conversation with my financial advisor recently. He remarked that the executives at his institution were disseminating the advice that AI is a substantive change in the economic scene, and that investing strategies should regard it as revolutionary, not just a hype cycle or a flash in the pan. He wanted to know what I thought, as a practitioner in the machine learning industry. I told him, as I’ve said before to friends and readers, that there’s a lot of overblown hype, and we’re still waiting to see what’s real under all of that. The hype cycle is still happening.

Also this week, I listened to the episode of Tech Won’t Save Us about tech journalism and Kara Swisher. Guest Edward Ongweso Jr. remarked that he thought Swisher has a pattern of being credulous about new technologies in the moment and changing tune after those new technologies prove not to be as impressive or revolutionary as they promised (see, self-driving cars and cryptocurrency). He thought that this phenomenon was happening with her again, this time with AI.

My partner and I both work in tech, and regularly discuss tech news. He remarked once about a phenomenon where you think that a particular pundit or tech thinker has very wise insights when the topic they are discussing is one you don’t know a lot about, but when they start talking about something that’s in your area of expertise, suddenly you realize that they’re very off base. You go back in your mind and wonder, “I know they’re wrong about this. Were they also wrong about those other things?” I’ve been experiencing this from time to time recently on the subject of machine learning.

It’s really hard to know how new technologies are going to settle and what their long term impact will be on our society. Historians will tell you that it’s easy to look back and assume “this is the only way that events could have panned out”, but in reality, in the moment no one knew what was going to happen next, and there were myriad possible turns of events that could have changed the whole outcome, equally or more likely than what finally happened.

TL;DR

AI is not a total scam. Machine learning really does give us opportunities to automate complex tasks and scale effectively. AI is also not going to change everything about our world and our economy. It’s a tool, but it’s not going to replace human labor in our economy in the vast majority of cases. And, AGI is not a realistic prospect.

AI is not a total scam. … AI is also not going to change everything about our world and our economy.

Why do I say this? Let me explain.

First, I want to say that machine learning is pretty great. I think that teaching computers to parse the nuances of patterns that are too complex for people to really grok themselves is fascinating, and that it creates loads of opportunities for computers to solve problems. Machine learning is already influencing our lives in all kinds of ways, and has been doing so for years. When I build a model that can complete a task that would be tedious or nearly impossible for a person, and it is deployed so that a problem for my colleagues is solved, that’s very satisfying. This is a very small scale version of some of the cutting edge things being done in generative AI space, but it’s in the same broad umbrella.

Expectations

Speaking to laypeople and speaking to machine learning practitioners will get you very different pictures of what AI is expected to mean. I’ve written about this before, but it bears some repeating. What do we expect AI to do for us? What do we mean when we use the term “artificial intelligence”?

To me, AI is basically “automating tasks using machine learning models”. That’s it. If the ML model is very complex, it might enable us to automate some complicated tasks, but even little models that do relatively narrow tasks are still part of the mix. I’ve written at length about what a machine learning model really does, but for shorthand: mathematically parse and replicate patterns from data. So that means we’re automating tasks using mathematical representations of patterns. AI is us choosing what to do next based on the patterns of events from recorded history, whether that’s the history of texts people have written, the history of house prices, or anything else.

AI is us choosing what to do next based on the patterns of events from recorded history, whether that’s the history of texts people have written, the history of house prices, or anything else.

However, to many folks, AI means something far more complex, on the level of being vaguely sci-fi. In some cases, they blur the line between AI and AGI, which is poorly defined in our discourse as well. Often I don’t think people themselves know what they mean by these terms, but I get the sense that they expect something far more sophisticated and universal than what reality has to offer.

For example, LLMs understand the syntax and grammar of human language, but have no inherent concept of the tangible meanings. Everything an LLM knows is internally referential — “king” to an LLM is defined only by its relationships to other words, like “queen” or “man”. So if we need a model to help us with linguistic or semantic problems, that’s perfectly fine. Ask it for synonyms, or even to accumulate paragraphs full of words related to a particular theme that sound very realistically human, and it’ll do great.

But there is a stark difference between this and “knowledge”. Throw a rock and you’ll find a social media thread of people ridiculing how ChatGPT doesn’t get facts right, and hallucinates all the time. ChatGPT is not and will never be a “facts producing robot”; it’s a large language model. It does language. Knowledge is even one step beyond facts, where the entity in question has understanding of what the facts mean and more. We are not at any risk of machine learning models getting to this point, what some people would call “AGI”, using the current methodologies and techniques available to us.

Knowledge is even one step beyond facts, where the entity in question has understanding of what the facts mean and more. We are not at any risk of machine learning models getting to this point using the current methodologies and techniques available to us.

If people are looking at ChatGPT and wanting AGI, some form of machine learning model that has understanding of information or reality on par with or superior to people, that’s a completely unrealistic expectation. (Note: Some in this industry space will grandly tout the impending arrival of AGI in PR, but when prodded, will back off their definitions of AGI to something far less sophisticated, in order to avoid being held to account for their own hype.)

As an aside, I am not convinced that what machine learning does and what our models can do belongs on the same spectrum as what human minds do. Arguing that today’s machine learning can lead to AGI assumes that human intelligence is defined by increasing ability to detect and utilize patterns, and while this certainly is one of the things human intelligence can do, I don’t believe that is what defines us.

In the face of my skepticism about AI being revolutionary, my financial advisor mentioned the example of fast food restaurants switching to speech recognition AI at the drive-thru to reduce problems with human operators being unable to understand what the customers are saying from their cars. This might be interesting, but hardly an epiphany. This is a machine learning model as a tool to help people do their jobs a bit better. It allows us to automate small things and reduce human work a bit, as I’ve mentioned. This is not unique to the generative AI world, however! We’ve been automating tasks and reducing human labor with machine learning for over a decade, and adding LLMs to the mix is a difference of degrees, not a seismic shift.

We’ve been automating tasks and reducing human labor with machine learning for over a decade, and adding LLMs to the mix is a difference of degrees, not a seismic shift.

I mean to say that using machine learning can and does definitely provide us incremental improvements in the speed and efficiency by which we can do lots of things, but our expectations should be shaped by real comprehension of what these models are and what they are not.

Practical Limits

You may be thinking that my first argument is based on the current technological capabilities for training models, and the methods being used today, and that’s a fair point. What if we keep pushing training and technologies to produce more and more complex generative AI products? Will we reach some point where something totally new is created, perhaps the much vaunted “AGI”? Isn’t the sky the limit?

The potential for machine learning to support solutions to problems is very different from our ability to realize that potential. With infinite resources (money, electricity, rare earth metals for chips, human-generated content for training, etc), there’s one level of pattern representation that we could get from machine learning. However, with the real world in which we live, all of these resources are quite finite and we’re already coming up against some of their limits.

The potential for machine learning to support solutions to problems is very different from our ability to realize that potential.

We’ve known for years already that quality data to train LLMs on is running low, and attempts to reuse generated data as training data prove very problematic. (h/t to Jathan Sadowski for inventing the term “Habsburg AI,” or “a system that is so heavily trained on the outputs of other generative AIs that it becomes an inbred mutant, likely with exaggerated, grotesque features.”) I think it’s also worth mentioning that we have poor capability to distinguish generated and organic data in many cases, so we may not even know we’re creating a Habsburg AI as it’s happening, the degradation may just creep up on us.

I’m going to skip discussing the money/energy/metals limitations today because I have another piece planned about the natural resource and energy implications of AI, but hop over to the Verge for a good discussion of the electricity alone. I think we all know that energy is not an infinite resource, even renewables, and we are committing the electrical consumption equivalent of small countries to training models already — models that do not approach the touted promises of AI hucksters.

I also think that the regulatory and legal challenges to AI companies have potential legs, as I’ve written before, and this must create limitations on what they can do. No institution should be above the law or without limitations, and wasting all of our earth’s natural resources in service of trying to produce AGI would be abhorrent.

My point is that what we can do theoretically, with infinite bank accounts, mineral mines, and data sources, is not the same as what we can actually do. I don’t believe it’s likely machine learning could achieve AGI even without these constraints, in part due to the way we perform training, but I know we can’t achieve anything like that under real world conditions.

[W]hat we can do theoretically, with infinite bank accounts, mineral mines, and data sources, is not the same as what we can actually do.

Even if we don’t worry about AGI, and just focus our energies on the kind of models we actually have, resource allocation is still a real concern. As I mentioned, what the popular culture calls AI is really just “automating tasks using machine learning models”, which doesn’t sound nearly as glamorous. Importantly, it reveals that this work is not a monolith, as well. AI isn’t one thing, it’s a million little models all over the place being slotted in to workflows and pipelines we use to complete tasks, all of which require resources to build, integrate, and maintain. We’re adding LLMs as potential choices to slot in to those workflows, but it doesn’t make the process different.

As someone with experience doing the work to get business buy-in, resources, and time to build those models, it is not as simple as “can we do it?”. The real question is “is this the right thing to do in the face of competing priorities and limited resources?” Often, building a model and implementing it to automate a task is not the most valuable way to spend company time and money, and projects will be sidelined.

Conclusion

Machine learning and its results are awesome, and they offer great potential to solve problems and improve human lives if used well. This is not new, however, and there’s no free lunch. Increasing the implementation of machine learning across sectors of our society is probably going to continue to happen, just like it has been for the past decade or more. Adding generative AI to the toolbox is just a difference of degree.

AGI is a completely different and also entirely imaginary entity at this point. I haven’t even scratched the surface of whether we would want AGI to exist, even if it could, but I think that’s just an interesting philosophical topic, not an emergent threat. (A topic for another day.) But when someone tells me that they think AI is going to completely change our world, especially in the immediate future, this is why I’m skeptical. Machine learning can help us a great deal, and has been doing so for many years. New techniques, such as those used for developing generative AI, are interesting and useful in some cases, but not nearly as profound a change as we’re being led to believe."
https://towardsdatascience.com/callbacks-and-pipeline-structures-in-langchain-925aa077227e,Callbacks and Pipeline structures in LangChain,"Learn about the structure of LangChain pipelines, callbacks, how to create custom callbacks and integrate them into your pipelines for improved monitoring

Roshan Santhosh

·

Follow

Published in

Towards Data Science

·

11 min read

·

1 day ago

--

Callbacks are an important functionality that helps with monitoring/debugging your pipelines. In this note, we cover the basics of callbacks and how to create custom ones for your use cases. More importantly, through examples, we also develop an understanding of the structure/componentization of LangChain pipelines and how that plays into the design of custom callbacks.

This note assumes basic familiarity with LangChain and how pipelines in LangChain work.

Basic Structure of Callbacks

To learn about the basics of callbacks in LangChain, we start with the official documentation where we can find the definition of the BaseCallbackHandler class.

BaseCallbackManager code

As you can see this is an abstract class that defines quite a few methods to cover various events in your LangChain pipeline. These methods can be grouped together into the following segments :

LLM [start, end, error, new token]

Chain [start, end, error]

Tool [start, end, error]

Agent [action, finish]

If you have worked with LangChain pipelines before, the methods along with their provided descriptions should be mostly self explanatory. For example, the on_llm_start callback is the event that gets triggered when the LangChain pipeline passes input to the LLM. And that on_llm_end is subsequently triggered when the LLM provides its final output.

NOTE : There are events triggers that can be used in addition to whats shown above. These can be found here. These cover triggers relating to Retrievers, Prompts, ChatModel etc.

Understanding how Callbacks work

Callbacks are a very common programming concept that have been widely used for a while now, so the high level concept of how callbacks work is well understood. So in this post, we focus on the specific nuances of how callbacks work in LangChain and how we could use it to satisfy our specific use cases.

Keeping in the mind the base Callback class that we saw in the previous section, we explore Callbacks in LangChain through a series of increasingly complex examples and in the process gain a better understanding of the structure of pipelines in LangChain. This would be a top-down approach to learning where we start with examples first and actual definitions later as I found that to be more useful personally for this specific topic.

Example 1

We start with a simple dummy chain that has 3 components : 2 prompts and a custom function to join them. I refer to this as a dummy example because its very unlikely that you would need two separate prompts to interact with each other, but it makes for an easier example to start with for understanding callbacks and LangChain pipelines.

Implementing this in code would look like :

The above code is pretty textbook stuff. The only possibly complex piece is the retrieve_text and RunnableLambda function thats being used here. The reason this is necessary is because the format of the output from qa_prompt1 is not compatible with the format of the output required by qa_prompt2.

Defining the custom Callback

For our custom callback, we define a new subclass of BaseCallbackHandler called CustomCallback1 which defines the on_chain_start method. The method definition is straightforward as it simply takes the input values passed to it and saves it in 2 specific variables : chain_input and serialized_input

Invoking the custom callback

The above code shows one of the possible ways to pass your custom callback to your pipeline : As a list of callback objects as the value to a corresponding key of ‘callbacks’. This also makes it easy to guess that you can pass multiple callbacks to your LangChain pipeline.

Decoding the Callback/Pipeline Structure

Now comes the interesting part. After we have defined the callbacks and passed it on to our pipeline, we now perform a deep dive into the callback outputs

We first look at the values stored in chain_input

Observations :

Though there are 3 components in our chain, there are 4 values in chain_input. Which corresponds to the on_chain_start method being triggered 4 times instead of 3.

For the first two chain_input values/ on_chain_start triggers, the input is the same as the user provided input.

We next look at the outputs of serialized_input

Observations :

The first component is a RunnableSequence which is a component that wasnt added by the user but was automatically added by LangChain. The rest of the components correspond directly to the user-defined components in the pipeline.

The full contents of serialized_input is extensive! While there is a definite structure to that content, its definitely out of scope for this post and possibly doesnt have much practical implications for an end user.

How do we interpret these results

For the most part, the outputs seen in the chain_input and serialized_input make sense. Whether its the input values or the names/IDs of the components. The only largely unknown part is the RunnableSequence component, so we take a closer look at this.

As I mentioned previously, the full contents of serialized_input is extensive and not easy to digest. So to make things easier, we look at only the high level attributes described in serialized_input and try to intrepret the results through these attributes. For this, we make use of a custom debugging function called getChainBreakdown (code in notebook).

We call getChainBreakdown on all values of serialized_input and observe the output. Specifically for the first RunnableSequence element, we look at the keys of the kwargs dict : first, midde, last, name.

On closer inspection of the kwargs argument and their values, we see that they have the same structure as our previous pipeline components. In fact, the first, middle and last components correspond exactly to the user-defined components of the pipeline.

The above details form the basis of the final conclusion that we make here. That the structure of the pipeline is like shown below :

We do make a bit of a leap here as the above flowchart was confirmed after going through a bunch of examples and observing the format in which these components are created internally by LangChain. So bear with me as we go through these other examples which will solidify the conclusion that we make here.

With the above defined structure, the other pieces of the puzzle fit together quite well. Focusing on the chain_input values, lets map them to the components (with their ordering) defined above.

Observations :

For RunnableSequence, as it acts like a wrapper for the whole pipeline, the input from the user acts as the input for the RunnableSequence component as well.

For the first ChatPromptTemplate (qa_prompt1), as the first ‘true’ component of the pipeline, it receives the direct input from the user

For RunnableLambda (retrieve_text), it receives as input the output from qa_prompt1, which is a Message object

For the last ChatPromptTemplate (qa_prompt2), it receives as input the output from retrieve_text, which is a dict with ‘prompt’ as its single key

The above breakdown shows how the structure of the pipeline described above fits perfectly with the data seen in serialized_input and chain_input

Example 2

For the next example, we extend Example 1 by adding a LLM as the final step.

For the callback, since we have now added a LLM into the mix, we define a new custom callback that additionally defines the on_llm_start method. It has the same functionality as on_chain_start where the input arguments are saved into the callback object variables : chain_input and serialized_input

Proposing the Pipeline structure

At this stage, instead of evaluating the callback variables, we switch things up and propose the potential structure of the pipeline. Given what we had learnt from the first example, the following should be the potential structure of the pipeline

So we would have a RunnableSequence component as a wrapper for the pipeline. And additionally include a new ChatOpenAI object thats nested within the RunnableSequence component.

Validating proposed structure using data

We now look at the values of in the callback object to validate the above proposed structure.

We first look at the values stored in chain_input

And then the serialized_input values :

As well as a deeper inspection of the RunnableSequence components

Observations :

The values of serialized_input validate the activation/trigger sequence that was proposed in the pipeline structure : RunnableSequence -> ChatPromptTemplate(qa_prompt1) -> RunnableLambda(retrieve_text) -> ChatPromptTemplate(qa_prompt2) -> ChatOpenAI

The values of chain_input also map correctly to the proposed structure. The only new addition is the fifth entry, which corresponds to the output from qa_prompt2, which is fed as input to the ChatOpenAI object

The components of the RunnableSequence kwargs also verify the proposed structure as the new ‘last’ element is the ChatOpenAI object

By this stage, you should have an intuitive understanding of how LangChain pipelines are structured and when/how different callback events are triggered.

Though we have only focused on Chain and LLM events so far, these translate well to the other Tool and Agent triggers as well

Example 3

For the next example, we progress to a more complex chain involving a parallel implementation (RunnableParallel)

Chain/Callback Implementation

The chain has a parallel implementation as its first block which computes two values : context and question, which are then passed on to a prompt template to create the final prompt. The parallel functionality is required because we need to pass both context and question to the prompt template at the same time, where the context is retrived from a different source while the question is provided by the user.

For the context value, we use a static function get_data that returns the same piece of text (this is a dummy version of an actual retriever used in RAG applications).

For the callback implementation, we use the same callback as the first example, CustomCallback1

Decoding the Callback/Pipeline Structure

Similar to previous examples, we start by looking at the outputs of chain_input and serialized_input

We also look do a deep dive into the RunnableSequence (index 0) and RunnableParallel (index 1) components

Observations :

Consistent with previous examples, the RunnableSequence acts as a wrapper to the whole pipeline. Its first component is the RunnableParallel component and its last component is the ChatPromptTemplate component

The RunnableParallel in turn encompasses two components : the RunnablePassthrough and the RunnableLambda (get_data).

The inputs to the first 4 components : RunnableSequence, RunnableParallel, RunnablePassthrough and RunnableLambda (get_data) are the same : the provided user input. Only for the final ChatPromptTemplate component do we have a different input, which is a dict with question and context keys.

Based on these observations, we can infer the final structure of the pipeline as such :

Example 4

Same as Example 3, but with an additional processing function for retrieving context

Chain/Callback Implementation

Decoding the Callback/Pipeline Structure

Similar to previous examples, we again look at the usual data points

We observe that there are now 2 RunnableSequence components in our pipeline. So for the next step, we deep dive into both of these RunnableSequence components to see its internal components

Observations :

For the first RunnableSequence components, its components are the same as the previous example. Starts with RunnableParallel and ends with ChatPromptTemplate

For the second RunnableSequence, its first component is the RunnableLambda (get_data) component and the last component is the RunnableLambda (format_docs) component. This is basically the part of the pipeline responsible for generating the ‘context’ value. So its possible for a LangChain pipeline to have multiple RunnableSequence components to it. Especially when you are creating ‘sub-pipelines’

In this case, the creation of the ‘context’ value can be considered a pipeline by itself as it involves 2 different components chained together. So any such sub-pipelines in your primary pipeline will be wrapped up by a RunnableSequence component

3. The values from chain_input also match up well with the pipeline components and their ordering (Not going to breakdown each component’s input here as it should be self-explanatory by now)

So based on the above observations, the following is the identified structure of this pipeline

Conclusion

The objective of this post was to help develop an (intuitive) understanding of how LangChain pipelines are structured and how callback triggers are associated with the pipeline.

By going through increasingly complex chain implementations, we were able to understand the general structure of LangChain pipelines and how a callback can be used for retrieving useful information. Developing an understanding of how LangChain pipelines are structured will also help facilitate the debugging process when errors are encountered.

A very common use case for callbacks is retrieving intermediate steps and through these examples we saw how we can implement custom callbacks that track the input at each stage of the pipeline. Add to this our understanding of the structure of the LangChain pipelines, we can now easily pinpoint the input to each component of the pipeline and retrieve it accordingly.

Resources

Notebook with code/examples : Contains few additional examples not covered in this note.

Unless specified otherwise, all images are created by the author.

In addition to Medium, I share my thoughts, ideas and other updates on Linkedin."
https://towardsdatascience.com/the-definitive-guide-to-structured-data-parsing-with-openai-gpt3-5-0e5ea0e52637,The Definitive Guide to Structured Data Parsing with OpenAI GPT3.5,"Parsing structured data from Large Language Models (LLMs) can be frustrating for anything beyond toy problems. Yet, reliably parsing LLM outputs into pre-defined structures is crucial to integrating LLMs into other software systems and generative AI apps. OpenAI has taken the lead by releasing the GPT function calling (Link) and JSON mode (Link). Still, these require intensive prompt engineering, robust parsing, retry, and graceful error handling to work reliably for production real-world problems.

Below are some problems I’ve faced parsing structured data with LLMs. This article was written entirely by a human with help from Grammarly’s grammar checker, which has been my writing method since 2019.

Classification: The LLM must strictly adhere to a list of allowed classes, which can be as many as tens to hundreds in real-world problems. LLMs start hallucinating about disallowed classes in tasks with more than a handful of classes.

Named Entity Recognition (NER): The LLM should only pick entities explicitly present in the text. These entities might be in a 2- or 3-level deeply nested structure like User → Address → City. LLMs struggle to reliably identify these deeply nested fields and either miss them or hallucinate something that doesn’t exist.

Synthetic Data Generation: Similar to NER, you might require a 2- or 3-level deeply nested data structure, so the challenges are the same.

Thankfully, some open-source projects aim to solve these challenges, but I’ve been getting mixed results from them on complex real-world problems like those mentioned above. So, I set out to systematically compare the three open-source frameworks that I’ve used: Instructor (Link), Fructose (Link), and everyone’s favorite Langchain (Link), to identify the best overall framework for the above three tasks on more challenging real-world scenarios. Spoiler alert: it’s not Langchain!

Experiment Philosophy and Plan"
https://towardsdatascience.com/how-to-build-your-own-ai-assistant-for-bookmark-searching-7e3dcc17e3fc,How to build your own AI assistant for bookmark searching?,"Chrome Plugin for bookmark retrieval

Code: https://github.com/swsychen/Boomark2Sheet_Chromeplugin

To transport bookmarks into a Google Sheet for further processing, we need to build a customized Chrome plugin (or extension) first.

The most important file for a Chrome extension is the manifest.json, which defines the high-level structure and behavior of the plugin. Here we add the necessary permissions to use the bookmark API from Google Chrome and track the changes in the bookmarks. We also have a field for oauth2 authentication because we will use the Google Sheet API. You will need to put your own client_id in this field. You can mainly follow the Set up your environment section in this link to get the client_id and a Google Sheet API key (we will use it later). Something you should notice is:

In OAuth consent screen, you need to add yourself (Gmail address) as the test user. Otherwise, you will not be allowed to use the APIs.

In Create OAuth client ID, the application type you should choose is Chrome extension (not the Web application as in the quickstart link). The Item ID needed to be specified is the plugin ID (we will have it when we load our plugin and you can find it in the extension manager).

The core functional file is background.js, which can do all the syncs in the background. I’ve prepared the code for you in the GitHub link, the only thing you need to change is the spreadsheetId at the start of the javascript file. This id you can identify it in the sharing link of your created Google Sheet (after d/ and before /edit, and yes you need to manually create a Google Sheet first!):

https://docs.google.com/spreadsheets/d/{spreadsheetId}/edit#gid=0

The main logic of the code is to listen to any change in your bookmarks and refresh (clear + write) your Sheet file with all the bookmarks you have when the plugin is triggered (e.g. when you add a new bookmark). It writes the id, title, and URL of each bookmark into a separate row in your specified Google Sheet.

The last file popup.html is basically not that useful as it only defines the content it shows in the popup window when you click the plugin button in your Chrome browser.

After you make sure all the files are in a single folder, now you are ready to upload your plugin:

Go to the Extensions>Manage Extensions of your Chrome browser, and turn on the Developer mode on the top right of the page.

Click the Load unpacked and choose the code folder. Then your plugin will be uploaded and running. Click the hyperlink service worker to see the printed log info from the code.

Once uploaded, the plugin will stay operational as long as the Chrome browser is open. And it’ll also automatically start running when you re-open the browser.

Setting up Estuary Flow and Pinecone

Estuary Flow is basically a connector that syncs the database with the data source you provided. In our case, when Estuary Flow syncs data from a Google Sheet into a vector database — Pinecone, it will also call an embedding model to transform the data into embedding vectors which will then be stored in the Pinecone database.

For setting up Estuary Flow and Pinecone, there is already a quite comprehensive video tutorial on YouTube: https://youtu.be/qyUmVW88L_A?si=xZ-atgJortObxDi-

But please pay attention! Because the Estuary Flow and Pinecone are in fast development. Some points in the video have changed by now, which may cause confusion. Here I list some updates to the video so that you can replicate everything easily:

1.(Estuary Flow>create Capture) In row batch size, you may set some larger numbers according to the total row numbers in your Google Sheet for bookmarks. (e.g. set it to 600 if you’ve already got 400+ rows of bookmarks)

2. (Estuary Flow>create Capture) When setting Target Collections, delete the cursor field “row_id” and add a new one “ID” like the following screenshot. You can keep the namespace empty.

3. (Estuary Flow>create Capture) Then switch to the COLLECTION subtab, press EDIT to change the Key from /row_id to /ID. And you should also change the “required” field of the schema code to “ID” like the following:

//...skipped

""URL"": {

""type"": ""string""

},

""row_id"": {

""type"": ""integer""

}

},

""required"": [

""ID""

],

""type"": ""object""

}

After “SAVE AND PUBLISH”, you can see that Collections>{your collection name}>Overview>Data Preview will show the correct ID of each bookmark.

4. (Estuary Flow>create Capture) In the last step, you can see an Advanced Specification Editor (in the bottom of the page). Here you can add a field “interval”: 10m to decrease the refresh rate to per 10 minutes (default setting is per 5 minutes if not specified). Each refresh will call the OpenAI embedding model to redo all the embedding which will cost some money. Decreasing the rate is to save half of the money. You can ignore the “backfill” field.

//...skipped

""syncMode"": ""full_refresh""

},

""target"": ""CJQ/mybookmark/bookmarks_v3""

}

],

""interval"": ""10m""

}

5. (Estuary Flow>create Materialization) The Pinecone environment is typically “gcp-starter” for a free-tier Pinecone index or like “us-east-1-aws” for standard-plan users (I don’t use serverless mode in Pinecone because the Estuary Flow has not yet provided a connector for the Pinecone serverless mode). The Pinecone index is the index name when you create the index in Pinecone.

6. (Estuary Flow>create Materialization) Here are some tricky parts.

First, you should select the source capture using the blue button “SOURCE FROM CAPTURE” and then leave the Pinecone namespace in “CONFIG” EMPTY (the free tier of Pinecone must have an empty namespace).

Second, after pressing “NEXT”, in the emerged Advanced Specification Editor of the materialization, you must make sure that the “bindings” field is NOT EMPTY. Fill in the content as in the following screenshot if it is empty or the field does not exist, otherwise, it won’t send anything to Pinecone. Also, you need to change the “source” field using your own Collection path (same as the “target” in the previous screenshot). If some errors pop up after you press “NEXT” and before you can see the editor, press “NEXT” again, and you will see the Advanced Specification Editor. Then you can specify the “bindings” and press “SAVE AND PUBLISH”. Everything should be ok after this step. The errors occur because we didn’t specify the “bindings” before.

If there is another error message coming up after you have published everything and just returned to the Destination page telling you that you have not added a collection, simply ignore it as long as you see the usage is not zero in the OVERVIEW histogram (see the following screenshots). The histogram basically means how much data it has sent to Pinecone.

""bindings"": [

{

""resource"": {},

""source"": ""CJQ/mybookmark/bookmarks_v3"",

""fields"": {

""recommended"": true

}

}

],

7. (Pinecone>create index) Pinecone has come up with serverless index mode (free but not supported by Estuary Flow yet) but I don’t use it in this project. Here we still use the pod-based option (not free anymore since last checked on April 14, 2024) which is well enough for our bookmark embedding storage. When creating an index, all you need is to set the index name and dimensions.

8. (Pinecone>Indexes>{Your index}) After you finish the creation of the Pinecone index and make sure the index name and environment are filled in correctly in the materialization of Estuary Flow, you are set. In the Pincone console, go to Indexes>{Your index} and you should see the vector count showing the total number of your bookmarks. It may take a few minutes until the Pinecone receives information from Estuary Flow and shows the correct vector count.

Building your own App with Streamlit and Langchain

Code: https://github.com/swsychen/BookmarkAI_App

We are almost there! The last step is to build a beautiful interface just like the original ChatGPT. Here we use a very convenient framework called Streamlit, with which we can build an app in only a few lines of code. Langchain is also a user-friendly framework for using any large language model with minimum code.

I’ve also prepared the code for this App for you. Follow the installation and usage guide in the GitHub link and enjoy!

The main logic of the code is:

get user prompt → create a retriever chain with ChatGPT and Pinecone → input the prompt to the chain and get a response → stream the result to the UI"
https://towardsdatascience.com/quantization-linear-regression-and-hardware-for-ai-our-best-recent-deep-dives-a6baf108db0c,"Quantization, Linear Regression, and Hardware for AI: Our Best Recent Deep Dives","TDS Editors

·

Follow

Published in

Towards Data Science

·

3 min read

·

5 hours ago

--

There are times when brevity is a blessing; sometimes you just need to figure something out quickly to move ahead with your day. More often than not, though, if you’d like to truly learn about a new topic, there is no substitute for spending some time with it.

This is where our Deep Dives excel: these articles tend to be on the longer side (some of them could easily become a short book!), but they reward readers with top-notch writing, nuanced explanations, and a well-rounded approach to the question or problem at hand. We’ve published some excellent articles in this category recently, and wanted to make sure you don’t miss out.

Happy reading (and bookmarking)!

Quantizing the AI Colossi Sure, Nate Cibik’s comprehensive guide to quantization might be an 81-minute read, but we promise it’s worth the investment: it’s a one-stop resource to understand the mathematical underpinning of this ever-relevant approach, catch up with recent research, and learn about the practical aspects of implementation, too.

Linear Regressions for Causal Conclusions For a thorough and highly accessible intro to linear regression, especially in the context of business problems and decision-making scenarios, head right over to Mariya Mansurova’s latest explainer, which shows how a relatively straightforward method can yield sophisticated insights.

Groq, and the Hardware of AI — Intuitively and Exhaustively Explained We all know that recent advances in AI depend on major improvements to computing technology, but far fewer among us can explain in detail how this evolution unfolded. This is where Daniel Warfield’s stellar overview kicks in, taking us through the entire recent history of hardware from CPUs and GPUs to TPUs and beyond.

Deep Dive into Sora’s Diffusion Transformer (DiT) by Hand We have a soft spot for patient, well-illustrated guides that focus on one thing—a model, a tool, a workflow—and unpack its nuances with care. Srijanie Dey, PhD offers precisely that in her recent deep dive, which focuses on the inner workings of OpenAI’s video-generating (and buzz-generating) model, Sora.

Create an Agent with OpenAI Function Calling Capabilities If your idea of an immersive read entails less language, more code, we suspect you’ll appreciate Tianyi Li and Selina Li’s patient tutorial, which walks us through the process of creating a trip-assistant agent—one that leverages function calling for a more streamlined and efficient workflow.

5 Powerful Strategies To Make Sure AI Doesn’t Steal Your Job — A Spotify Data Scientist’s Survival Guide In times of economic and technological uncertainty, it’s always a good idea to invest in your core skills. Khouloud El Alami shares several actionable insights on the areas you should focus on to make your career more resilient to disruption (whether AI-induced or otherwise).

Overwriting in Python: Tricky. Dangerous. Powerful.

Looking to expand your Python toolkit and gain a deeper understanding of a common programming procedure? Marcin Kozak is back with another Python must-read, this one zooming in on overwriting: how it works, why using it comes with more than a few risks, and how to go about harnessing its power effectively and safely.

Thank you for supporting the work of our authors! If you’re feeling inspired to join their ranks, why not write your first post? We’d love to read it.

Until the next Variable,

TDS Team"
https://uwm.edu/news/northwestern-mutual-data-science-institute-features-ai-discussion-at-annual-symposium-at-uwm-2/,Northwestern Mutual Data Science Institute features AI discussion at annual symposium at UWM,"The Northwestern Mutual Data Science Institute, a partnership among the University of Wisconsin-Milwaukee, Marquette University and Northwestern Mutual, is hosting its second annual, free-to-the-public symposium on April 24 at the UWM Student Union.

The daylong event will address the evolving landscape of artificial intelligence and how AI will bridge innovation and impact. Attendees will learn about the various facets of AI, hear from industry and academic experts, and network with others in the AI and data science community.

The symposium kicks off with a fireside chat at 9:15 a.m. featuring NMDSI leadership, UWM Chancellor Mark Mone, Marquette President Michael Lovell and Northwestern Mutual Chief Customer Officer Christian Mitchell. That’s followed by a 10 a.m. keynote address by Chris Wiggins, author and Columbia University professor, who will discuss how data-empowered products and automated decision systems increasingly determine our political, professional and personal realities.

For a full schedule of sessions and speakers, and registration, visit the symposium’s website. The symposium will also be livestreamed, and a link to that stream will be available at a later date.

NMDSI is creating a technology ecosystem and advancing southeastern Wisconsin as a national hub for technology, research, business and talent development. Since its inception in 2018, NMDSI has championed academic data science and technology learning while propelling innovation in key areas, including AI, data bias and ethics, behavioral economics, financial literacy, and health and wealth inequities. NMDSI-affiliated research projects use data science to address challenging societal issues that have a local and national impact."
https://blogs.oracle.com/ai-and-datascience/post/ai-quick-actions-in-oci-data-science,Introducing AI Quick Actions in OCI Data Science,"Today, we’re announcing the release of OCI Data Science AI Quick Actions, designed to enable anyone to easily deploy, fine-tune, and evaluate foundation models.

Over the past year, we have witnessed an explosion in the popularity of generative AI and interest in the foundation models that power them. OCI Data Science offers a platform to fine-tune and deploy foundation models in OCI. However, until today, it was a multistep process that requires Python coding, containers, and machine learning expertise.

AI Quick Actions

This new feature available in OCI Data Science aims to expand the reach of foundation models by providing customers with a streamlined, code-free, and efficient environment to work with foundation models. Using AI Quick Actions incurs no extra cost on top of OCI Data Science, which only charges for the underlying compute infrastructure and storage for your Data Science workload. To start using AI Quick Actions, you need to set up the required policies. For more information, see our documentation. After setting up the policies, create a Data Science notebook or deactivate and reactivate an existing notebook to begin your journey with AI Quick Actions.

When you open a Data Science notebook, you can find AI Quick Actions under Extensions in the Notebook Launcher. See Figures 1 and 2. After opening AI Quick Actions, you can access models, deployments, and evaluations.

Explore LLMs and other foundation models

In the model explorer, a list of foundation models that AI Quick Actions support and a list of your fine-tuned models are shown. For our first release, we’re supporting several large language models (LLMs), such as CodeLlama, Mistral, and Falcon. We plan to add more models over time. When you select the card of each LLM, you can view details about the model, such as the architecture, input, output, and model license. See figure 4.

Fine-tune your model with your own data

Fine-tuning is the process of taking a pretrained model and training it on a domain-specific dataset to improve its knowledge and provide more accurate responses in that domain. You can fine-tune a model with the tag “Ready to Fine Tune” on the model card so that the model is better-adapted to your specific domain, as shown in Figure 5. You can use a dataset from OCI Object Storage or the storage of your notebook session. We recommend that your dataset contains a minimum of 100 records. For information about the format of the dataset needed for fine tuning, consult this GitHub page.

Deploy and test your model immediately

Create your own model deployment from a foundation model with the tag “Ready to Deploy” or a model that you’ve already fine-tuned as shown in Figure 6. Then you can deploy the model as a HTTP endpoint in OCI. After your model is deployed, you can test it out quickly and easily with our prompt and response panel, see Figure 7.

Evaluate your models

With AI Quick Actions, you can create a model evaluation to see your model performance. Evaluating LLMs according to your data is necessary, but it presents a considerable challenge because of the unstructured nature of their output. You have numerous metrics to assess specific aspects of a language model performance.

Currently, we’re using ROUGE and BERTScore for model evaluation, with plans to support other evaluation metrics in the future. ROUGE is based on measuring the overlap between the model prediction and the human-produced reference. This focuses on the overlap of the n-grams between the reference and model prediction. BERTScore is a metric for evaluating text generation models. It measures the similarity between the contextual token embeddings of the reference and model prediction.

You can evaluate the model with a dataset from Object Storage or the storage of your notebook and group model evaluations together by creating an experiment name. After evaluation is complete, you can view the evaluation report and download it to your local machine.

Conclusion

AI Quick Actions in OCI Data Science simplifies your users’ experience, including the less technical ones, so that they can deploy, customize, test, and evaluate foundation models faster and focus on creating generative AI-powered applications. In the upcoming months, we plan to add more support and improvements including support for more foundation models, support for more dataset file formats, and the addition of other model evaluation metrics."
https://news.nd.edu/news/five-notre-dame-faculty-elected-aaas-fellows-as-program-celebrates-150th-anniversary/,Five Notre Dame faculty elected AAAS Fellows as program celebrates 150th anniversary,"Today, the American Association for the Advancement of Science (AAAS), one of the world’s largest general scientific societies and publisher of the Science family of journals, announced its newest class of AAAS Fellows, including five faculty from the University of Notre Dame.

This class represents expertise and accomplishment in the fields of biological sciences, chemistry, medical sciences, engineering, neuroscience and physics.

“To be elected by one’s peers as a AAAS Fellow is a tremendous honor and a mark of disciplinary excellence and innovation,” said John T. McGreevy, the Charles and Jill Fischer Provost and Francis A. McAnaney Professor of History. “We are proud to celebrate the achievements of these extraordinary colleagues whose scientific contributions help advance Notre Dame as a leading global Catholic research university and a force for good in the world.”

Notre Dame faculty elected to the 2023 class of AAAS Fellows include:

Elizabeth A. Archie, professor in the Department of Biological Sciences. Archie’s research aims to understand the scientific impact of community. The AAAS recognizes her for novel and important contributions to the understanding of health and disease in the context of evolution and ecology, particularly in wild mammal populations. Archie is co-director of the Amboseli Baboon Research Project, a collaboration among Notre Dame, Princeton University, Duke University and the Max Planck Institute of Evolutionary Anthropology, and one of the longest-running primate studies in the world.

Peter C. Burns, the Henry Massman Professor of Civil Engineering in the Department of Civil and Environmental Engineering and Earth Sciences and director of Notre Dame’s Center for Sustainable Energy (ND Energy). Burns is recognized for contributions to advancing actinide chemistry, geochemistry and mineralogy to improve the nuclear fuel cycle, manage nuclear waste and address environmental contamination. He has focused most of his research over the past decade on the solid-state chemistry, mineralogy and environmental chemistry of uranium, as well as the transuranic elements neptunium and plutonium.

Nitesh Chawla, the Frank M. Freimann Professor of Computer Science and Engineering and director of the Lucy Family Institute for Data and Society. Chawla is recognized for distinguished contributions to artificial intelligence and data science, specifically in machine learning from imbalanced data, machine learning on graphs, and data science for societal impact. Chawla is also a fellow of the Association for Advancement of Artificial Intelligence, the Association of Computing Machinery and the Institute of Electrical and Electronics Engineers.

Patricia J. Culligan, the Matthew H. McCloskey Dean of Engineering and professor in the Department of Civil and Environmental Engineering and Earth Sciences. Culligan’s expertise is in geo-environmental engineering, with a focus on sustainable urban infrastructure, social networks and the application of advanced measurement and sensing technologies to improve water, energy and environmental management. She is recognized for advancing the understanding of the physical mechanisms governing porous media flow and transport, emphasizing knowledge generation in areas spanning from groundwater protection to energy dissipation and urban water management.

Nathan G. Swenson, professor in the Department of Biological Sciences and the Gillen Director of Notre Dame’s Environmental Research Center (UNDERC). Swenson is recognized for his distinguished contributions in elucidating the drivers of the structure, diversity and dynamics of forest tree communities. His research is focused on leveraging information regarding the intra- and inter-specific variation in tree performance to understand and predict the past, present and future distribution of biodiversity — including a collaboration with NASA to measure forest health.

“We would like to thank the AAAS for recognizing these stellar members of the Notre Dame faculty, and we congratulate each of them on receiving this distinct honor,” said Jeffrey F. Rhoads, vice president for research and professor in the Department of Aerospace and Mechanical Engineering. “They are leading scientists, engineers and innovators who also embody Notre Dame’s commitment to make discoveries that yield benefits for the common good. We are grateful for the work they are doing to prepare the next generation of researchers at Notre Dame and beyond.”

Election as a fellow of AAAS is a lifetime honor, with an expectation that recipients maintain commonly held standards of professional ethics and scientific integrity.

New fellows join noted fellows such as Alondra Nelson, the Harold F. Linder Professor at the Institute for Advanced Study and former deputy assistant to President Joe Biden and acting director of the White House Office of Science and Technology Policy; Mae Jemison, the first Black woman to go to space; Steven Chu, 1997 Nobel laureate in physics who served as the 12th U.S. Secretary of Energy; W.E.B. Du Bois, considered the founding father of American sociology; Ellen Ochoa, veteran astronaut and the Johnson Space Center’s first Hispanic and second female director in its history; Grace Hopper, pioneer in computer software development and programming language; and Vint Cerf, who co-designed the TCP/IP protocols and the architecture of the internet and received the U.S. Presidential Medal of Freedom."
https://news.yale.edu/2024/04/17/creating-global-impact-through-yales-data-driven-social-sciences,Creating global impact through Yale’s data-driven social sciences,"This story is the latest in a series about Yale’s evolution under President Peter Salovey as he prepares to return to the faculty later this year.

To understand how people moved around during the COVID-19 pandemic, Yale sociologist Emma Zang needs data — a lot of it. When asked, she reels off a list of datasets she works with to analyze patterns: voter-registration data, cell-phone location data, credit-card transaction data, X (formerly Twitter) data, and net-light data that captures population density through satellite imagery showing the geographic areas glowing brightest at night.

Traditionally, mapping migration patterns required survey data, which takes great effort and time to compile, Zang explains.

“By the time you collect the data, clean it, and use it, it’s already two years old, which limits its usefulness,” said Zang, an assistant professor of sociology in Yale’s Faculty of Arts and Sciences (FAS). “These new, innovative datasets are game-changers.”

For Zang and other social scientists, the emergence of large, computerized datasets containing information from the government, nonprofit sector, and private enterprise is altering how they approach their work — and Yale, during President Peter Salovey’s presidency, has responded by investing broadly to facilitate this work and other aspects of data-driven social science.

In the past decade, the university has launched bold initiatives and built key infrastructure to create a collaborative campus environment for data-driven social science that is being used to guide domestic policy, address climate change and other pressing global challenges, and which seeks to understand human cognition, values, and behavior.

“Social science research has the potential to shape policy and effect change on a global scale,” said Salovey, a distinguished psychologist who will return to social science research and teaching when he steps down at the end of the academic year. “That requires bringing together deep expertise on data, on theory, and on policy, facilitating collaboration, convening leaders and guiding important conversations, and pursuing insights into human relationships and society.

“At Yale, we are committed to leading the way in this field, to understand urgent global challenges and increase knowledge, without partisanship or ideology.”

Since Salovey began his tenure, in 2013, the university has strengthened the social science faculty by hiring top-flight scholars, many of whom have taken on leadership roles at the university. It has enhanced social-science education by transforming the Department of Statistics into the Department of Statistics and Data Science and establishing a major in economics and computer science to teach undergraduates the skills needed to harness data for a better understanding of the world.

Yale has also opened several innovative and cross-cutting centers for research. These include the Data-Intensive Social Science Center, which helps scholars across the university access and manage the comprehensive, complex datasets that increasingly drive boundary-expanding social science research; the Institute for Foundations of Data Science, which applies the methodology of data science across multiple disciplines; and the Tobin Center for Economic Policy, which brings Yale’s widely recognized excellence in economics and other fields to bear on public policy.

In 2021, the university launched the Wu Tsai Institute, an interdisciplinary research center that combines neuroscience, social science, and data science to accelerate breakthroughs unlocking the mysteries of human cognition.

And in 2022, Yale established the Yale Jackson School of Global Affairs, the university’s first new professional school since 1976.

“These are all remarkable accomplishments,” said Alan Gerber, Sterling Professor of Political Science in the FAS, who served as its inaugural dean of social science from 2014 to 2021 and currently directs Yale’s Institution for Social and Policy Studies. “Through them, President Salovey has created a fertile environment that encourages collaboration and enables social scientists in the FAS and professional schools to pursue ambitious, exciting research that has a real-world impact.”

New areas of excellence

Over the past 10 years, Yale has built on its historic strengths while advancing new techniques in data and analysis.

The Tobin Center, established in 2019, exemplifies the approach, harnessing recent advances in economics, data science, and analytics to conduct rigorous, evidence-based research that helps define and inform policy debates.

“Yale is traditionally strong in economics,” Gerber said. “The Tobin Center is expanding that traditional excellence into a new area of enormous public importance.”

The center unites researchers across campus in the pursuit of policy-relevant scholarship while connecting them with lawmakers and government officials at the local, state, and federal levels.

For example, faculty from the Yale School of Management, FAS, and the Yale School of Public Health recently met with administrators from Connecticut’s Medicaid program to discuss how the latest evidence-based research might strengthen the state’s health system. The center’s staff includes data analysts and investigators to support scholarship, as well as veterans of the policy process to help faculty share their work with lawmakers.

SELECTED MILESTONES IN DATA-DRIVEN SOCIAL SCIENCES

While the Tobin Center supports research primarily in the domestic sphere, the Yale Jackson School of Global Affairs provides opportunities for social scientists to tackle international issues. Its faculty includes economists, political scientists, historians, and anthropologists studying agricultural markets in sub-Saharan Africa, authoritarian regimes and transitions to democracy, mental health and child development among refugee populations, and education policy in developing countries, among other issues of global importance.

Aside from their research, the school’s faculty members are helping to train a new generation of leaders equipped to embrace the use of data to inform policy. The school aims to give its students deep knowledge of the world around them, fluency with data, and an agility working across disciplines that will equip them to meet global challenges.

“The Jackson School is a unique convening space for scholarship on a range of pressing global issues. We have a multidisciplinary faculty — with top scholars from the humanities, social sciences, and Yale’s other professional schools as well as senior practitioners of global affairs — in dialogue with one another,” said Jim Levinsohn, dean of the Jackson School and Charles W. Goodyear Professor in Global Affairs. “We’re training our students to take this cross-disciplinary, collaborative approach and bring fresh insight to urgent problems facing the world.”

The Wu Tsai Institute, established through a gift from Joseph Tsai ’86, ’90 J.D. and Clara Wu Tsai, bridges multiple fields of neuroscience research, from biology to psychology, and data science to engineering. Its leadership team includes three social scientists and a neuroscientist: Nicholas Turk-Browne, a professor of psychology and the institute’s director; Kia Nobre, Wu Tsai Professor of Psychology, associate director of the institute and director of the Center for Neurocognition and Behavior; John Lafferty, the John C. Malone Professor of Statistics and Data Science and director of the Center for Neurocomputation and Machine Intelligence; and Daniel Colón-Ramos, the Dorys McConnell Duberg Professor of Neuroscience and Cell Biology and director of the Center for Neurodevelopment and Plasticity.

The institute has united more than 150 faculty across disciplines, including from four social science departments, in a moonshot effort to reveal the secrets of human cognition.

“President Salovey and Joe Tsai conceived of the Wu Tsai Institute over a breakfast in La Jolla, California,” said Turk-Browne. “They recognized that, in an era obsessed with the intelligence of machines, the remarkable capabilities of humans are not yet understood, including our ability to perceive, remember, think, decide, and create. These wonders of human cognition are the basic ingredients of all knowledge, relationships, organizations, and pursuits, and in this way, their understanding is fundamental for advancing social science.”

‘One giant sandbox’

Perhaps no development has been more important to the study, teaching, and practice of social science over the past several years than the proliferation of large data sets. The vast quantity of information now available informs the study of health care, education, political polarization, immigration, economic inequality, and climate change, among other pressing issues.

“Decades ago, a lot of social science research was largely theoretical, based on small datasets, or methodologically focused on statistical techniques that were designed to compensate for the relatively poor quality of data,” said Steven Berry, the David Swensen Professor of Economics in the FAS and the inaugural faculty director of the Tobin Center for Economic Policy.

“Computerization has made many new sources of data available, which become potential datasets for the study of human behavior, social behavior, and economic behavior.”

The rise of these massive datasets presents challenges. While the Marx Science and Social Science Library provides researchers access to many important datasets, they also must negotiate user agreements with the vendors that compile them, devise way to securely store the data that often includes confidential information, and learn computing techniques, including machine learning and artificial intelligence, to analyze it.

In 2022, Yale established the Data-Intensive Social Science Center (DISSC) to help researchers across FAS and Yale’s professional schools — the faculties of Yale School of the Environment, the Yale School of Management, Yale School of Public Health, the Yale Jackson School of Global Affairs, and Yale Law School all include social scientists — looking to access, analyze, and preserve enormous amounts of data.

Faculty members have always found ways to access and analyze the data they need, but centralized support offered by the DISSC accelerates that process and ensures all researchers are supported, said Gerber, who serves as the DISSC’s faculty director along with Berry. Creating a center that accelerates the adoption and ease the use of methods like AI and machine learning, Gerber said, is a “truly visionary effort.”

“To do that as a university service open to all faculty in the social sciences distinguishes Yale from others.”

In its first year of operation, the DISSC provided programming to help faculty stay apprised of the latest innovations in analyzing and managing data, began helping faculty negotiate the cumbersome process of reaching user agreements with vendors for access to datasets, and launched a pilot project with Yale Amazon Web Services to create secure space on the cloud to safely store datasets.

Storing data in a centralized location allows multiple researchers to work without having to move the datasets around or make copies of them, explained Ron Borzekowski, the DISSC’s inaugural director. If a researcher adds value to data by cleaning it or appending new variables, then the enhanced version becomes available to anyone with login authorization, he said.

“Centralization is the key,” Borzekowski said. “Instead of working in four or five distinct silos, they’ll be working in one giant sandbox.”

The DISSC embodies Salovey’s goal of creating a more unified Yale, Berry said.

“It allows social scientists across the university to benefit from the same infrastructure,” he said. “When a problem is solved once or progress is made one project, or for one individual, that progress becomes available to other researchers.

“I don’t know of any other university in the country that is trying this at this scale.”"
https://phys.org/news/2024-04-driven-music-climate.html,Data-driven music: Converting climate measurements into music,"A geo-environmental scientist from Japan has composed a string quartet using sonified climate data. The 6-minute-long composition—titled ""String Quartet No. 1 ""Polar Energy Budget""—is based on over 30 years of satellite-collected climate data from the Arctic and Antarctic and aims to garner attention on how climate is driven by the input and output of energy at the poles.

The backstory about how the composition was put together is published April 18 in the journal iScience as part of a collection ""Exploring the Art-Science Connection.""

""I strongly hope that this manuscript marks a significant turning point, transitioning from an era where only scientists handle data to one where artists can freely leverage data to craft their works,"" writes author and composer Hiroto Nagai, a geo-environmental scientist at Rissho University.

Scientist-composer Hiroto Nagai asserts that music, as opposed to sound, evokes an emotional response and posits that ""musification"" (as opposed to sonification) of data requires some intervention by the composer to build tension and add dynamics. For this reason, Nagai was more liberal in adding a ""human touch"" compared to previous data-based musical compositions, aiming to meld sonification with traditional music composition.

""As a fundamental principle in music composition, it is necessary to combine temporal sequences from tension-building to resolution in various scales, from harmonic progressions to entire movements,"" Nagai writes. ""So far, there haven't been published attempts and open discussion on sonification-based music composition, nor attempts to demonstrate the methodology required to intentionally affect the audience's emotions with an artistic piece.""

To do this, he first used a program to sonify environmental data by assigning sounds to different data values. The publicly available data was collected from four polar locations between 1982 and 2022: an ice-core drilling site in the Greenland ice sheet, a satellite station in Norway's Svalbard archipelago, and two Japanese-owned research stations in the Antarctic (Showa Station and Dome Fuji Station). For each of the sites, Nagai used data on monthly measurements of short- and longwave radiation, precipitation, surface temperature, and cloud thickness.

Next, he transformed this collection of sounds into a musical composition to be played by two violins, a viola, and a cello. This process involved many steps, including manipulating the pitch of different data points and assigning sections of data to the different instruments, overlaying passages created from different data, and introducing musical playing techniques such as pizzicato and staccato.

Nagai also intervened in more artistic ways by introducing rhythm, deliberately removing certain sounds, and introducing handwritten (non-data derived) parts into the composition.

The quartet's premiere live performance was shared at Waseda University in Tokyo in March 2023 followed by a panel discussion. A filmed performance of the piece by PRT Quartet, a Japanese professional string quartet, was also released on YouTube in March 2023.

""Upon listening, my initial reaction was like, 'What is this?' It felt like a typical contemporary piece,"" said Haruka Sakuma, the professional violinist who performed 2nd violin. ""The flow of the music was a bit hard to memorize quickly, and it was quite challenging at first.""

Nagai says that, in contrast to graphical representations of data, music elicits emotion before intellectual curiosity and suggests that using graphical and music representations of data in conjunction might be even more powerful.

""It grabs the audiences' attention forcefully, while graphical representations require active and conscious recognition instead,"" Nagai writes. ""This reveals the potential for outreach in the Earth sciences through music."""
https://sloanreview.mit.edu/video/how-grassroots-automation-speeds-digital-success/,Webinar: How Grassroots Automation Speeds Digital Success,"Companies must digitize to survive — but many can’t find the developers and data scientists to do so. To keep pace, leaders are launching citizen development initiatives to harness the creativity and business acumen of their nontechnical “citizens.” When designed and championed effectively, these programs speed digital transformation.

In this webinar, you will learn:"
https://builtin.com/data-science,What Is Data Science?,"Data science is a discipline that combines math, statistics, artificial intelligence and computer science to process large volumes of data and determine patterns and trends. With these insights, organizations can better understand why certain events happen and develop more informed decision-making processes.

Data science is the realm of data scientists, who often rely on artificial intelligence, especially its subfields of machine learning and deep learning, to create models and make predictions using algorithms and other techniques.

Why Is Data Science Important?

Data science makes it possible to analyze large amounts of data and spot trends through formats like data visualizations and predictive models. Given the ability to take proactive measures, businesses can then make smarter decisions, design more efficient operations, improve their cybersecurity practices and provide better customer experiences as a result. Teams are already applying data science across a range of scenarios like diagnosing diseases, detecting malware and optimizing transportation routes.

What Is Data Science Used For?

Data science is used to look for connections and patterns within complex information, leading to insights that businesses can then use to make better decisions. More specifically, data science is used for complex data analysis, predictive modeling, recommendation generation and data visualization.

Analysis of Complex Data

Data science allows for quick and precise analysis. With various software tools and techniques at their disposal, data analysts can easily identify trends and detect patterns within even the largest and most complex datasets. This enables businesses to make better decisions, whether it’s regarding how to best segment customers or conducting a thorough market analysis.

Predictive Modeling

Data science can also be used for predictive modeling. In essence, by finding patterns in data through the use of machine learning, analysts can forecast possible future outcomes with some degree of accuracy. These models are especially useful in industries like insurance, marketing, healthcare and finance, where anticipating the likelihood of certain events happening is central to the success of the business.

Recommendation Generation

Some companies — like Netflix, Amazon and Spotify — rely on data science and big data to generate recommendations for their users based on their past behavior. It’s thanks to data science that users of these and similar platforms can be served up content that’s tailored to their preferences and interests.

Data Visualization

Data science is also used to create data visualizations — think graphs, charts, dashboards — and reporting, which helps non-technical business leaders and busy executives easily understand otherwise complex information about the state of their business.

What Are the Benefits of Data Science?

Industries are realizing the advantages of employing data science, including these common benefits.

Improved Decision Making

Being able to analyze and glean insights from massive amounts of data gives leaders an accurate understanding of past developments and concrete evidence for justifying their decisions moving forward. Companies can then make sound, data-driven decisions that are also more transparent to employees and other stakeholders.

Increased Efficiency

By gathering historical data, businesses can pinpoint workflow inefficiencies and devise solutions to speed up production. They can also test different ideas and compile data to see what’s working and what’s not. With a data-first approach, companies can then design processes that maximize productivity and minimize unnecessary work and costs.

Complex Data Interpretation

Data science allows for the handling of large volumes of complex data, which businesses can then use to build predictive models for anything from anticipating customer behavior to forecasting market trends. If other organizations can’t extract insights from complicated data, companies that do have the clear advantage of being the first ones to foresee upcoming events and prepare accordingly.

Better Customer Experience

Collecting data on customer behavior allows companies to determine customer buying habits and product preferences. Teams can then leverage this data to design personalized customer experiences. For example, businesses can create marketing campaigns tailored toward certain demographics, offer product recommendations based on a customer’s past purchases and tweak products according to customer uses and feedback.

Strengthened Cybersecurity

Data science tools give teams the capacity to monitor large volumes of data, which makes it easier to spot anomalies. For example, financial institutions can review transactional data to determine suspicious activity and fraud. Security teams can also gather data from network systems to detect unusual behavior and catch cyber attacks in their early stages.

What Is the Data Science Process?

Data science is typically thought of as a five-step process, or lifecycle:

1. Capture

This stage is when data scientists gather raw and unstructured data. The capture stage typically includes data acquisition, data entry, signal reception and data extraction.

2. Maintain

This stage is when data is put into a form that can be utilized. The maintenance stage includes data warehousing, data cleansing, data staging, data processing and data architecture.

3. Process

This stage is when data is examined for patterns and biases to see how it will work as a predictive analysis tool. The process stage includes data mining, clustering and classification, data modeling and data summarization.

4. Analyze

This stage is when multiple types of analyses are performed on the data. The analysis stage involves data reporting, data visualization, business intelligence and decision making.

5. Communicate

This stage is when data scientists and analysts showcase the data through reports, charts and graphs. The communication stage typically includes exploratory and confirmatory analysis, predictive analysis, regression, text mining and qualitative analysis.

What Are Data Science Techniques?

There are lots of data science techniques with which data science professionals must be familiar in order to do their jobs. These are some of the most popular techniques:

Regression

Regression analysis allows you to predict an outcome based on multiple variables and how those variables affect each other. Linear regression is the most commonly used regression analysis technique. Regression is a type of supervised learning.

Classification

Classification in data science refers to the process of predicting the category or label of different data points. Like regression, classification is a subcategory of supervised learning. It’s used for applications such as email spam filters and sentiment analysis.

Clustering

Clustering, or cluster analysis, is a data science technique used in unsupervised learning. During cluster analysis, closely associated objects within a data set are grouped together, and then each group is assigned characteristics. Clustering is done to reveal patterns within data — typically with large, unstructured data sets.

Anomaly Detection"
https://medium.com/@drbernard21/data-science-sooner-rather-than-later-dad56a46a25e?responsesOpen=true&sortBy=REVERSE_CHRON,Data Science Sooner Rather than Later,"In today’s digital age, the importance of data cannot be overstated. Data drives decisions in sectors from healthcare to retail, impacting everything from global economies to personal choices. Therefore, it is crucial to introduce data science literacy at a young age, ideally beginning in middle school. While some high schools have a data science program, a limited number exists nationwide. The introduction at the middle school level, albeit seemingly early, equips students with the analytical skills needed to navigate the world and fosters an understanding of data science in daily life.

Why Start in Middle School?

Middle school is a critical time for cognitive development (Fischer & Bidell, n.d.; Warren et al., 2023). According to developmental theories proposed by Piaget, students are transitioning from concrete operational stages to more formal operational ways of thinking (Mcleod, 2024). This stage is when children start to think more abstractly and can grasp complex concepts more readily. Introducing data science — a field that combines statistical analysis, critical thinking, and technological application — aligns well with their developmental milestones. It encourages analytical thinking, problem-solving, and the ability to discern patterns, all valuable across all areas of study and daily life.

Moreover, early exposure to data science can demystify mathematics and technology subjects, where U.S. students have historically and continue to underperform relative to other countries. Early exposure to data science in middle schools, particularly in underfunded and underserved communities, can be a powerful tool to counteract existing educational disparities that transfer to high school, higher education, and the workforce. Also, with Artificial Intelligence (AI), an advanced form of data modeling where the “author” of the model does not know precisely how it works, it still gives valuable results and can be very useful. AI is a component of data science. Additionally, computer science is a broader field encompassing data science and AI.

In making data science an integral part of the curriculum, schools can provide a context for mathematics and…"
https://www.analyticsinsight.net/cambridge-vs-harvard-the-best-picks-for-data-science-courses/,Cambridge vs Harvard: The Best Picks for Data Science Courses!,"Explore the comparison between Cambridge University and Harvard University for Data Science Courses

Choosing the right institution for studying Data Science is an important aspect of who aspires to become a Data Scientist. Harvard and Cambridge are renowned universities that offer Data Science Courses. Here, we will delve into the detailed comparison of Cambridge and Harvard

Data Science Courses offered by Cambridge University

Cambridge University gives options for Data Science courses that range from various experience levels and career fields. This course in Data Science offered by the University of Cambridge provides a relatively good grounding on the subject, topics such as Statistical Analysis, Machine Learning, and Data Visualization are dealt with here. For those who are looking for a data-driven practical experience in more detail, MPhil in Data Intensive Science is a postgraduate degree program that deals with more modern data analysis workflows and information sets. Furthermore, a Cambridge Data Science Career Accelerator is designed to reach to professionals who want to upgrade their technical skills and modern techniques through these trends. In addition to these, Cambridge has introduced Data Skills Bootcamps, which are one-year courses and are publicly funded to produce data skills.

Data Science Courses offered by Harvard University

Harvard offers a Professional Certificate course in Data Science, which imparts skills in R programming, data wrangling, and machine learning, among other important skills. The university also offers a cohort of online courses from HarvardX on disciplines including essential testing methods and modeling, workplace productivity, and linear regression. These courses are tailored to being accessible and are experiential-based to enable participants to gain data science skills that will be used in their careers.

Curriculum and Teaching Methods

Both universities have theoretical as well as practical approaches. It’s hardly a surprise that ideas like using demonstration sheets and code snippets instead of hard-copy textbooks have proven themselves to be an especially fruitful part of Cambridge’s courses. Harvard praises case studies and applying theory in real-world cases, therefore, learning should be the product of the classroom through practice.

Flexibility and Accessibility

Access to flexible-looking leads at Cambridge and Harvard University. The main merit of the pace of Cambridge courses is that students can attend classes at their convenience, whereas this is very useful for people who have to work or other commitments to attend classes. Distance learners from nearly every country on the planet have the opportunity to take Harvard’s departments through edX.

Industry Relevance

Both these organizations have courses on cards so that they meet the industry’s needs. By UC’s intake, working in collaboration with industry professionals, the training taught is in line with the abilities employers require. Harvard’s curriculum is business-minded; classes are presented by faculty members who are not only experts in the field but also conductors of research and practitioners.

Certification and Recognition

Recruiters and managers of companies see and seek graduates of both Harvard and Cambridge Universities as highly skilled on the market, whether to hire them or to keep them in their teams. Credentials acquired from these universities have lots of weight, and they can give you many open doors of career opportunities that is in the Data science domain.

While there is no doubt that both Cambridge and Harvard have an excellent curriculum in Data Science, offer different aspects. Cambridge delivers the keynote aspect of traditional and rigorous education with many options to choose from, whereas, Harvard places an emphasis on real-world application and spreads the teaching material through different ways."
https://www.cdotrends.com/story/3942/oracle-train-10000-ai-data-science,"Oracle To Train 10,000 in AI, Data Science","Oracle has announced a collaboration with the Singapore Government to train up to 10,000 students and professionals in the latest digital technologies including AI, cloud, cybersecurity, and data science by 2027.

The announcement was made at the CloudWorld Tour Singapore conference on Wednesday, which was attended by Oracle chief executive officer Safra Catz.

AI and data science

Specifically, Oracle will offer up to 300 internships and apprenticeships over three years to students and graduates across five polytechnics. This includes AI, generative AI, cloud computing, cybersecurity, data management, and autonomous databases.

Oracle will also provide training and certifications for up to 9,700 learners in Singapore over the next three years. They can obtain a new “Gen AI Professional Certification”, which Oracle says was designed to empower digital professionals in Singapore with advanced expertise and skills in AI technologies.

“When we launched the refreshed National AI Strategy (NAIS 2.0) in December last year, we set ambitious goals, one of which involves tripling our AI practitioner pool to 15,000 over the next five years,” said Minister Josephine Teo, who helms the Communications and Information, Smart Nation, and Cybersecurity portfolios.

“Although it has only been four months, Singapore is already making good progress towards realizing our vision of cultivating a skilled tech workforce capable of driving innovation and meeting industry demands. I am delighted to welcome like-minded partners such as Oracle to join us on our AI journey,” she said.

Billed as a whole-of-government and whole-of-economy approach, the National AI Strategy 2.0 (NAIS 2.0) builds on the country’s first AI strategy launched in 2019. We reported on it in December last year.

Garrett Ilg, executive vice president and general manager of Oracle for Japan and Asia Pacific pointed to Oracle’s decades of data expertise and “full stack cloud-based AI” as an enabler for digital skills development.

“Our TIP Alliance collaboration and Oracle University platform strongly align with Singapore’s Smart Nation initiative. By enhancing the digital literacy of the workforce, we aim to bolster local employment opportunities and equip individuals to navigate the complexities of the digital economy effectively,” he said."
https://www.datasciencecentral.com/using-window-functions-for-advanced-data-analysis/,Using window functions for advanced data analysis,"Window functions are an advanced feature of SQL that provides powerful tools for detailed data analysis and manipulation without grouping data into single output rows, which is common in aggregate functions. These functions operate on a set of rows and return a value for each row based on the calculation against the set.

In this article, we delve into window functions in SQL Server. You will learn how to apply various window functions, including moving averages, ranking, and cumulative sums, to achieve comprehensive analytics on data sets.

You will also see how to partition and filter data using the window functions.

Finally, you will study some best practices and pitfalls to avoid when working with the Window functions. These are the types of things that are covered during the more advanced SQL workshops that are available online.

Note: We will use the Microsoft Pubs database as an example to execute various window function queries.

Understanding window functions

Window functions are used for calculations across sets of rows related to the current row. Unlike standard aggregate functions, window functions do not collapse rows and allow us to perform calculations across rows related to the current row. This capability is crucial for running totals, moving averages, and cumulative statistics, which are invaluable for time-series data analysis, financial data, inventory management, and more.

With window functions, you can specify a “window” of rows related to the current row over which SQL Server performs a calculation. You can define this window using clauses like OVER, PARTITION BY, and ORDER BY.

Basic syntax

The basic syntax for a window function is:

Each part of the syntax has a specific purpose:

{function_name}(): This is the window function you want to apply. SQL supports various window functions such as SUM(), AVG(), COUNT(), RANK(), ROW_NUMBER(), and more. These functions can compute values over a specified range of rows.

OVER: This keyword defines the window over which the SQL server executes the function. It signifies the start of the window specification.

PARTITION BY: Divides the data into partitions (or groups) to which the function is applied. If you don’t include the PARTITION BY clause, all the rows will be treated as a single partition.

ORDER BY: Defines the order of data within each partition.

Practical scenarios using window functions

Let’s explore some practical scenarios using window functions on the Microsoft Pubs database. We will look into calculating moving averages, ranking, and cumulative sums.

Calculating moving averages for sales quantities

Moving averages smooth out data series and are commonly used to understand trends.

Let’s calculate a moving average for the sales quantities in the sales table of the Pubs database.

USE pubs

SELECT ord_num, ord_date, qty,

AVG(qty) OVER (ORDER BY qty ROWS UNBOUNDED PRECEDING) AS MovingAvgQty

FROM sales;

Output:

In the above query, we use the AVG window functions to calculate the moving average for the qty column. The ROWS UNBOUNDED PRECEDING means we want to calculate the moving average of all the previous rows up to the current ones.

You can also calculate the moving average for a specific number of previous rows.

For example, the following script returns the moving average for the previous two rows and the current row. Notice here that we cast the qty column to a floating type to have a precise average value.

USE pubs

SELECT ord_num, ord_date, qty,

AVG(CAST(qty AS float)) OVER (ORDER BY qty ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS MovingAvgQty

FROM sales;

Output:

Ranking Sales Data by Price

Ranking can help in comparing items, like listing products by sales price.

Let’s see an example where we rank the total sales price for each sale. We will first join the sales and titles tables. Next, we will calculate the total sale price for each record by multiplying qty with the price column of the corresponding tables). Finally, we will use the RANK function to rank all the records in descending order of the total sale price. This will give you information about which sale made the most money.

SELECT

S.ord_num,

S.ord_date,

S.qty,

T.title,

S.qty * T.price AS TotalSalePrice,

RANK() OVER (ORDER BY S.qty * T.price DESC) AS SalesRank

FROM

sales S

JOIN

titles T ON S.title_id = T.title_id;

Output:

Cumulative Sums of Total Sales Price

Cumulative sums are useful for running totals, which can be essential for inventory or account balance tracking.

For example, let’s calculate the cumulative total sale prices for all the rows in the sales table. As we did previously, we will join the sales and titles column to calculate the total sale price for each row.

Next, you can use the SUM window function to calculate the cumulative sales by ordering the results using the ord_date column. This will return you the cumulative sales by date.

USE pubs;

SELECT

S.ord_num,

S.ord_date,

S.qty,

T.title,

S.qty * T.price AS TotalSalePrice,

SUM(S.qty * T.price) OVER (ORDER BY s.ord_date ROWS UNBOUNDED PRECEDING) AS CumulativeSales

FROM

sales S

JOIN

titles T ON S.title_id = T.title_id;

Output:

Partitioning and Filtering with Window Functions

You can partition and filter records in a window function using the PARTITION BY and the CASE statement.

Partitioning with PARTITION BY Clause

You can use the PARTITION BY clause in conjunction with window functions. This allows you to apply window functions separately for each partition.

For example, the following query returns cumulative prices for various title types in the titles table.

USE pubs;

SELECT

title_id,

title,

type,

price,

SUM(price) OVER (PARTITION BY type ORDER BY price ROWS UNBOUNDED PRECEDING) AS CumulativePriceByType

FROM

titles

Output:

In the above output, cumulative prices are calculated separately for each title type.

Filtering with CASE Statement

You can use the CASE statement inside a window function to filter the records before applying the window function.

For example, you can use the following query containing the CASE statement if you only want to include titles in the cumulative sum where the price is greater than $10:

Output:

Best Practices and Common Pitfalls When Using Window Functions

Let’s now discuss some of the best practices and common pitfalls to avoid when using window functions in SQL Server.

Best practices

Indexing for Performance: Ensure columns used in ORDER BY and PARTITION BY are indexed to improve query performance, especially with large datasets.

Use PARTITION BY Judiciously: Use PARTITION BY thoughtfully. Overpartitioning, especially by columns with high cardinality, can reduce performance. Balance meaningful data segmentation with efficiency.

Limit Window Frames: Use specific boundaries like ROWS or RANGE to limit window sizes instead of defaulting to UNBOUNDED PRECEDING, which improves performance by reducing the number of rows processed.

Common pitfalls

Ignoring NULL Values: Window functions include NULL values by default. To ensure accuracy, exclude or handle NULLs as necessary.

Forgetting to Order Data: Omitting ORDER BY can yield incorrect results since the order of rows affects calculations like running totals or moving averages.

Performance Issues: Be mindful of potential performance issues with large datasets or complex queries. Check execution plans to identify and mitigate bottlenecks.

Conclusion

Window functions in SQL Server are indispensable tools for anyone seeking to perform sophisticated data analysis without the constraints of traditional aggregate functions. Their ability to operate over a set of rows and dynamically compute values makes them essential for various applications—from financial modelling and time-series analysis to inventory management.

In this article, you saw how SQL window functions work with the help of different practical scenarios. You also learned how to partition and filter data using window functions and what are the best practices and pitfalls to avoid when using window functions."
https://i2db.wustl.edu/calendar_event/2024-annual-i2db-symposium/,2024 I2DB Symposium: The Power of AI in Medicine,"Joshua Denzer, PhD

BI Solution Developer

Business Intelligence & Data Solutions

BJC Healthcare

Levi Kaster

Bioinformatics Research Assistant

Institute for Informatics, Data Science, and Biostatistics

School of Medicine

Washington University in St. Louis

Seunghwan (Nigel) Kim

PhD Candidate, Biomedical Informatics and Data Science

Division of Biology and Biomedical Sciences

School of Medicine

Washington University in St. Louis

Sunny Lou, MD, PhD

Instructor in Anesthesiology

Division of Adult Cardiothoracic Anesthesiology

Division of Clinical and Translational Research

School of Medicine

Washington University in St. Louis

Matthew Schuelke

Medical Informaticist III

Institute for Informatics Center for Applied Clinical Informatics

School of Medicine

Washington University in St. Louis

Mei Wang

PhD Student

Division of Biology & Biomedical Sciences

Division of Public Health Sciences

Department of Surgery

School of Medicine

Washington University in St. Louis

Ben Warner

PhD Student

McKelvey School of Engineering

AI for Health Institute

Washington University in St. Louis

The inaugural I2DB Datathon is a unique opportunity for teams to engage in a spirited competition, leveraging synthetic medical data, to build accurate risk prediction models. Participants receive a comprehensive training dataset and the chance to present their work to experts in the field at the annual I2DB Symposium. Winners in first, second, and third place are duly rewarded with cash prizes. Join us in this first-ever competition to showcase your talent and contribute to the advancement of medical data analysis.

Participants include (team name followed by team captain and fellow team members):

BDM_Team2: Xuping Luo, Ruby Gao, Zhen Luo, and Purva Patel.

Dan DI2: Dan Maranan.

The AI prediction pawtners: Mei Wang, Yi-Hsuan Shih, Yuan-Hung Kuan, Su-Hsin Chang, and Jr-Shin Li.

BDM_T4: Jingyi Zhang, Wenjing Lin, Zirui Chen, and Trevor Zimmerman.

LifeSavers Analytics: Gauri Hemant Darekar, Yian Liu, Xuanwei Li, and Qingqing Li.

The Predictablizers: Min Zhao, Hao Fan, and Weiwei Ma.

Sandhya: Sandhya Tripathi and Joshin Kumar.

DataGeeks: Zheng Xu, Zining Yang, Yueshui Lyu, and Preeti Sharma.

Dude, Where’s My Model?: Jason Dude, Keith Lohse, Tanner Reece.

Python Pandemic Predictors: Ashish Vaidyanathan, Jeevan Sivamohan, Ben Dizdar, Zachary Bertino, and Jacob Haralson.

Student: Matthew Schuelke.

Team 156: Jeff Zhang.

Charles (Chuck) Goss, PhD

Associate Director, Center for Biostatistics and Data Science

Assistant Professor of Biostatistics

Center for Biostatistics and Data Science

School of Medicine

Washington University in St. Louis

Mackenzie Hofford, MD

Associate Chief Research Information Officer

Assistant Professor of Medicine Division of General Medicine

Center for Applied Clinical Informatics

School of Medicine

Washington University in St. Louis

Jinghua Ou, PhD

Program Officer, Methodological Research

Patient-Centered Outcomes Research Institute (PCORI)

Linying Zhang, PhD

Assistant Professor of Biostatistics

Center for Biostatistics and Data Science

School of Medicine

Washington University in St. Louis

Phillip V Asaro, MD

Director, Emergency Medicine Informatics, Applications & Analytics

Assistant Professor, Emergency Medicine

School of Medicine

Washington University in St. Louis

Graham Bachman

Bioinformaticist

McDonnell Genome Institute

School of Medicine

Washington University in St. Louis

Laura R. Baratta

Medical Scientist Training Program Student

Division of Biology and Biomedical Sciences

School of Medicine

Washington University in St. Louis

Patrick Donohue

MD/MS Biomedical Informatics Student

School of Medicine

Washington University in St. Louis

Joshua Denzer, PhD

BI Solution Developer

Business Intelligence & Data Solutions

BJC Healthcare

Sung Min Ha

PhD Candidate, Imaging Science

Washington University in St. Louis

School of Medicine

Washington University in St. Louis

Ethan Hillis

Medical Informaticist II

Washington University in St. Louis

School of Medicine

Washington University in St. Louis

Matthew Schuelke

Medical Informaticist III

Institute for Informatics Center for Applied Clinical Informatics

School of Medicine

Washington University in St. Louis

Levi Kaster

Bioinformatics Research Assistant

Institute for Informatics, Data Science, and Biostatistics

School of Medicine

Washington University in St. Louis

Seunghwan (Nigel) Kim

PhD Candidate, Biomedical Informatics and Data Science

Division of Biology and Biomedical Sciences

School of Medicine

Washington University in St. Louis

Kendall Kiser, MD MS

Resident Physician

Department of Radiation Oncology

School of Medicine

Washington University in St. Louis

Yuan-Hung, Kuan

PhD Candidate, Electrical and Systems Engineering

McKelvey School of Engineering

Washington University in St. Louis

Sunny Lou, MD, PhD

Instructor in Anesthesiology

Division of Adult Cardiothoracic Anesthesiology

Division of Clinical and Translational Research

School of Medicine

Washington University in St. Louis

Brianna Munnich

Research Technician

Department of Pathology and Immunology

School of Medicine

Washington University in St. Louis

Inez Oh

Senior Scientist

Institute for Informatics, Data Science, and Biostatistics

School of Medicine

Washington University in St. Louis

James R. Rudloff, MD

Clinical Fellow, Pediatric Emergency Medicine

School of Medicine

Washington University in St. Louis

Yi-Hsuan Shih

PhD Candidate, Electrical and Systems Engineering

McKelvey School of Engineering

Washington University in St. Louis

Sandhya Tripathi, PhD

Postdoctoral Research Associate

Department of Anesthesiology

School of Medicine

Washington University in St. Louis

Ashish Vaidyanathan

Undergraduate Research Assistant, Biomedical Engineering

McKelvey School of Engineering

Washington University in St. Louis

Mei Wang

PhD Student

Division of Biology & Biomedical Sciences

Division of Public Health Sciences

Department of Surgery

School of Medicine

Washington University in St. Louis

Ben Warner

PhD Student

McKelvey School of Engineering

AI for Health Institute

Washington University in St. Louis

Pan Xiao

PhD Student, Imaging Science

Mallinckrodt Institute of Radiology

School of Medicine

Washington University in St. Louis"
https://towardsdatascience.com/pushing-boundaries-integrating-foundational-models-e-g-556cfb6d0632,"Pushing RL Boundaries: Integrating Foundational Models, e.g. LLMs and VLMs, into Reinforcement Learning","Authors: Elahe Aghapour, Salar Rahili

Overview:

With the rise of the transformer architecture and high-throughput compute, training foundational models has turned into a hot topic recently. This has led to promising efforts to either integrate or train foundational models to enhance the capabilities of reinforcement learning (RL) algorithms, signaling an exciting direction for the field. Here, we’re discussing how foundational models can give reinforcement learning a major boost.

Before diving into the latest research on how foundational models can give reinforcement learning a major boost, let’s engage in a brainstorming session. Our goal is to pinpoint areas where pre-trained foundational models, particularly Large Language Models (LLMs) or Vision-Language Models (VLMs), could assist us, or how we might train a foundational model from scratch. A useful approach is to examine each element of the reinforcement learning training loop individually, to identify where there might be room for improvement:

1- Environment: Given that pre-trained foundational models understand the causal relationships between events, they can be utilized to forecast environmental changes resulting from current actions. Although this concept is intriguing, we’re not yet aware of any specific studies that focus on it. There are two primary reasons holding us back from exploring this idea further for now.

While the reinforcement learning training process demands highly accurate predictions for the next step observations, pre-trained LLMs/VLMs haven’t been directly trained on datasets that enable such precise forecasting and thus fall short in this aspect. It’s important to note, as we highlighted in our previous post, that a high-level planner, particularly one used in lifelong learning scenarios, could effectively incorporate a foundational model.

Latency in environment steps is a critical factor that can constrain the RL algorithm, especially when working within a fixed budget for training steps. The presence of a very large model that introduces significant latency can be quite restrictive. Note that while it might be challenging, distillation into a smaller network can be a solution here.

2- State (LLM/VLM Based State Generator): While experts often use the terms observation and state interchangeably, there are distinctions between them. A state is a comprehensive representation of the environment, while an observation may only provide partial information. In the standard RL framework, we don’t often discuss the specific transformations that extract and merge useful features from observations, past actions, and any internal knowledge of the environment to produce “state”, the policy input. Such a transformation could be significantly enhanced by employing LLMs/VLMs, which allow us to infuse the “state” with broader knowledge of the world, physics, and history (refer to Fig. 1, highlighted in pink).

3- Policy (Foundational Policy Model): Integrating foundational models into the policy, the central decision-making component in RL, can be highly beneficial. Although employing such models to generate high-level plans has proven successful, transforming the state into low-level actions has challenges we’ll delve into later. Fortunately, there has been some promising research in this area recently.

4- Reward (LLM/VLM Based Reward Generator): Leveraging foundational models to more accurately assess chosen actions within a trajectory has been a primary focus among researchers. This comes as no surprise, given that rewards have traditionally served as the communication channel between humans and agents, setting goals and guiding the agent towards what is desired.

Pre-trained foundational models come with a deep knowledge of the world, and injecting this kind of understanding into our decision-making processes can make those decisions more in tune with human desires and more likely to succeed. Moreover, using foundational models to evaluate the agent’s actions can quickly trim down the search space and equip the agent with a head start in understanding, as opposed to starting from scratch.

Pre-trained foundational models have been trained on internet-scale data generated mostly by humans, which has enabled them to understand worlds similarly to humans. This makes it possible to use foundational models as cost-effective annotators. They can generate labels or assess trajectories or rollouts on a large scale.

1- Foundational models in reward

It is challenging to use foundational models to generate low level control actions as low level actions are highly dependent on the setting of the agent and are underrepresented in foundational models’ training dataset. Hence, the foundation model application is generally focused on high level plans rather than low level actions. Reward bridges the gap between high-level planner and low level actions where foundation models can be used. Researchers have adopted various methodologies integrating foundation models for reward assignment. However, the core principle revolves around employing a VLM/LLM to effectively track the progress towards a subgoal or task.

1.a Assigning reward values based on similarity

Consider the reward value as a signal that indicates whether the agent’s previous action was beneficial in moving towards the goal. A sensible method involves evaluating how closely the previous action aligns with the current objective. To put this approach into practice, as can be seen in Fig. 2, it’s essential to:

- Generate meaningful embeddings of these actions, which can be done through images, videos, or text descriptions of the most recent observation.

- Generate meaningful representations of the current objective.

- Assess the similarity between these representations.

Let’s explore the specific mechanics behind the leading research in this area.

Dense and well-shaped reward functions enhance the stability and training speed of the RL agent. Intrinsic rewards address this challenge by rewarding the agent for novel states’ exploration. However, in large environments where most of the unseen states are irrelevant to the downstream task, this approach becomes less effective. ELLM uses background knowledge of LLM to shape the exploration. It queries LLM to generate a list of possible goals/subgoals given a list of the agent’s available actions and a text description of the agent current observation, generated by a state captioner. Then, at each time step, the reward is computed by the semantic similarity, cosine similarity, between the LLM generated goal and the description of the agent’s transition.

LiFT has a similar framework but also leverages CLIP4Clip-style VLMs for reward assignment. CLIP4Clip is pre-trained to align videos and corresponding language descriptions through contrastive learning. In LiFT, the agent is rewarded based on the alignment score, cosine similarity, between the task instructions and videos of the agent’s corresponding behavior, both encoded by CLIP4CLIP.

UAFM has a similar framework where the main focus is on robotic manipulation tasks, e.g., stacking a set of objects. For reward assignment, they measure the similarity between the agent state image and the task description, both embedded by CLIP. They finetune CLIP on a small amount of data from the simulated stacking domain to be more aligned in this use case.

1.b Assigning rewards through reasoning on auxiliary tasks:

In scenarios where the foundational model has the proper understanding of the environment, it becomes feasible to directly pass the observations within a trajectory to the model, LLM/VLM. This evaluation can be done either through straightforward QA sessions based on the observations or by verifying the model’s capability in predicting the goal only by looking at the observation trajectory.

Read and Reward integrates the environment’s instruction manual into reward generation through two key components, as can be seen in Fig. 3:

QA extraction module: it creates a summary of game objectives and features. This LLM-based module, RoBERTa-large, takes in the game manual and a question, and extracts the corresponding answer from the text. Questions are focused on the game objective, and agent-object interaction, identified by their significance using TF-IDF. For each critical object, a question as: “What happens when the player hits a <object>?” is added to the question set. A summary is then formed with the concatenation of all non-empty question-answer pairs.

Reasoning module: During gameplay, a rule-based algorithm detects “hit” events. Following each “hit” event, the LLM based reasoning module is queried with the summary of the environment and a question: “Should you hit a <object of interaction> if you want to win?” where the possible answer is limited to {yes, no}. A “yes” response adds a positive reward, while “no” leads to a negative reward.

EAGER introduces a unique method for creating intrinsic rewards through a specially designed auxiliary task. This approach presents a novel concept where the auxiliary task involves predicting the goal based on the current observation. If the model predicts accurately, this indicates a strong alignment with the intended goal, and thus, a larger intrinsic reward is given based on the prediction confidence level. To achieve this goal, To accomplish this, two modules are employed:

Question Generation (QG): This component works by masking all nouns and adjectives in the detailed objective provided by the user.

Question Answering (QA): This is a model trained in a supervised manner, which takes the observation, question masks, and actions, and predicts the masked tokens.

(P.S. Although this work does not utilize a foundational model, we’ve included it here due to its intriguing approach, which can be easily adapted to any pre-trained LLM)

1.c Generating reward function code

Up to this point, we’ve discussed generating reward values directly for the reinforcement learning algorithms. However, running a large model at every step of the RL loop can significantly slow down the speed of both training and inference. To bypass this bottleneck, one strategy involves utilizing our foundational model to generate the code for the reward function. This allows for the direct generation of reward values at each step, streamlining the process.

For the code generation schema to work effectively, two key components are required:

1- A code generator, LLM, which receives a detailed prompt containing all the necessary information to craft the code.

2- A refinement process that evaluates and enhances the code in collaboration with the code generator.

Let’s look at the key contributions for generating reward code:

R2R2S generates reward function code through two main components:

LLM based motion descriptor: This module uses a pre-defined template to describe robot movements, and leverages Large Language Models (LLMs) to understand the motion. The Motion Descriptor fills in the template, replacing placeholders e.g. “Destination Point Coordinate” with specific details, to describe the desired robot motion within a pre-defined template.

LLM based reward coder: this component generates the reward function by processing a prompt containing: a motion description, a list of functions with their description that LLM can use to generate the reward function code, an example code of how the response should look like, and constraints and rules the reward function must follow.

Text2Reward develops a method to generate dense reward functions as an executable code within iterative refinement. Given the subgoal of the task, it has two key components:

LLM-based reward coder: generates reward function code. Its prompt consists of: an abstract of observation and available actions, a compact pythonic style environment to represent the configuration of the objects, robot, and callable functions; a background knowledge for reward function design (e.g. “reward function for task X typically includes a term for the distance between object x and y”), and a few-shot examples. They assume access to a pool of instruction, and reward function pairs that top k similar instructions are retrieved as few-shot examples.

LLM-Based Refinement: once the reward code is generated, the code is executed to identify the syntax errors and runtime errors. These feedbacks are integrated into subsequent prompts to generate more refined reward functions. Additionally, human feedback is requested based on a task execution video by the current policy.

Auto MC-Reward has a similar algorithm to Text2Reward, to generate the reward function code, see Fig. 4. The main difference is in the refinement stage where it has two modules, both LLMs:

LLM-Based Reward Critic: It evaluates the code and provides feedback on whether the code is self-consistent and free of syntax and semantic errors.

LLM-Based Trajectory Analyser: It reviews the historical information of the interaction between the trained agent and the environment and uses it to guide the modifications of the reward function.

EUREKA generates reward code without the need for task-specific prompting, predefined reward templates, or predefined few-shot examples. To achieve this goal, it has two stages:

LLM-based code generation: The raw environment code, the task, generic reward design and formatting tips are fed to the LLM as context and LLM returns the executable reward code with a list of its components.

Evolutionary search and refinement: At each iteration, EUREKA queries the LLM to generate several i.i.d reward functions. Training an agent with executable reward functions provides feedback on how well the agent is performing. For a detailed and focused analysis of the rewards, the feedback also includes scalar values for each component of the reward function. The LLM takes top-performing reward code along with this detailed feedback to mutate the reward code in-context. In each subsequent iteration, the LLM uses the top reward code as a reference to generate K more i.i.d reward codes. This iterative optimization continues until a specified number of iterations has been reached.

Within these two steps, EUREKA is able to generate reward functions that outperform expert human-engineered rewards without any task specific templates.

1.d. Train a reward model based on preferences (RLAIF)

An alternative method is to use a foundational model to generate data for training a reward function model. The significant successes of Reinforcement Learning with Human Feedback (RLHF) have recently drawn increased attention towards employing trained reward functions on a larger scale. The heart of such algorithms is the use of a preference dataset to train a reward model which can subsequently be integrated into reinforcement learning algorithms. Given the high cost associated with generating preference data (e.g., action A is preferable to action B) through human feedback, there’s growing interest in constructing this dataset by obtaining feedback from an AI agent, i.e. VLM/LLM. Training a reward function, using AI-generated data and integrating it within a reinforcement learning algorithm, is known as Reinforcement Learning with AI Feedback (RLAIF).

MOTIF requires access to a passive dataset of observations with sufficient coverage. Initially, LLM is queried with a summary of desired behaviors within the environment and a text description of two randomly sampled observations. It then generates the preference, selecting between 1, 2, or 0 (indicating no preference), as seen in Fig. 5. This process constructs a dataset of preferences between observation pairs. Subsequently, this dataset is used to train a reward model employing preference based RL techniques.

2- Foundation models as Policy

Achieving the capability to train a foundational policy that not only excels in tasks previously encountered but also possesses the ability to reason about and adapt to new tasks using past learning, is an ambition within the RL community. Such a policy would ideally generalize from past experiences to tackle novel situations and, through environmental feedback, achieve goals previously unseen with human-like adaptability.

However, several challenges stand in the way of training such agents. Among these challenges are:

The necessity of managing a very large model, which introduces significant latency into the decision-making process for low-level control actions.

The requirement to collect a vast amount of interaction data across a wide array of tasks to enable effective learning.

Additionally, the process of training a very large network from scratch using RL introduces extra complexities. This is because backpropagation efficiency inherently is weaker in RL compared to supervised training methods .

Up to now, it’s mostly been teams with substantial resources and top-notch setups who’ve really pushed the envelope in this domain.

AdA paved the way for training an RL foundation model within the X.Land 2.0 3D environment. This model achieves human time-scale adaptation on held-out test tasks without any further training. The model’s success is founded on three ingredients:

The core of the AdA’s learning mechanism is a Transformer-XL architecture from 23 to 265 million parameters, employed alongside the Muesli RL algorithm. Transformer-XL takes in a trajectory of observations, actions, and rewards from time t to T and outputs a sequence of hidden states for each time step. The hidden state is utilized to predict reward, value, and action distribution π. The combination of both long-term and short-term memory is critical for fast adaptation. Long-term memory is achieved through slow gradient updates, whereas short-term memory can be captured within the context length of the transformer. This unique combination allows the model to preserve knowledge across multiple task attempts by retaining memory across trials, even though the environment resets between trials.

The model benefits from meta-RL training across 1⁰⁴⁰ different partially observable Markov decision processes (POMDPs) tasks. Since transformers are meta-learners, no additional meta step is required.

Given the size and diversity of the task pool, many tasks will either be too easy or too hard to generate a good training signal. To tackle this, they used an automated curriculum to prioritize tasks that are within its capability frontier.

RT-2 introduces a method to co-finetune a VLM on both robotic trajectory data and vision-language tasks, resulting in a policy model called RT-2. To enable vision-language models to generate low-level actions, actions are discretized into 256 bins and represented as language tokens.

By representing actions as language tokens, RT-2 can directly utilize pre-existing VLM architectures without requiring substantial modifications. Hence, VLM input includes robot camera image and textual task description formatted similarly to Vision Question Answering tasks and the output is a series of language tokens that represent the robot’s low-level actions; see Fig. 6.

They noticed that co-finetuning on both types of data with the original web data leads to more generalizable policies. The co-finetuning process equips RT-2 with the ability to understand and execute commands that were not explicitly present in its training data, showcasing remarkable adaptability. This approach enabled them to leverage internet-scale pretraining of VLM to generalize to novel tasks through semantic reasoning.

3- Foundation Models as State Representation

In RL, a policy’s understanding of the environment at any given moment comes from its “state” which is essentially how it perceives its surroundings. Looking at the RL block diagram, a reasonable module to inject world knowledge into is the state. If we can enrich observations with general knowledge useful for completing tasks, the policy can pick up new tasks much faster compared to RL agents that begin learning from scratch.

PR2L introduces a novel approach to inject the background knowledge of VLMs from internet scale data into RL.PR2L employs generative VLMs which generate language in response to an image and a text input. As VLMs are proficient in understanding and responding to visual and textual inputs, they can provide a rich source of semantic features from observations to be linked to actions.

PR2L, queries a VLM with a task-relevant prompt for each visual observation received by the agent, and receives both the generated textual response and the model’s intermediate representations. They discard the text and use some or all of the models intermediate representation generated for both the visual and text input and the VLM’s generated textual response as “promptable representations”. Due to the variable size of these representations, PR2L incorporates an encoder-decoder Transformer layer to embed all the information embedded in promptable representations into a fixed size embedding. This embedding, combined with any available non-visual observation data, is then provided to the policy network, representing the state of the agent. This innovative integration allows the RL agent to leverage the rich semantic understanding and background knowledge of VLMs, facilitating more rapid and informed learning of tasks.

Also Read Our Previous Post: Towards AGI: LLMs and Foundational Models’ Roles in the Lifelong Learning Revolution

References:"
https://towardsdatascience.com/leveraging-python-pint-units-handler-package-part-1-716a13e96b59,Leveraging Python Pint Units Handler Package — Part 1,"If you work in the engineering or science fields, or even if you are someone involved in supply chain operations, environmental sustainability, or whatever field that uses physical quantities like time, mass, and length, you have faced situations where you need to operate and manipulate physical quantities programmatically and on the fly. As a data practitioner or software developer working with Python, you probably have come up with a solution like creating dictionary-like lookup tables to convert between units (e.g., kg to lb) or perform operations containing different physical dimensions (e.g., volume and time). One of the features of the ever-growing Python ecosystem is the different kinds of packages available to do whatever you have in mind. In this post, I will introduce Pint, a Python package to programmatically handle units in your data science or software project 🍻. I will organize this post so that you understand not only the key elements that make up Pint but also how to seamlessly integrate and extend them for your project 🧩.

Pint Quantity

The Pint package was developed based on an OOP paradigm. It uses objects to set up an arsenal to operate physical quantities “pythonically”. The Quantity object is one important element that allows us to store the magnitude and unit of a physical quantity. The code snippet below shows how to declare a Quantity instance and how to access its magnitude, unit, and dimensionality.

from pint import Quantity

medium_q = Quantity(""2 kg"") # You can also use Quantity((2, ""kg""))

print(""Magnitude: "", medium_q.m)

print(""Magnitude type: "", type(medium_q.m))

print(""Dimensionality: "", medium_q.dimensionality)

print(""Dimensionality type: "", type(medium_q.dimensionality))

print(""Unit: "", medium_q.u)

print(""Unit type: "", type(medium_q.u))

Output:

Magnitude: 2

Magnitude type: <class 'int'>

Dimensionality: [mass]

Dimensionality type: <class 'pint.util.UnitsContainer'>

Unit: kilogram

Unit type: <class 'pint.Unit'>

You can see that the magnitude data type is an integer (it could be a float), i.e., a primitive, but dimensionality and unit are…"
https://towardsdatascience.com/advanced-retriever-techniques-to-improve-your-rags-1fac2b86dd61,Advanced Retriever Techniques to Improve Your RAGs,"Master Advanced Information Retrieval: Cutting-edge Techniques to Optimize the Selection of Relevant Documents with Langchain to Create Excellent RAGs

Damian Gil

·

Follow

Published in

Towards Data Science

·

18 min read

·

1 day ago

--

Content Table

· Introduction

· Vectore Store Creation

· Method: Naive Retriever

· Method: Parent Document Retriever

· Method: Self Query Retriever ∘ Query Constructor

∘ Query Translater

· Method: Contextual Compression Retriever (Reranking)

· Conclusion

Introduction

Let’s briefly remember what the 3 acronyms that make up the word RAG mean:

Retrieval: The main objective of a RAG is to collect the most relevant documents/chunks regarding the query.

Augmented: Create a well-structured prompt so that when the call is made to the LLM, it knows perfectly what its purpose is, what the context is and how it should respond.

Generation: This is where the LLM comes into play. When the model is given good context (provided by the “Retrieval” step) and has clear instructions (provided by the “Augmented” step), it will generate high-value responses for the user.

As we can see, the generation of the response to a user’s query (If we apply a RAG for the purpose of Q&A), depends directly on how well we have built the “Augmented” and especially the “Retrieval”.

In this article we are going to focus exclusively on the “Retrieval” part. In this important process of returning the most relevant documents, the concept of vector store appears.

To create these retrievals, we will use the Langchain library.

The vectore store is nothing more than a vector database, which stores documents in vector format. This vector representation comes from the use of transformers. I’m not saying something you don’t know at the moment.

It is clear that the more robust and complete this vector store is, the better retriever we can run. We already know that the creation of this database is an art in itself. Depending on the size of the chunks or the embedding model we use, our RAG will be better or worse.

I make a clarification here:

In this post we are NOT going to discuss how to create this vector store.

In this post we are going to discuss some of the techniques used to retrieve relevant documents.

Since a picture is worth a thousand words, I suggest you take a look at the following:

Therefore, I reiterate that in this post we are going to deeply study one of the many important steps in creating a good RAG tool. The “Retrieve” step is key since it directly improves the context that the LLM has when generating a response.

The methods we will study are:

Naive Retriever

Parent Document Retriever

Self-Query Retriever

Contextual Compression Retriever (Reranking)

You can find the project with the notebooks here. And you can also take a look at my github:

damiangilgonzalez1995 - Overview

Passionate about data, I transitioned from physics to data science. Worked at Telefonica, HP, and now CTO at…

github.com

Vectore Store Creation

To expose these methods, a practical use case will be carried out to improve the explanation. Therefore, we are going to create a RAG about reviews of the John Wick movies.

So that the reader can follow each step of this post, they can access the repository that I have created. In it you will find the code for each of the methods, in addition to the documents used to create the vector store. The jupyter notebook in charge of this task can be found in the git repository, and is the file called “0_create_vectore_db.ipynb”.

In relation to the data source of our RAG, there are 4 csv’s each corresponding to the reviews obtained for each of the films in the John Wick saga. The files contain the following information:

As you can see, the “Review” field will be the target of our retriever. The other fields being important to store as metadata:

Movie_Title

Review_Date

Review_Title

Review_Url

Author

Rating

To read and convert each row of our files into the “Document” format, we execute the following code:

from langchain_community.document_loaders.csv_loader import CSVLoader

from datetime import datetime, timedelta

documents = []

for i in range(1, 4):

loader = CSVLoader(

encoding=""utf8"",

file_path=f""data/john_wick_{i}.csv"",

metadata_columns=[""Review_Date"", ""Review_Title"", ""Review_Url"", ""Author"", ""Rating""]

)

movie_docs = loader.load()

for doc in movie_docs:

# We add metadate about the number of the movi

doc.metadata[""Movie_Title""] = f""John Wick {i}""

# convert ""Rating"" to an `int`, if no rating is provided - None

doc.metadata[""Rating""] = int(doc.metadata[""Rating""]) if doc.metadata[""Rating""] else 5

documents.extend(movie_docs)

We already have our documents in “Document” format:

print(documents[0])

Document(page_content="": 0\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity."", metadata={'source': 'data/john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2024, 4, 8, 11, 49, 47, 92560)})

We only have to create a vector database (Vectore Store) locally. For this, I have used Chroma. Also keep in mind that it is necessary to use an embedding model, which will transform our documents into vector format for storage. Everything mentioned can be seen in the following piece of code:

from langchain_community.vectorstores import Chroma

from langchain_openai import OpenAIEmbeddings

import os

from dotenv import load_dotenv

load_dotenv()

os.environ[""OPENAI_API_KEY""] = os.getenv('OPENAI_KEY')

embeddings = OpenAIEmbeddings(model=""text-embedding-3-small"")

db = Chroma.from_documents(documents=documents, embedding=embeddings, collection_name=""doc_jonhWick"", persist_directory=""./jonhWick_db"")

This will create a database on our premises called “JonhWick_db”. This will be the database that our RAG will use and from where our retriever will obtain the most relevant documents regarding the user’s queries.

Now is the time to present the different methods for creating a retriever.

Method: Naive Retriever

Code in 1_naive_retriever.ipynb file.

This method is the simplest, in fact its name indicates it. We use this adjective to identify this method for the simple reason that when entering the query into our database, we hope (naively) that it will return the most relevant documents/chunks.

Basically what happens is that we encode the user query with the same transformer with which we created the vector store. Once its vector representation is obtained, we calculate the similarity by calculating the cosine, the distance, etc.

And we collect the top K documents closest/similar to the query.

The flow of this type of retriever can be seen in the following image:

Keeping the scheme in mind, let’s see how all this looks in the code. We read the database:

from langchain_community.vectorstores import Chroma

from langchain_openai import OpenAIEmbeddings

import os

from dotenv import load_dotenv

load_dotenv()

os.environ[""OPENAI_API_KEY""] = os.getenv('OPENAI_KEY')

embeddings = OpenAIEmbeddings(model=""text-embedding-3-small"")

vectordb= Chroma(persist_directory=""./jonhWick_db"",

embedding_function=embeddings,

collection_name=""doc_jonhWick"")pyth

And we create our retriever. We can configure the similarity calculation method, in addition to other parameters.

Retriever

# Specifying top k

naive_retriever = vectordb.as_retriever(search_kwargs={ ""k"" : 10})

# Similarity score threshold retrieval

# naive_retriever = db.as_retriever(search_kwargs={""score_threshold"": 0.8}, search_type=""similarity_score_threshold"")

# Maximum marginal relevance retrieval

# naive_retriever = db.as_retriever(search_type=""mmr"")

Actually, we have already created our “Naive Retriever”, but to see how it works, we will create the complete RAG that we remember is composed of the following components:

R (Retrieval): Done

A (Augmented): Not yet

G (Generation): Not yet

Augmented & Generation

from langchain_core.prompts import ChatPromptTemplate

from langchain_openai import ChatOpenAI

# Augmented

TEMPLATE = """"""\

You are happy assistant. Use the context provided below to answer the question.

If you do not know the answer, or are unsure, say you don't know.

Query:

{question}

Context:

{context}

""""""

rag_prompt = ChatPromptTemplate.from_template(TEMPLATE)

# Generation

chat_model = ChatOpenAI()

We already have the 3 components of our RAG. All that remains is to assemble them, and for this we will use the langchain chains to create a RAG.

I don’t know if you know the language created by langchain for creating chains in a more efficient way. This language is known as LCEL (LangChain Expression Language). If you are new to this way of creating chains in langchain, I leave you a very good tutorial here:

Finally, we create our RAG using Langchain’s own chain creation language (LCEL):

from langchain_core.runnables import RunnablePassthrough, RunnableParallel

from operator import itemgetter

from langchain_core.output_parsers import StrOutputParser

setup_and_retrieval = RunnableParallel({""question"": RunnablePassthrough(), ""context"": naive_retriever })

output_parser = StrOutputParser()

naive_retrieval_chain = setup_and_retrieval

| rag_prompt

| chat_model

| output_parser

naive_retrieval_chain.invoke( ""Did people generally like John Wick?"")

# response: 'Yes, people generally liked John Wick.'

This is the simplest way to create a chain for a RAG. In the Jupyter notebook you can find the same chain but more robust. Since I don’t want us to get lost on this topic now, I have only shown the simplest form. Also so that we understand what is happening in the code above, I have created this very clarifying diagram:

Great, we’re done creating our Naive RAG. Let’s move on to the next method.

Method: Parent Document Retriever

Code in 2_parent_document_retriever.ipynb file.

Imagine that we have created a RAG to recognize possible diseases by introducing some of their symptoms in the consultation. In the event that we have a Naive RAG, we may collect a series of possible diseases that only coincide in one or two symptoms, leaving our tool in a bit of a bad place.

This is an ideal case to use Parent Doc Retriever. And the type of technique consists of cutting large chunks (parent chunk) into even smaller pieces (child chunk). By having small chunks, the information they contain is more concentrated and therefore, its informative value is not diluted between paragraphs of text.

There is a small problem in all this:

If we want to be precise in searching for the most relevant documents, we need to break our documents into small chunks.

But it is also very important to provide good context to the LLM, which is achieved by providing larger chunks.

What has been said can be seen in the following image:

It seems that there is no way out of the problem, since when we increase the precision, the context is reduced, and vice versa. This is when this method appears that will solve our lives.

The main idea is to further chop the large chunks (Parent chunks/documents) into smaller chunks (Child Chunks/documents). Once this is done, perform the search for the most relevant top K documents with the child chunks, and return the parents chunks to which the top K child document belongs.

We already have the main idea, now let’s get it down to earth. The best way to explain it is step by step:

Obtain the documents and create the large chunks (Parent chunks)

Perform a split of each of the parent chunks for the growth of the child chunks.

Save the child chunks (Vector Representation) in the Vector Store.

Save the parent chunks in memory (We do not need to create their vector representation).

What has been said can be seen in the following image:

This may seem very complex to create, since we have to create a new database with the small chunks, save the parent chunks in memory. Additionally, know which parent chunk each child chunk belongs to. Thank goodness Langchain exists and the way to build it is super simple.

Surely you have come to the conclusion that it is necessary to create a new vector store for this method. Furthermore, in the case of reviews of the John Wick movies, such as the data source with CSV files, it is not necessary to perform the first split (parent chunks). This is because we can consider each row of our csv files to be a chunk in itself.

Overall, let’s visualize the following image that reflects how this method works:

Going to code it is represented as follows:

from langchain.retrievers import ParentDocumentRetriever

from langchain.storage import InMemoryStore

from langchain_text_splitters import RecursiveCharacterTextSplitter

from langchain_openai import OpenAIEmbeddings

from langchain_community.vectorstores import Chroma

# documents = Read csv files. Check jupyter notebook for more details

parent_docs = documents

# Embedding Model

embeddings = OpenAIEmbeddings(model=""text-embedding-3-small"")

# Splitters

child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)

# We don't need a parent splitter because the data cames from CSV file, and each row is a parent doc.

# parent_splitter = RecursiveCharacterTextSplitter(chunk_size=800)

# Stores

store = InMemoryStore()

vectorstore = Chroma(embedding_function=embeddings, collection_name=""fullDoc"", persist_directory=""./JohnWick_db_parentsRD"")

parent_document_retriever = ParentDocumentRetriever(

vectorstore=vectorstore,

docstore=store,

child_splitter=child_splitter,

# parent_splitter =parent_splitter

)

Something intuitive about what happens here is that the number of chunks in the vector store (number of child chunks) should be much higher than the number of documents stored in memory (parent chunks). With the following code we can check it:

print(f""Number of parent chunks is: {len(list(store.yield_keys()))}"")

print(f""Number of child chunks is: {len(parent_document_retriever.vectorstore.get()['ids'])}"")

'''

Number of parent chunks is: 75

Number of child chunks is: 3701

'''

Great, we would already have our Parent Document Retriever, we just need to create our RAG based on this retriever and that would be it. It would be done exactly the same as in the previous method. I attach the code for creating the chain in langchain. To see more details, take a look at the jupyter notebook.

setup_and_retrieval = RunnableParallel({""question"": RunnablePassthrough(), ""context"": parent_document_retriever })

output_parser = StrOutputParser()

parent_retrieval_chain = setup_and_retrieval | rag_prompt | chat_model | output_parser

Note that it is exactly the same as in the previous case, only with the small difference that in the “setup_and_retrieval” variable, we configure that we want to use our “parent_document_retriever”, instead of the “naive_retriever”.

Method: Self Query Retriever

Code in 3_self_query_retriever.ipynb file.

This is possibly one of the most optimal methods to improve the efficiency of our retriever.

Its main feature is that it is capable of performing searches in the vector store, applying filters based on the metadata.

We know that when we apply a “Naive retrieval”, we are calculating the similarity of all the chunks of the vector database with the query. The more chunks the vector store has, the more similarity calculations will have to be done. Now, imagine being able to do a prior filter based on the metadata, and after selecting the chunks that meet the conditions imposed in relation to the metadata, calculate similarities. This can drastically reduce computational and time cost.

Let’s look at a use case to fully understand when to apply this type of retreival.

Let’s imagine that we have stored in our vector database a large number of experiences and leisure offers (Ex: surf classes, zip line, gastronomic route, etc.). The description of the experience is what we have encoded, using our embedding model. Additionally, each offer has 3 key values or metadata: Date, price and place.

Let’s imagine that a user is looking for an experience of this style: An experience in nature, that is for the whole family and safe. Furthermore, the price must be less than $50 and the place is California.

Something is clear here

WE DO NOT WANT YOU TO RETURN US ACTIVITY/EXPERIENCES THAT DO NOT MEET THE PRICE OR PLACE THAT THE USER REQUESTS.

Therefore, it does not make sense to calculate similarities with chunks/experiences that do not comply with the metadata filter.

This case is ideal for applying Self Query Retriever. What this type of retriever allows us is to perform a first filter through the metadata, and then perform the similarity calculation between the chunks that meet the metadata requirements and the user input.

This technique can be summarized in two very specific steps:

Query Constructor

Query Translater

Query Constructor

The objective of the step called “Query Constructor” is to create the appropriate query and filters according to the user input.

Who is in charge of applying the corresponding filters and how do you know what they are?

For this we are going to use an LLM. This LLM will have to be able to decide which filters to apply and when. We will also have to explain beforehand what the metadata is and what each of them means. In short, the prompt must contain 3 key points:

Context: Personality, how you should act, output format, etc.

Metadata: Information about available metadata.

Query: The user’s query/input/question.

The output generated by the LLM cannot be directly entered into the database. Therefore, the so-called “Query Translater” is needed.

Query Translater

This is a module in charge of translating the output of the LLM (Query Constructor) into the appropriate format to perform the query. Depending on the vector database you use, you will have to use one or the other. In my case I used Chroma db, therefore, I need a translator focused on this database. Luckily, Langchain has specific database translators for almost all of them.

As you may have already noticed, I am a big fan of diagrams. Let’s look at the following which provides quite a bit of clarity to the matter:

Regarding the previous image, we see that everything begins with the user’s query. We create the prompt that contains the 3 key fields and is introduced to the LLM that generates a response with two key fields: “Query” and “Filter”. This is fed into the query translator which translates these two fields into the correct format needed by Chroma DB. Performs the query and returns the most relevant documents based on the user’s initial question.

Something to emphasize is that the query entered by the user does not have to be the same as the one entered into the database. In the diagram shown, it can be seen that the LLM, taking into account the available metadata and the user’s question, detects that it can create a filter with the “Rating” metadata. It also creates a new query based on the user’s query.

Let’s look at all this in code. As I have explained, it is very important to provide the LLM with a detailed description of the metadata available in the vector store. This translates into the following piece of code:

from langchain.chains.query_constructor.base import AttributeInfo

from langchain.retrievers.self_query.base import SelfQueryRetriever

from langchain_openai import ChatOpenAI

from langchain.retrievers.self_query.chroma import ChromaTranslator

metadata_field_info = [

AttributeInfo(

name=""Movie_Title"",

description=""The title of the movie"",

type=""string"",

),

AttributeInfo(

name=""Review_Date"",

description=""The date of the review"",

type=""string"",

),

AttributeInfo(

name=""Review_Title"",

description=""The title of the review"",

type=""string"",

),

AttributeInfo(

name=""Review_Url"",

description=""The URL of the review"",

type=""string"",

),

AttributeInfo(

name=""Author"",

description=""The author of the review"",

type=""string"",

),

AttributeInfo(

name=""Rating"",

description=""A 1 to 10 rating for the movie"",

type=""integer"",

)

]

To define our retrieval we must define the following points:

The LLM to use

The embedding model to be used

The vector basis that is accessed

A description of what information can be found in the

documents of this vector base.

The metadata description

The Query translator you want to use

Let’s see what it looks like in code:

document_content_desription = ""A review of the Jonh Wick movie.""

embeddings = OpenAIEmbeddings(model=""text-embedding-3-small"")

chat_model = ChatOpenAI()

self_query_retriever = SelfQueryRetriever.from_llm(

llm=ChatOpenAI(temperature=0),

vectorstore =vectordb,

document_contents = document_content_desription,

metadata_field_info =metadata_field_info,

verbose = True,

structured_query_translator = ChromaTranslator()

)

Let’s see with a very clear example how we have greatly improved our RAG by using this type of retriever. First we use a naive retriever and then a self query retriever.

Question = ""Make a summary of the reviews that talk about John Wick 3 and have a score higher than 7""

response = naive_retrieval_chain.invoke(Question)

print(response)

'''

I don't know the answer.

'''

------------------------------------------------------------------------

response = self_retrieval_chain.invoke(Question)

print(response)

'''

John Wick: Chapter 3 - Parabellum is quite literally

about consequences, dealing with the fallout of John's...

'''

As we can see, there is a notable improvement.

Method: Contextual Compression Retriever (Reranking)

Code in 4_contextual_compression_retriever(reranking).ipynb file.

Context Windows: The more documents we obtain from the vectore store, the more information the LLM will have to give a good answer.

Recall: The more documents are retrieved from the vector store, the probability of obtaining irrelevant chunks is greater and therefore, the recall decreases (Not a good thing).

There seems to be no solution for this problem. When we increase one of the metrics, the other seems destined to decrease. Are we sure about that?

This is when this technique, compression retriever, is presented, focusing on the reranking technique. Let’s say that this technique consists of two very different steps:

Step 1: Get a good amount of relevant docs based on the input/question. Normally we set the most relevant K.

Step 2: Recalculate which of these documents are really relevant. discarding the other documents that are not really useful (Compression).

For the first step, what is known as Bi-Encoder is used, which is nothing more than what we usually use to make a basic RAG. Vectorize our documents. vectorize the query and calculate the similarity with any metric of our choice.

The second step is something different from what we are used to seeing. This recalculation/reranking is executed by the reranking model or cross-encoder.

These models expect two documents/texts as input, returning a similarity score between the pair.

If one of these two inputs is the query and the other is a chunk, we can calculate the similarity between the two.

These two methods can be displayed as follows:

You will have realized that the two methods in the end provide the same result, a metric that reflects the similarity between two texts. And this is totally true, but there is a key feature:

The result returned by the cross encoder is much more reliable than with the Bi-encoder

Okay, it works better, then, because we don’t use it directly with all chunks, instead of just the top K chunks. Because it would be terribly expensive in time and money/computation. For this reason, we make a first filter of the chunks closest in similarity to the query, reducing the use of the reranking model to only K times.

A good question would be where to find the Cross-Encoder models? We are lucky that there are open source models that we can find in HuggingFace, but for the practical case of this post we are going to use the model made available by the company Cohere.

Cohere | The leading AI platform for enterprise

Cohere provides industry-leading large language models (LLMs) and RAG capabilities tailored to meet the needs of…

cohere.com

To better understand the architecture of this method, let’s look at a visual example.

The image shows the steps:

1º) We obtain the query, which we encode in its vector form with a transformer and we introduce it into the vector base.

2º) Collect the documents most similar to the query from our database. We can use any retriever method.

3º) Next we use the Cohere cross-encoder model. In the example in the image, this model will be used a total of 4 times. Remember that the input of this model will be the query and a document/chunk, to collect the similarity of these two texts.

4º) The 4 calls have been made to this model in the previous step and 4 new values (between 0 and 1) of the similarity between the query and each of the documents have been obtained. As can be seen, the chunk number 1 obtained in the previous steps, after the reranking, is now in 4th place.

5º) We add the first 3 chunks most relevant to the context.

Returning again to the computational cost and time, if the cross-encoders were applied directly, think that with each new query, the similarity of the query with each of the documents should be calculated. Something that is not optimal at all.

On the other hand, using Bi-Encoders, the vector representation of the documents is the same for each new query.

We then have a much superior method that is expensive to execute, and on the other hand, another method that works well but does not have a large computational cost with each new query. All this ends with the conclusion of unifying these two methods for a better RAG. And this is known as the Contextual Compression with reranking method.

Let’s move on to the code part. Let’s remember that this method uses a retreiver, which in our case will be a Naive Retriever:

naive_retriever = vectordb.as_retriever(search_kwargs={ ""k"" : 10})

Thanks to Langchain and its integration with Cohere, we only have to import the module that will execute the call to the Cohere cross-encoder model:

from langchain_cohere import CohereRerank

os.environ[""COHERE_API_KEY""] = ""YOUR API KEY FROM COHERE""

compressor = CohereRerank(top_n=3)

Finally, we create our Contextual Compression Retriever with Langchain:

from langchain.retrievers.contextual_compression import ContextualCompressionRetriever

compression_retriever = ContextualCompressionRetriever(

base_compressor=compressor,

base_retriever=naive_retriever

)

As simple as that. Let’s see a comparison between a Naive Retriever and a Reranking Retriever:

As we see, Naive returns us the top 10 chunks/documents. After performing the reranking and obtaining the 3 most relevant documents/chunks, there are noticeable changes. Notice how document number 16, which is in third position in relation to its relevance in the first retriever, becomes first position when performing the reranking.

Conclusion

We have seen that depending on the characteristics of the case where we want to apply a RAG, we will want to use one method or another. Furthermore, there may be the case in which one does not know which retriever method to use. For this, there are different libraries to evaluate your rags.

There are several tools for this purpose. Some of those options that I personally recommend are the combination of RAGAS and LangSmith.

Evaluating RAG pipelines with Ragas + LangSmith

Editor's Note: This post was written in collaboration with the Ragas team. One of the things we think and talk about a…

blog.langchain.dev

I highly recommend following, learning and watching the videos of these people who are really what inspired me to make this article.

AI Makerspace

Learn how to build, ship, and share production Large Language Model applications with us!

www.youtube.com

Thank you for reading!

If you find my work useful, you can subscribe to get an email every time that I publish a new article.

If you’d like, follow me on Linkedin!"
https://www.datanami.com/this-just-in/ai-squared-raises-13-8m-to-accelerate-widespread-ai-adoption-within-organizations/,AI Squared Raises $13.8M to Accelerate Widespread AI Adoption Within Organizations,"WASHINGTON, April 18, 2024 — AI Squared has announced $13.8 million in Series A funding led by Ansa Capital with participation from Latimer Ventures, and existing investors NEA and Ridgeline. As part of the investment, Ansa Capital co-founder and General Partner Allan Jean-Baptiste will join AI Squared’s board.

Roger W. Ferguson Jr., former Vice Chairman of the Federal Reserve and board member of Alphabet Inc, has also invested and will join the company’s Board of Directors. AI Squared will use this funding to expand its team, and further mature its platform helping businesses integrate AI into their workflows.

As investments in AI rapidly increase, data science teams in businesses and governments are racing to implement AI models that can extract much more value from their data, improving their decision-making and the efficiency of their operations. AI Squared’s platform dramatically increases companies’ ROI in AI projects by making it much easier to integrate and adopt AI-powered insights into the tools and apps they use every day. The founding team, including founder and CEO Benjamin Harvey Ph.D., draws on deep data science expertise from over a decade working in the National Security Agency, and within Databricks’ data science team.

AI Squared estimates that up to 90% of AI models developed by enterprises do not make it into production, meaning they struggle to generate greater value from their AI investments. The company’s solution lessens the time to integrate data and AI into workflows from 4 months to 4 minutes and reduces the cost of implementing even one model by roughly 100x.

“Far too many companies aren’t getting enough ROI from AI,” said AI Squared’s founder and CEO Benjamin Harvey, Ph.D. “Deploying a single model often requires the use of over 10 tools. AI Squared’s tools directly tackle this ‘last mile’ problem, and make it much easier for businesses to deploy, use, and improve the use of AI within their teams.”

“While AI’s capabilities are rapidly growing, organizations’ ability to deploy them are not. With new state-of-the-art models being released practically every week, enterprises risk getting left behind”, said Ansa’s Capital’s Co-Founder and General Partner, Allan Jean-Baptiste. “We see a massive market opportunity for AI Squared to solve significant corporate hurdles in AI implementation by simplifying integration into existing workflows and tools while enabling faster time to value for AI investments.”

Model developers can use AI Squared’s platform to build pipelines that connect data sources and AI models to business applications, rendering relevant insights directly into their workflows. Using AI Squared, users can connect machine-learning models and other advanced analytics to business applications directly and in an app-agnostic way. AI Squared’s platform then creates feedback loops to improve model performance and UI design.

As a result, organizations can generate greater value from their AI investments. The company’s solution is being implemented across the finance, manufacturing, and health sectors — including Fortune 500 enterprises — as well as government organizations.

As one of the few Black-founded AI businesses, AI Squared is also committed to expanding accessibility in the wider ecosystem to ensure underrepresented communities help drive forward progress in AI. The company recently funded the AI Squared Innovation Lab, providing computers and supplies to support programming and technology advancement, and will continue its internship programs for underserved students.

About AI Squared

Founded in 2019, AI Squared helps organizations deliver data and AI insights into their business applications. The company’s solutions are currently being rolled out across government organizations, as well as Fortune 500 corporations across the finance, manufacturing, and health industries. The leadership team, including CEO and founder Benjamin Harvey Ph.D., carries deep data science experience across large tech companies such as Databricks and Microsoft, financial organizations such as JPMorgan Chase, as well as the National Security Agency.

Source: AI Squared"
https://www.analyticsinsight.net/is-data-science-a-promising-career-in-2024/,Is Data Science a Promising Career In 2024?,"Here is what you need to know about a career in data science in 2024

The last few years have witnessed an explosion in the sphere of data science, spurred on by the rampant digitization of industries and the colossal bulk of data created daily. However, as we step into 2024, the question arises: Is data science still an attractive job? Now, let’s get into what the data science market is like in 2024 and what aspiring data scientists have to know to prepare.

On the other hand, despite the pace of technology evolution, demand for data science solutions remains high across different segments. Organizations are shifting towards data-driven strategic management to make intelligent decisions, which results in the necessity of workers who can extract knowledge that exhibits valuable insights from multiple sets of complex data. From healthcare to finance, shopping to manufacturing, the areas of applications of data science are broad and very wide. This opens up numerous career paths to choose from.

The technological revolution has caused a constant high demand for data scientists. Given the increasing use of IoT devices, social media networks, and online transactions, the amount of data generated, processed, and stored keeps growing in waves. This, in turn, leads to an organizational struggle with managing datasets and analysis and a continuous desire for data science capability.

In addition, the integration of AI and ML algorithms is completely changing the whole data science field. Data scientists can now predict, automate, and discover hidden patterns in data using cutting-edge algorithms. In 2024, competency in AI and ML approaches, particularly areas such as deep learning, natural language processing, and reinforcement learning, will be highly sought after in the job market.

On a positive note, there is still a high interest in data scientists, but the competition in this area has been increasing. With more data science professionals changing their roles and original programs from universities dedicated to this field, it becomes hardly contention for those who want to become data scientists. Lifelong learning and relevance of the latest technologies and methodologies are essential factors in staying ahead of the competition.

Equally important to technical skills are soft skills like communication, critical thinking, and problem-solving, which are instrumental to the success of data science teams. Unlike many other roles, data scientists not only provide data analysis but also share insights with stakeholders in a data-driven decision. Top-notch communication skills give data scientists the ability to present complexities in an intelligible and concise way, thereby linking technological expertise with business needs.

The ethics of data science in the year 2024 can’t be neglected also. Given the fact that privacy is a matter of concern, algorithms have bias, and the ethics of AI usage are also to be observed, data scientists are required to act according to ethical standards as well as to exhibit fairness, transparency, and accountability in their jobs. Consequently, practitioners of data science are to be ethically literate and possess a robust ethical framework to satisfy ever-increasing demand.

In fact, data science has plenty of bright career prospects in 2024, resulting primarily from the increased importance of data-based decision-making and new technology. Nonetheless, data scientists need to stick up for their role by frequently learning the knowledge of technical and soft skills and by integrating data ethics into their work practice."
https://towardsdatascience.com/the-math-behind-deep-cnn-alexnet-738d858e5a2f,The Math Behind Deep CNN — AlexNet,"1: Introduction

AlexNet is a pioneering deep learning network that rose to prominence after winning the ImageNet Large Scale Visual Recognition Challenge in 2012. Developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, AlexNet significantly lowered the top-5 error rate to 15.3% from the previous best of 26.2%, setting a new benchmark for the field. This achievement highlighted the effectiveness of CNNs that use ReLU activations, GPU acceleration, and dropout regularization to manage complex image classification tasks across large datasets.

The model comprises several layers that have become standard in most deep-learning CNNs today. These include convolutional layers, max-pooling, dropout, fully connected layers, and a softmax output layer. The model’s success demonstrated the practicality of deeper network architectures through creative approaches to design and training.

In this article, we will break down the sophisticated design and mathematical principles that underpin AlexNet. We’ll also review AlexNet’s training procedures and optimization techniques, and we will build it from scratch using PyTorch.

2: Overview of AlexNet Architecture

2.1: General Layer Structure

AlexNet’s architecture cleverly extracts features through a hierarchical layering system where each layer builds on the previous layers’ outputs to refine the feature extraction process. Here’s a detailed breakdown of its layers and functions:

Input Image

The model processes input images resized to 227x227 pixels. Each image has three channels (Red, Green, and Blue), reflecting standard RGB encoding.

Layer Configuration

It consists of eight primary layers that learn weights, five of which are convolutional, and the remaining three are fully connected. Between these layers, activation functions, normalization, pooling, and dropout are strategically applied to improve learning efficacy and combat overfitting.

Convolutional Layers

The initial layer uses 96 kernels (filters) sized 11x11x3, which convolve with the input image using a stride of 4 pixels. This large stride size helps reduce the output spatial volume size significantly, making the network computationally efficient right from the first layer.

Outputs from the first layer undergo normalization and max-pooling before reaching the second convolutional layer, which consists of 256 kernels each of size 5x5x48. The use of 48 feature maps each corresponds to separate filtered outputs from the previous layer, allowing this layer to mix features effectively.

The third convolutional layer does not follow with pooling or normalization, which typically helps to maintain the feature map’s richness derived from previous layers. It includes 384 kernels of size 3x3x256, directly connected to the outputs of the second layer, enhancing the network’s ability to capture complex features.

The fourth convolutional layer mirrors the third layer’s configuration but uses 384 kernels of size 3x3x192, enhancing the depth of the network without altering the layer’s spatial dimensions.

The final convolutional layer employs 256 kernels of size 3x3x192 and is followed by a max-pooling layer, which helps to reduce dimensionality and provides rotational and positional invariance to the features being learned.

Fully Connected Layers

The first fully connected layer is a dense layer with 4096 neurons. It takes the flattened output from the preceding convolutional layers (transformed into a 1D vector) and projects it onto a high-dimensional space to learn non-linear combinations of the features.

The second fully connected layer also features 4096 neurons and includes dropout regularization. Dropout helps prevent overfitting by randomly setting a fraction of input units to zero during training, which encourages the network to learn more robust features that are not reliant on any small set of neurons.

The final fully connected layer comprises 1000 neurons, each corresponding to a class of the ImageNet challenge. This layer is essential for class prediction, and it typically utilizes a softmax function to derive the classification probabilities.

2.2: Output Layer and Softmax Classification

The final layer in AlexNet is a softmax regression layer which outputs a distribution over the 1000 class labels by applying the softmax function to the logits of the third fully connected layer.

The softmax function is given by:

​​where zi​ are the logits or the raw prediction scores for each class from the final fully connected layer.

This layer essentially converts the scores into probabilities by comparing the exponentiated score of each class with the sum of exponentiated scores for all classes, highlighting the most probable class.

The softmax layer not only outputs these probabilities but also forms the basis for the cross-entropy loss during training, which measures the difference between the predicted probability distribution and the actual distribution (the true labels).

3: In-depth Analysis of AlexNet Components

3.1: ReLU Nonlinearity

The Rectified Linear Unit (ReLU) has become a standard activation function for deep neural networks, especially CNNs like AlexNet. Its simplicity allows models to train faster and converge more effectively compared to networks using sigmoid or tanh functions.

The mathematical representation of ReLU is straightforward:

This function outputs x if x is positive; otherwise, it outputs zero.

Graphically, it looks like a ramp function that increases linearly for all positive inputs and is zero for negative inputs.

Advantages Of Sigmoid Over Tanh

ReLU has several advantages over traditional activation functions such as sigmoid:

and hyperbolic tangent:

ReLU helps neural networks converge faster by addressing the vanishing gradient problem. This problem occurs with sigmoid and tanh functions where gradients become very small (approach zero) as inputs become large, in either positive or negative direction. This small gradient slows down the training significantly as it provides very little update to the weights during backpropagation. In contrast, the gradient of the ReLU function is either 0 (for negative inputs) or 1 (for positive inputs), which simplifies and speeds up gradient descent.

It promotes sparsity of the activation. Since it outputs zero for half of its input domain, it inherently produces sparse data representations. Sparse representations seem to be more beneficial than dense representations (as typically produced by sigmoid or tanh functions), particularly in large-scale image recognition tasks where the inherent data dimensionality is very high but the informative part is relatively low.

Moreover, ReLU involves simpler mathematical operations. For any input value, this activation function requires a single max operation, whereas sigmoid and tanh involve more complex exponential functions, which are computationally more expensive. This simplicity of ReLU leads to much faster computational performance, especially beneficial when training deep neural networks on large datasets.

Because the negative part of ReLU’s function is zeroed out, it avoids the problem of outputs that do not change in a non-linear fashion as seen with sigmoid or tanh functions. This characteristic allows the network to model the data more cleanly and avoid potential pitfalls in training dynamics.

3.2: Training on Multiple GPUs

AlexNet was one of the pioneering convolutional neural networks to leverage parallel GPU training, managing its deep and computation-heavy architecture. The network operates on two GPUs simultaneously, a core part of its design that greatly improves its performance and practicality.

Layer-wise Distribution

AlexNet’s layers are distributed between two GPUs. Each GPU processes half of the neuron activations (kernels) in the convolutional layers. Specifically, the kernels in the third layer receive inputs from all kernel maps of the second layer, whereas the fourth and fifth layers only receive inputs from kernel maps located on the same GPU.

Communication Across GPUs

The GPUs need to communicate at specific layers crucial for combining their outputs for further processing. This inter-GPU communication is essential for integrating the results of parallel computations.

Selective Connectivity

Not every layer in AlexNet is connected across both GPUs. This selective connectivity reduces the amount of data transferred between GPUs, cutting down on communication overhead and enhancing computation efficiency.

This strategy of dividing not just the dataset but also the network model across two GPUs enables AlexNet to handle more parameters and larger input sizes than if it were running on a single GPU. The extra processing power allows AlexNet to handle its 60 million parameters and the extensive computations required for training deep networks on large-scale image classification tasks efficiently.

Training with larger batch sizes is more feasible with multiple GPUs. Larger batches provide more stable gradient estimates during training, which is vital for efficiently training deep networks. While not directly a result of using multiple GPUs, the ability to train with larger batch sizes and more rapid iteration times helps combat overfitting. The network experiences a more diverse set of data in a shorter amount of time, which enhances its ability to generalize from the training data to unseen data.

3.3: Local Response Normalization

Local Response Normalization (LRN) in AlexNet is a normalization strategy that plays a crucial role in the network’s ability to perform well in image classification tasks. This technique is applied to the output of the ReLU non-linearity activation function.

LRN aims to encourage lateral inhibition, a biological process where activated neurons suppress the activity of neighboring neurons in the same layer. This mechanism works under the “winner-takes-all” principle, where neurons showing relatively high activity suppress the less active neurons around them. This dynamic allows the most significant features relative to their local neighborhood to be enhanced while suppressing the lesser ones.

The LRN layer computes a normalized output for each neuron by performing a sort of lateral inhibition by damping the responses of neurons when their locally adjacent neurons exhibit high activity.

Given a neuron’s activity ax, yi​ at position (x, y) in the feature map i, the response-normalized activity bx, yi​ is given by:​​

where:

ax, yi​ is the activity of a neuron computed by applying kernel i at position (x, y) and then applying the ReLU function.

N is the total number of kernels in the layer.

The sum runs over n neighboring kernel maps at the same spatial position, and N is the total number of kernels.

k, α, β are hyperparameters whose values are predetermined (in AlexNet, typically n=5, k=2, α=10e−4, β=0.75).

bx, yi​ is the normalized response of the neuron.

Local Response Normalization (LRN) serves to implement a form of local inhibition among adjacent neurons, which is inspired by the concept of lateral inhibition found in biological neurons. This inhibition plays a vital role in several key areas:

Activity Regulation

LRN prevents any single feature map from overwhelming the response of the network by penalizing larger activations that lack support from their surroundings. This squaring and summing of neighboring activations ensures no single feature disproportionately influences the output, enhancing the model’s ability to generalize across various inputs.

Contrast Normalization

By emphasizing patterns that stand out relative to their neighbors, LRN functions similarly to contrast normalization in visual processing. This feature highlights critical local features in an image more effectively, aiding in the visual differentiation process.

Error Rate Reduction

Incorporating LRN in AlexNet has helped reduce the top-1 and top-5 error rates in the ImageNet classification tasks. It manages the high activity levels of neurons, thereby improving the overall robustness of the network.

3.4: Overlapping Pooling

Overlapping pooling is a technique used in convolutional neural networks (CNNs) to reduce the spatial dimensions of the input data, simplify the computations, and help control overfitting. It modifies the standard non-overlapping (traditional) max-pooling by allowing the pooling windows to overlap.

Traditional Max Pooling

In traditional max pooling, the input image or feature map is divided into distinct, non-overlapping regions, each corresponding to the size of the pooling filter, often 2x2. For each of these regions, the maximum pixel value is determined and output to the next layer. This process reduces the data dimensions by selecting the most prominent features from non-overlapping neighborhoods.

For example, assuming a pooling size (z) of 2x2 and a stride (s) of 2 pixels, the filter moves 2 pixels across and 2 pixels down the input field. The stride of 2 ensures there is no overlap between the regions processed by the filter.

Overlapping Pooling in AlexNet

Overlapping pooling, used by AlexNet, involves setting the stride smaller than the pool size. This approach allows the pooling regions to overlap, meaning the same pixel may be included in multiple pooling operations. It increases the density of the feature mapping and helps retain more information through the layers.

For example, using a pooling size of 3x3 and a stride of 2 pixels. This configuration means that while the pooling filter is larger (3x3), it moves by only 2 pixels each time it slides over the image or feature map. As a result, adjacent pooling regions share a column or row of pixels that gets processed multiple times, enhancing feature integration.

3.5: Fully Connected Layers and Dropout

In the architecture of AlexNet, after several stages of convolutional and pooling layers, the high-level reasoning in the network is done by fully connected layers. Fully connected layers play a crucial role in transitioning from the extraction of feature maps in the convolutional layers to the final classification.

A fully connected (FC) layer takes all neurons in the previous layer (whether they are the output of another fully connected layer, or a flattened output from a pooling or convolutional layer) and connects each of these neurons to every neuron it contains. In AlexNet, there are three fully connected layers following the convolutional and pooling layers.

The first two fully connected layers in AlexNet have 4096 neurons each. These layers are instrumental in integrating the localized, filtered features that the prior layers have identified into global, high-level patterns that can represent complex dependencies in the inputs. The final fully connected layer effectively acts as a classifier: with one neuron for each class label (1000 for ImageNet), it outputs the network’s prediction for the input image’s category.

Each neuron in these layers applies a ReLU (Rectified Linear Unit) activation function except for the output layer, which uses a softmax function to map the output logits (the raw prediction scores for each class) to a probabilistic distribution over the classes.

The output from the final pooling or convolutional layer typically undergoes flattening before being fed into the fully connected layers. This process transforms the 2D feature maps into 1D feature vectors, making them suitable for processing via traditional neural network techniques. The final layer’s softmax function then classifies the input image by assigning probabilities to each class label based on the feature combinations learned through the network.

3.6: Dropout

Dropout is a regularization technique used to prevent overfitting in neural networks, particularly effective in large networks like AlexNet. Overfitting occurs when a model learns patterns specific to the training data, but which do not generalize to new data.

In AlexNet, dropout is applied to the outputs of the first two fully connected layers. Each neuron in these layers has a probability p (commonly set to 0.5, i.e., 50%) of being “dropped,” meaning it is temporarily removed from the network along with all its incoming and outgoing connections.

If you want to dive deep into Dropout’s math and code, I highly recommend you take a look at section 3.4 of my previous article:

4: Training Process and Optimization

4.1: Stochastic Gradient Descent Parameters

In AlexNet, Stochastic Gradient Descent (SGD) is employed to optimize the network during training. This method updates the network’s weights based on the error gradient of the loss function, where the effective tuning of parameters such as batch size, momentum, and weight decay is critical for the model’s performance and convergence. In today’s article, we will use a Pytorch implementation of SGD, and we will cover a high-level view of this popular optimization technique. If you are interested in a low-level view, scraping its math, and building the optimizer from scratch, take a look at this article:

Let’s cover now the main components of SGD and the settings used in AlexNet:

Batch Size

The batch size, which is the number of training examples used to calculate the loss function’s gradient for one update of the model’s weights, is set to 128 in AlexNet. This size strikes a balance between computational efficiency — since larger batches require more memory and computation — and the accuracy of error estimates, which benefit from averaging across more examples.

The choice of a batch size of 128 helps stabilize the gradient estimates, making the updates smoother and more reliable. While larger batches provide a clearer signal for each update by reducing noise in the gradient calculations, they also require more computational resources and may sometimes generalize less effectively from training data to new situations.

Momentum

Momentum in SGD helps accelerate the updates in the correct direction and smoothens the path taken by the optimizer. It modifies the update rule by incorporating a fraction of the previous update vector. In AlexNet, the momentum value is 0.9, implying that 90% of the previous update vector contributes to the current update. This high level of momentum speeds up convergence towards the loss function’s minimum, which is particularly useful when dealing with small but consistent gradients.

Using momentum ensures that updates not only move in the right direction but also build up speed along surfaces of the loss function’s topology that have consistent gradients. This aspect is crucial for escaping from any potential shallow local minima or saddle points more effectively.

Weight Decay

Weight decay acts as a regularization term that penalizes large weights by adding a portion of the weight values to the loss function. AlexNet sets this parameter at 0.0005 to keep the weights from becoming too large, which could lead to overfitting given the network’s large number of parameters.

Weight decay is essential in complex models like AlexNet, which are prone to overfitting due to their high capacity. By penalizing the magnitude of the weights, weight decay ensures that the model does not rely too heavily on a small number of high-weight features, promoting a more generalized model.

The update rule for AlexNet’s weights can be described as follows:

Here:

vt​ is the momentum-enhanced update vector from the previous step.

μ (0.9 for AlexNet) is the momentum factor, enhancing the influence of the previous update.

ϵ is the learning rate, determining the size of the update steps.

∇L represents the gradient of the loss function for the weights.

λ (0.0005 for AlexNet) is the weight decay factor, mitigating the risk of overfitting by penalizing large weights.

w denotes the weights themselves.

These settings help ensure that the network not only learns efficiently but also achieves robust performance on both seen and unseen data, optimizing the speed and accuracy of training while maintaining the ability to generalize well.

4.2: Initialization

Proper initialization of weights and biases and the careful adjustment of the learning rate are critical to training deep neural networks. These factors influence the rate at which the network converges and its overall performance on both training and validation datasets.

Weights Initialization

In AlexNet, the weights for the convolutional layers are initialized from a zero-mean Gaussian distribution with a standard deviation of 0.01. This narrow standard deviation prevents any single neuron from initially overwhelming the output, ensuring a uniform scale of weight initialization.

Similarly, weights in the fully connected layers are initialized from a Gaussian distribution. Special attention is given to the variance of this distribution to keep the output variance consistent across layers, which is crucial for maintaining the stability of deeper networks.

To get a better understanding of this process let’s build the initialization for AlexNet from scratch in Python:

import numpy as np

def initialize_weights(layer_shapes):

weights = []

for shape in layer_shapes:

if len(shape) == 4: # This is a conv layer: (out_channels, in_channels, filter_height, filter_width)

std_dev = 0.01 # Standard deviation for conv layers

fan_in = np.prod(shape[1:]) # product of in_channels, filter_height, filter_width

elif len(shape) == 2: # This is a fully connected layer: (out_features, in_features)

# He initialization: std_dev = sqrt(2. / fan_in)

fan_in = shape[1] # number of input features

std_dev = np.sqrt(2. / fan_in) # Recommended to maintain variance for ReLU

else:

raise ValueError(""Invalid layer shape: must be 4D (conv) or 2D (fc)"")

# Gaussian initialization

weight = np.random.normal(loc=0, scale=std_dev, size=shape)

weights.append(weight)

return weights

# Example usage:

layer_shapes = [

(96, 3, 11, 11), # Conv1 Layer: 96 filters, 3 input channels, 11x11 filter size

(256, 96, 5, 5), # Conv2 Layer: 256 filters, 96 input channels, 5x5 filter size

(384, 256, 3, 3), # Conv3 Layer: 384 filters, 256 input channels, 3x3 filter size

(384, 384, 3, 3), # Conv4 Layer: 384 filters, 384 input channels, 3x3 filter size

(256, 384, 3, 3), # Conv5 Layer: 256 filters, 384 input channels, 3x3 filter size

(4096, 256*6*6), # FC1 Layer: 4096 output features, (256*6*6) input features

(4096, 4096), # FC2 Layer: 4096 output features, 4096 input features

(1000, 4096) # FC3 (output) Layer: 1000 classes, 4096 input features

]

initialized_weights = initialize_weights(layer_shapes)

for idx, weight in enumerate(initialized_weights):

print(f""Layer {idx+1} weights shape: {weight.shape} mean: {np.mean(weight):.5f} std dev: {np.std(weight):.5f}"")

The initialize_weights function takes a list of tuples describing the dimensions of each layer's weights. Convolutional layers expect four dimensions (number of filters, input channels, filter height, filter width), while fully connected layers expect two dimensions (output features, input features).

In the convolutional layers standard deviation is fixed at 0.01, aligned with the original AlexNet configuration to prevent overwhelming outputs by any single neuron.

Fully connected layers use He initialization (good practice for layers using ReLU activation) where the standard deviation is adjusted to sqrt(2/fan_in) to keep the output variance consistent, promoting stable learning in deep networks.

For each layer defined in layer_shapes, weights are initialized from a Gaussian (normal) distribution centered at zero with a calculated

Biases Initialization

Biases in some convolutional layers are set to 1, particularly in layers followed by ReLU activations. This initialization pushes the neuron outputs into the positive range of the ReLU function, ensuring they are active from the beginning of training. Biases in other layers are initialized at 0 to start from a neutral output.

Like in certain convolutional layers, biases in fully connected layers are also set to 1. This strategy helps to prevent dead neurons at the start of training by ensuring that neurons are initially in the positive phase of activation.

4.3: Strategy for Adjusting the Learning Rate

AlexNet begins with an initial learning rate of 0.01. This rate is high enough to allow significant updates to the weights, facilitating rapid initial progress without being so high as to risk the divergence of the learning process.

The learning rate is decreased by a factor of 10 at predetermined points during the training. This approach is known as “step decay.” In AlexNet, these adjustments typically occur when the validation error rate stops decreasing significantly. Reducing the learning rate at these points helps refine the weight adjustments, promoting better convergence.

Starting with a higher learning rate helps the model overcome potential local minima more effectively. As the network begins to stabilize, reducing the learning rate helps it settle into broad, flat minima that are generally better for generalization to new data.

As training progresses, lowering the learning rate allows for finer weight adjustments. This gradual refinement helps the model to not only fit the training data better but also improves its performance on validation data, ensuring the model is not just memorizing the training examples but genuinely learning to generalize from them.

5: Building AlexNet in Python

In this section, we detail the step-by-step process to recreate AlexNet in Python using PyTorch, providing insights into the class architecture, its initial setup, training procedures, and evaluation techniques.

I suggest you keep this Jupyter Notebook open and accessible, as it contains all the code we will be covering today:

5.1: AlexNet Class

Let’s start with building the AlexNet main class:

# PyTorch for creating and training the neural network

import torch

import torch.nn as nn

import torch.optim as optim

from torch.utils.data.dataset import random_split

# platform for getting the operating system

import platform

# torchvision for loading and transforming the dataset

import torchvision

import torchvision.transforms as transforms

# ReduceLROnPlateau for adjusting the learning rate

from torch.optim.lr_scheduler import ReduceLROnPlateau

# numpy for numerical operations

import numpy as np

# matplotlib for plotting

import matplotlib.pyplot as plt

class AlexNet(nn.Module):

def __init__(self, num_classes=1000):

super(AlexNet, self).__init__()

self.features = nn.Sequential(

nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),

nn.ReLU(inplace=True),

nn.MaxPool2d(kernel_size=3, stride=2),

nn.Conv2d(64, 192, kernel_size=5, padding=2),

nn.ReLU(inplace=True),

nn.MaxPool2d(kernel_size=3, stride=2),

nn.Conv2d(192, 384, kernel_size=3, padding=1),

nn.ReLU(inplace=True),

nn.Conv2d(384, 256, kernel_size=3, padding=1),

nn.ReLU(inplace=True),

nn.Conv2d(256, 256, kernel_size=3, padding=1),

nn.ReLU(inplace=True),

nn.MaxPool2d(kernel_size=3, stride=2),

)

self.avgpool = nn.AdaptiveAvgPool2d((6, 6))

self.classifier = nn.Sequential(

nn.Dropout(),

nn.Linear(256 * 6 * 6, 4096),

nn.ReLU(inplace=True),

nn.Dropout(),

nn.Linear(4096, 4096),

nn.ReLU(inplace=True),

nn.Linear(4096, num_classes),

)

def forward(self, x):

x = self.features(x)

x = self.avgpool(x)

x = torch.flatten(x, 1)

x = self.classifier(x)

return x

Initializationclass AlexNet(nn.Module)

class AlexNet(nn.Module):

def __init__(self, num_classes=1000):

super(AlexNet, self).__init__()

The AlexNet class inherits from nn.Module, a base class for all neural network modules in PyTorch. Any new network architecture in PyTorch is created by subclassing nn.Module.

The initialization method defines how the AlexNet object should be constructed when instantiated. It optionally takes a parameter num_classes to allow for flexibility in the number of output classes, defaulting to 1000, which is typical for ImageNet tasks.

Feature Layers

self.features = nn.Sequential(

nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),

nn.ReLU(inplace=True),

nn.MaxPool2d(kernel_size=3, stride=2),

nn.Conv2d(64, 192, kernel_size=5, padding=2),

nn.ReLU(inplace=True),

nn.MaxPool2d(kernel_size=3, stride=2),

nn.Conv2d(192, 384, kernel_size=3, padding=1),

nn.ReLU(inplace=True),

nn.Conv2d(384, 256, kernel_size=3, padding=1),

nn.ReLU(inplace=True),

nn.Conv2d(256, 256, kernel_size=3, padding=1),

nn.ReLU(inplace=True),

nn.MaxPool2d(kernel_size=3, stride=2),

)

Here is where the convolutional layers of AlexNet are defined. The nn.Sequential container wraps a sequence of layers, and data passes through these layers in the order they are added.

nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)

The first layer is a 2D convolutional layer (nn.Conv2d) with 3 input channels (RGB image), and 64 output channels (feature maps), with a kernel size of 11x11, a stride of 4, and padding of 2 on each side. This layer processes the input image and begins the feature extraction.

nn.ReLU(inplace=True)

Then, we pass the ReLU activation function which introduces non-linearity, allowing the model to learn complex patterns. The inplace=True parameter helps to save memory by modifying the input directly.

nn.MaxPool2d(kernel_size=3, stride=2)

The max-pooling layer reduces the spatial dimensions of the input feature maps, making the model more robust to the position of features in the input images. It uses a window of size 3x3 and a stride of 2.

Additional nn.Conv2d and nn.MaxPool2d layers follow, which further refine and compact the feature representation. Each convolutional layer typically increases the number of feature maps while reducing their dimensionality through pooling, a pattern that helps in abstracting from the spatial input to features that progressively encapsulate more semantic information.

Adaptive Pooling and Classifier

self.avgpool = nn.AdaptiveAvgPool2d((6, 6))

self.avgpool adaptively pools the feature maps to a fixed size of 6x6, which is necessary for matching the input size requirement of the fully connected layers, allowing the network to handle various input dimensions.

self.classifier = nn.Sequential(

nn.Dropout(),

nn.Linear(256 * 6 * 6, 4096),

nn.ReLU(inplace=True),

nn.Dropout(),

nn.Linear(4096, 4096),

nn.ReLU(inplace=True),

nn.Linear(4096, num_classes),

)

Here, we define another sequential container named classifier, which contains the fully connected layers of the network. These layers are responsible for making the final classification based on the abstract features extracted by the convolutional layers.

nn.Dropout() randomly zeroes some of the elements of the input tensor with a probability of 0.5 for each forward call, which helps prevent overfitting.

nn.Linear(256 * 6 * 6, 4096) reshapes the flattened feature maps from the adaptive pooling layer into a vector of size 4096. It connects every input to every output with learned weights.

Finally, nn.ReLU and nn.Dropout calls further refine the learning pathway, providing non-linear activation points and regularization respectively. The final nn.Linear layer reduces the dimension from 4096 to num_classes, outputting the raw scores for each class.

Forward Method

def forward(self, x):

x = self.features(x)

x = self.avgpool(x)

x = torch.flatten(x, 1)

x = self.classifier(x)

return x

The forward method dictates the execution of the forward pass of the network:

x = self.features(x) processes the input through the convolutional layers for initial feature extraction.

x = self.avgpool(x) applies adaptive pooling to the features to standardize their size.

x = torch.flatten(x, 1) flattens the output to a vector, preparing it for classification.

x = self.classifier(x) runs the flattened vector through the classifier to generate predictions for each class.

5.2: Early Stopping Class

The EarlyStopping class is used during the training of machine learning models to halt the training process when the validation loss ceases to improve. This approach is instrumental in preventing overfitting and conserving computational resources by stopping the training at the optimal time.

class EarlyStopping:

""""""

Early stopping to stop the training when the loss does not improve after

Args:

-----

patience (int): Number of epochs to wait before stopping the training.

verbose (bool): If True, prints a message for each epoch where the loss

does not improve.

delta (float): Minimum change in the monitored quantity to qualify as an improvement.

""""""

def __init__(self, patience=7, verbose=False, delta=0):

self.patience = patience

self.verbose = verbose

self.counter = 0

self.best_score = None

self.early_stop = False

self.delta = delta

def __call__(self, val_loss):

""""""

Args:

-----

val_loss (float): The validation loss to check if the model performance improved.

Returns:

--------

bool: True if the loss did not improve, False if it improved.

""""""

score = -val_loss

if self.best_score is None:

self.best_score = score

elif score < self.best_score + self.delta:

self.counter += 1

if self.counter >= self.patience:

self.early_stop = True

else:

self.best_score = score

self.counter = 0

Initialization

def __init__(self, patience=7, verbose=False, delta=0):

self.patience = patience

self.verbose = verbose

self.counter = 0

self.best_score = None

self.early_stop = False

self.delta = delta

The EarlyStopping class is initialized with several parameters that configure its operation:

patience determines the number of epochs to wait for an improvement in the validation loss before stopping the training. It is set by default to 7, allowing some leeway for the model to overcome potential plateaus in the loss landscape.

verbose controls the output of the class; if set to True, it will print a message for each epoch where the loss does not improve, providing clear feedback during training.

delta sets the threshold for what constitutes an improvement in the loss, aiding in fine-tuning the sensitivity of the early stopping mechanism.

Callable Method

def __call__(self, val_loss):

score = -val_loss

if self.best_score is None:

self.best_score = score

elif score < self.best_score + self.delta:

self.counter += 1

if self.counter >= self.patience:

self.early_stop = True

else:

self.best_score = score

self.counter = 0

The __call__ method allows the EarlyStopping instance to be used as a function, which simplifies its integration into a training loop. It assesses whether the model's performance has improved based on the validation loss from the current epoch.

The method first converts the validation loss into a score that should be maximized; this is done by negating the loss (score = -val_loss), as a lower loss is better. If this is the first evaluation (self.best_score is None), the method sets the current score as the initial best_score.

If the current score is less than self.best_score plus a small delta, indicating no significant improvement, the counter is incremented. This counter tracks how many epochs have passed without improvement. If the counter reaches the patience threshold, it triggers the early_stop flag, indicating that training should be halted.

Conversely, if the current score shows an improvement, the method updates self.best_score with the new score and resets the counter to zero, reflecting the new baseline for future improvements.

This mechanism ensures that the training process is only stopped after a specified number of epochs without meaningful improvement, thereby optimizing the training phase and preventing premature cessation that could lead to underfitting models. By adjusting patience and delta, users can calibrate how sensitive the early stopping is to changes in training performance, allowing them to tailor it to specific scenarios and datasets. This customization is crucial for achieving the best possible model given the computational resources and time available.

5.3: Trainer Class

The Trainer class incorporates the entire training workflow, which includes iterating over epochs, managing the training loop, handling backpropagation, and implementing early stopping protocols to optimize training efficiency and efficacy.

class Trainer:

""""""

Trainer class to train the model.

Args:

-----

model (nn.Module): Neural network model.

criterion (torch.nn.modules.loss): Loss function.

optimizer (torch.optim): Optimizer.

device (torch.device): Device to run the model on.

patience (int): Number of epochs to wait before stopping the training.

""""""

def __init__(self, model, criterion, optimizer, device, patience=7):

self.model = model

self.criterion = criterion

self.optimizer = optimizer

self.device = device

self.early_stopping = EarlyStopping(patience=patience)

self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=3, verbose=True, factor=0.5, min_lr=1e-6)

self.train_losses = []

self.val_losses = []

self.gradient_norms = []

def train(self, train_loader, val_loader, epochs):

""""""

Train the model.

Args:

-----

train_loader (torch.utils.data.DataLoader): DataLoader for training dataset.

val_loader (torch.utils.data.DataLoader): DataLoader for validation dataset.

epochs (int): Number of epochs to train the model.

""""""

for epoch in range(epochs):

self.model.train()

for images, labels in train_loader:

images, labels = images.to(self.device), labels.to(self.device)

self.optimizer.zero_grad()

outputs = self.model(images)

loss = self.criterion(outputs, labels)

loss.backward()

self.optimizer.step()

self.train_losses.append(loss.item())

val_loss = self.evaluate(val_loader)

self.val_losses.append(val_loss)

self.scheduler.step(val_loss)

self.early_stopping(val_loss)

# Log the training and validation loss

print(f'Epoch {epoch+1}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

if self.early_stopping.early_stop:

print(""Early stopping"")

break

def evaluate(self, test_loader):

""""""

Evaluate the model on the test dataset.

Args:

-----

test_loader (torch.utils.data.DataLoader): DataLoader for test dataset.

Returns:

--------

float: Average loss on the test dataset.

""""""

self.model.eval()

total_loss = 0

with torch.no_grad():

for images, labels in test_loader:

images, labels = images.to(self.device), labels.to(self.device)

outputs = self.model(images)

loss = self.criterion(outputs, labels)

total_loss += loss.item()

return total_loss / len(test_loader)

def accuracy(self, test_loader):

""""""

Calculate the accuracy of the model on the test dataset.

Args:

-----

test_loader (torch.utils.data.DataLoader): DataLoader for test dataset.

Returns:

--------

float: Accuracy of the model on the test dataset.

""""""

self.model.eval()

correct = 0

total = 0

with torch.no_grad():

for images, labels in test_loader:

images, labels = images.to(self.device), labels.to(self.device)

outputs = self.model(images)

_, predicted = torch.max(outputs.data, 1)

total += labels.size(0)

correct += (predicted == labels).sum().item()

return correct / total

def plot_losses(self, window_size=100):

# Compute moving averages

train_losses_smooth = self.moving_average(self.train_losses, window_size)

val_losses_smooth = self.moving_average(self.val_losses, window_size)

# Plot

plt.plot(train_losses_smooth, label='Train Loss')

plt.plot(val_losses_smooth, label='Validation Loss')

plt.legend()

plt.grid()

plt.title('Losses')

def moving_average(self, data, window_size):

return np.convolve(data, np.ones(window_size)/window_size, mode='valid')

Initialization

def __init__(self, model, criterion, optimizer, device, patience=7):

self.model = model

self.criterion = criterion

self.optimizer = optimizer

self.device = device

self.early_stopping = EarlyStopping(patience=patience)

self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=3, verbose=True, factor=0.5, min_lr=1e-6)

self.train_losses = []

self.val_losses = []

self.gradient_norms = []

The Trainer class is initialized with the neural network model, the loss function, the optimizer, and the device (CPU or GPU) on which the model will run. This setup ensures that all model computations are directed to the appropriate hardware.

It also configures early stopping and learning rate reduction strategies:

EarlyStopping: Monitors validation loss and stops training if there hasn’t been an improvement for a given number of epochs (patience).

ReduceLROnPlateau: Reduces the learning rate when the validation loss stops improving, which helps in fine-tuning the model by taking smaller steps in the weight space.

Here, train_losses and val_losses collect the loss per epoch for training and validation phases, respectively, allowing for performance tracking and later analysis. gradient_norms could be used to store the norms of the gradients, useful for debugging and ensuring that gradients are neither vanishing nor exploding.

Training Method

def train(self, train_loader, val_loader, epochs):

for epoch in range(epochs):

self.model.train()

for images, labels in train_loader:

images, labels = images.to(self.device), labels.to(self.device)

self.optimizer.zero_grad()

outputs = self.model(images)

loss = self.criterion(outputs, labels)

loss.backward()

self.optimizer.step()

self.train_losses.append(loss.item())

val_loss = self.evaluate(val_loader)

self.val_losses.append(val_loss)

self.scheduler.step(val_loss)

self.early_stopping(val_loss)

# Log the training and validation loss

print(f'Epoch {epoch+1}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

if self.early_stopping.early_stop:

print(""Early stopping"")

break

The train method orchestrates the model training over a specified number of epochs. It processes batches of data, performs backpropagation to update model weights, and evaluates model performance using the validation set at the end of each epoch.

After each epoch, it logs the training and validation losses and updates the learning rate if necessary. The loop may break early if the early stopping condition is triggered, which is checked after evaluating the validation loss.

Evaluation and Accuracy Methods

def evaluate(self, test_loader):

self.model.eval()

total_loss = 0

with torch.no_grad():

for images, labels in test_loader:

images, labels = images.to(self.device), labels.to(self.device)

outputs = self.model(images)

loss = self.criterion(outputs, labels)

total_loss += loss.item()

return total_loss / len(test_loader)

def accuracy(self, test_loader):

self.model.eval()

correct = 0

total = 0

with torch.no_grad():

for images, labels in test_loader:

images, labels = images.to(self.device), labels.to(self.device)

outputs = self.model(images)

_, predicted = torch.max(outputs.data, 1)

total += labels.size(0)

correct += (predicted == labels).sum().item()

return correct / total

The evaluate method assesses the model’s performance on a given dataset (typically the validation or test set) and returns the average loss. This method sets the model to evaluation mode, iterates through the dataset, computes the loss for each batch, and calculates the average loss across all batches.

accuracy calculates the accuracy of the model on a given dataset by comparing the predicted labels with the actual labels. This method processes the dataset in evaluation mode, uses the model’s predictions to compute the number of correct predictions, and returns the accuracy percentage.

Utility Methods for Visualization

def plot_losses(self, window_size=100):

# Compute moving averages

train_losses_smooth = self.moving_average(self.train_losses, window_size)

val_losses_smooth = self.moving_average(self.val_losses, window_size)

# Plot

plt.plot(train_losses_smooth, label='Train Loss')

plt.plot(val_losses_smooth, label='Validation Loss')

plt.legend()

plt.grid()

plt.title('Losses')

def moving_average(self, data, window_size):

return np.convolve(data, np.ones(window_size)/window_size, mode='valid')

This method visualizes the training and validation losses, smoothed over a specified window of epochs to highlight trends more clearly, such as reductions in loss over time or potential points where the model began to overfit.

5.4: Data Preprocessing

To effectively train the AlexNet model, proper data preprocessing is necessary to conform to the input requirements of the model, specifically, the dimension and normalization standards that AlexNet was originally designed with.

Transform

transform = transforms.Compose([

transforms.Resize((224, 224)), # Resize the images to 224x224 for AlexNet compatibility

transforms.ToTensor(), # Convert images to PyTorch tensors

transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize the tensors

])

transforms.Resize((224, 224)) adjusts the size of the images to 224x224 pixels, matching the input size required by the AlexNet model, ensuring that all input images are of the same size.

transforms.ToTensor() converts the images from a PIL format or a NumPy array to a PyTorch tensor, an essential step as PyTorch models expect inputs in tensor format.

transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) normalizes the image tensors; this specific normalization adjusts the mean and standard deviation for all three channels (RGB) to 0.5, effectively scaling pixel values to the range [-1, 1]. This step is crucial as it standardizes the inputs, facilitating the model's learning process.

Loading Dataset

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,

download=True, transform=transform)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,

download=True, transform=transform)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

Here, we load the CIFAR-10 dataset for both training and testing. You might wonder why we didn’t choose the ImageNet dataset, which is known for its extensive use in training models that compete in the ImageNet challenge. The reason is practical: ImageNet requires significant computational resources and lengthy training times, which I wouldn’t recommend attempting on a standard laptop. Instead, we opt for the CIFAR-10 dataset, which includes 60,000 32x32 color images distributed across 10 different classes, with 6,000 images per class.

Disclaimer: The CIFAR-10 dataset is open source and available for use under the MIT License. This license allows for wide freedom in use, including commercial applications.

Split and Data Loader

train_split = 0.8

train_size = int(train_split * len(trainset))

val_size = len(trainset) - train_size

train_dataset, val_dataset = random_split(trainset, [train_size, val_size])

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)

val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)

test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)

The training data is split to set aside 80% for training and 20% for validation. This practice is common to tune the model on unseen data, enhancing its ability to generalize well.

DataLoader objects are created for the training, validation, and test datasets with a batch size of 64. Shuffling is enabled for the training data to ensure randomness, which helps the model learn more effectively by reducing the chance of learning spurious patterns from the order of the data.

Data Visualization

dataiter = iter(train_loader)

images, labels = next(dataiter)

def imshow(img):

img = img / 2 + 0.5 # unnormalize

npimg = img.numpy()

plt.imshow(np.transpose(npimg, (1, 2, 0)))

plt.show()

imshow(torchvision.utils.make_grid(images[:5]))

print(' '.join('%5s' % classes[labels[j]] for j in range(5)))

First, we need to unnormalize the image (img = img / 2 + 0.5). Here imshow converts it from a tensor to a NumPy array, and changes the order of dimensions to fit what matplotlib.pyplot.imshow() expects.

Then, we display the first 5 images in the dataset:

5.5: Model Training and Evaluation

Finally, we set up the training environment for an AlexNet model, executing the training process, and evaluating the model’s performance on a test dataset using PyTorch.

But first, we need to ensure the best computational resource (CPU or GPU) to use, which maximizes performance efficiency.

# Check the system's operating system

if platform.system() == 'Darwin': # Darwin stands for macOS

try:

device = torch.device('cuda')

_ = torch.zeros(1).to(device) # This will raise an error if CUDA is not available

except:

device = torch.device('mps' if torch.backends.mps.is_built() else 'cpu')

else:

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

Here, we identify whether the system is macOS (‘Darwin’) and tries to configure CUDA for use. If CUDA is unavailable, which is common on macOS without NVIDIA GPUs, it opts for MPS (Apple’s Metal Performance Shaders) if available, or CPU otherwise.

On operating systems other than macOS, it directly attempts to utilize CUDA and defaults to CPU if CUDA isn’t available.

Model, Loss Function, and Optimizer Initialization

Next, we initialize the AlexNet model, specifying the computational device, and set up the loss function and optimizer:

model = AlexNet(num_classes=10).to(device)

criterion = nn.CrossEntropyLoss()

optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

An instance of AlexNet is created with 10 classes, and it is immediately transferred to the determined device (GPU or CPU). This ensures all computations for the model are performed on the specified device.

The CrossEntropyLoss function is used for training, which is typical for multi-class classification problems.

The SGD (Stochastic Gradient Descent) optimizer is initialized with the model’s parameters, a learning rate of 0.01, and a momentum of 0.9. These are standard values to start with for many vision-based tasks.

Training the Model

The model undergoes training over a specified number of epochs, handling data in batches, calculating loss, performing backpropagation, and applying early stopping based on the validation loss:

trainer = Trainer(model, criterion, optimizer, device, patience=7)

trainer.train(train_loader, val_loader, epochs=50)

The train method trains the model for 50 epochs using the training and validation data loaders. This method meticulously processes batches from the data loaders, computes the loss, performs backpropagation to update weights, and evaluates the model periodically using the validation dataset to implement early stopping if no improvement is observed in the validation loss.

Model Evaluation

After training, the model’s performance is assessed on the test set using:

test_loss = trainer.evaluate(test_loader)

print(f'Test Loss: {test_loss:.4f}')

accuracy = trainer.accuracy(test_loader)

print(f'Test Accuracy: {accuracy:.2%}')

Finally, the training and validation losses are visualized to monitor the model’s learning progress:

trainer.plot_losses(window_size=3)

This line calls the plot_losses method to visualize the training and validation loss. The losses are smoothed over a window (3 data points in this case) to better visualize trends without noise. By running this code you should expect the following loss:

As shown in the graph above, the model training stopped after 21 epochs because we set the patience parameter to 7, and the validation loss didn’t improve after the 14th epoch. Keep in mind, that this setup is meant for educational purposes, so the goal isn’t to outperform AlexNet.

You’re encouraged to tweak the setup by increasing the number of epochs or the patience to see if the validation loss might drop further. Also, there are several changes and updates you could apply to enhance AlexNet’s performance. Although we won’t cover these adjustments in this article due to our 30-minute limit, you can explore a variety of advanced techniques that could refine the model’s performance.

For those interested in further experimentation, try adjusting parameters like the learning rate, tweaking the network architecture, or using more advanced regularization methods. You can explore more optimization and fine-tuning techniques in this article:

6: Conclusion

AlexNet has been a pivotal model in the evolution of neural network design and training techniques, marking a significant milestone in the field of deep learning. Its innovative use of ReLU activations, overlapping pooling, and GPU-accelerated training dramatically improved the efficiency and effectiveness of neural networks, setting new standards for model architecture.

The introduction of dropout and data augmentation strategies by AlexNet addressed overfitting and improved the generalization capabilities of neural networks, making them more robust and versatile across various tasks. These techniques have become foundational in modern deep-learning frameworks, influencing a wide array of subsequent innovations.

Additional Resources

Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet Classification with Deep Convolutional Neural Networks. Advances In Neural Information Processing Systems. http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf

LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444. https://doi.org/10.1038/nature14539"
https://towardsdatascience.com/meet-the-nicegui-your-soon-to-be-favorite-python-ui-library-fb69f14bb0ac,Meet the NiceGUI: Your Soon-to-be Favorite Python UI Library,"Meet NiceGUI, a simple Python-based UI framework that works smoothly with your web browser or as a desktop app. Whether you’re making small web apps, dashboards, or playing with robotics projects, NiceGUI makes it simple with its easy interface and many features.

The goal of this post is to convince you to try it out by listing the pros and cons of this library and by showing you how you can build and deploy a NiceGUI app. (This is not a sponsored post, I just like the library 🙃)

Streamlit vs. NiceGUI: Why Switch?

While Streamlit is good for making interactive apps, it can be tricky to handle events and states, especially for bigger projects. NiceGUI is different. It lets you control states and interactions directly, without needing extra steps or hacky workarounds.

Simple State Management

NiceGUI makes managing states easy. Unlike Streamlit, which can reset states unexpectedly, NiceGUI keeps things steady, whether it’s the starting state or changes made by users. You can use callbacks to handle user interactions in event-based manner without getting annoyed by a full page refresh and losing state data.

Lots of Features

NiceGUI has many cool features:

Buttons, switches, sliders, inputs, and more for interaction.

Easy ways to arrange things on the screen.

Charts, tables, and even 3D scenes for visuals.

Integration with data visualization libraries like Matplotlib or Plotly.

Customize colors and styles easily.

Tools to help with coding and testing.

Main devs are always available to answer questions and are very receptive to feedback on their GitHub space.

Built on top of popular frameworks: FastAPI, Vue3, Tailwind, Quasar.

Their whole site is made with the NiceGUI library: https://nicegui.io/documentation

Limitations

While NiceGUI is great, it’s worth noting that its smaller community size might be a little limiting. It also has a slightly longer learning curve compared to more popular frameworks like Streamlit. It’s preferable to get familiar with CSS and Tailwind CSS to make the most of the library’s features. Also, knowledge of FastAPI, Vue and Quasar can provide you with greater flexibility and extend what you can implement.

Hands-On

Now, lets explore some features of NiceGUI and then build and deploy a demo app.

Basic app

First install NiceGUI:

pip install nicegui[highcharts]

Lets start from an example from the main documentation:

# https://nicegui.io/documentation/section_data_elements

from nicegui import ui

from random import random

chart = ui.highchart({

'title': False,

'chart': {'type': 'bar'},

'xAxis': {'categories': ['A', 'B']},

'series': [

{'name': 'Alpha', 'data': [0.1, 0.2]},

{'name': 'Beta', 'data': [0.3, 0.4]},

],

}).classes('w-full h-64')

def update():

chart.options['series'][0]['data'][0] = random()

chart.update()

ui.button('Update', on_click=update)

ui.run()

Here, the UI module is what will allow you to create a UI element.

In this example, first we create a highchart element, we assign to it the tailwind classes w-full and h-64. w-full will make it use the whole screen horizontally in a responsive manner and h-64 specifies the height.

When we click on the button, a callback function is triggered. This callback will update the data used for the chart and then re-renders it in a fluid manner.

You can also change the callback to add new bars:

def update():

chart.options[""xAxis""][""categories""].append(random.choice(string.ascii_uppercase))

for series in chart.options['series']:

series[""data""].append(random.random())

chart.update()

Also, notice that refreshing the page does not make you lose your data! You can’t do that with some other Python UI libraries. The reason why it works that way here is that data is shared among all users, but there are lots of ways to keep data user-specific like the app.storage.user object or app.storage.browser (when wrapped around a @ui.page decorator).

But, what if you want to update the UI on a recurrent timer? easy ! Just change the button element to ui.timer

ui.timer(5, callback=lambda: (update(), ui.notify(""Data Updated"")))

Now, let us build a demo app that lets users pick a category then allows them to generate a random Chuck Norris Fact.

First, here is the main code:

import requests # Importing the requests library to make HTTP requests

from nicegui import ui # Importing UI components from the NiceGUI library

from nicegui_app.header import add_head_html # Importing a function to add HTML head content

# List of categories for Chuck Norris facts

CATEGORIES = [

""animal"",

""career"",

""celebrity"",

""dev"",

""fashion"",

""food"",

""money"",

""movie"",

""music"",

""science"",

""sport"",

""travel"",

]

# Class to handle Chuck Norris facts

class Fact:

def __init__(self):

self.fact = None # Initialize the fact attribute to None

# Method to update the fact based on a given category

def update_fact(self, category):

url = f""https://api.chucknorris.io/jokes/random?category={category}"" # URL to Chuck Norris API

for i in range(10): # Try up to 10 times to fetch a valid fact

result = requests.get(url) # Make a GET request to the Chuck Norris API

if result.status_code == 200: # If the request is successful

result_json = result.json() # Parse the JSON response

if self.fact != result_json[""value""]: # If the fetched fact is different from the current one

self.fact = result_json[""value""] # Update the fact attribute

break # Exit the loop

# Function to generate the Chuck Norris fact UI

def chuck():

add_head_html() # Add HTML head content for the NiceGUI app

default_value = CATEGORIES[0] # Default category for Chuck Norris facts

fact = Fact() # Create an instance of the Fact class

fact.update_fact(default_value) # Update the fact using the default category

# Create a grid layout with 12 columns

with ui.grid(columns=12).classes(""w-full""):

# Column for category selection

with ui.column().classes(""col-span-4 sm:col-span-2 space-x-0""):

ui.label(""Pick a fact category:"") # Display a label for category selection

# Radio button group for selecting categories

category = ui.radio(

CATEGORIES,

value=default_value,

on_change=lambda _: fact.update_fact(category.value), # Update the fact when the category changes

).classes(""w-full"")

# Button to regenerate the fact for the selected category

ui.button(

""⟳ Re-Generate"", on_click=lambda _: fact.update_fact(category.value)

)

# Column for displaying the Chuck Norris fact

with ui.column().classes(

""flex col-span-8 sm:col-span-10 w-full justify-center mx-auto max-w-screen-md""

):

# Label to display the Chuck Norris fact, bound to the fact attribute of the Fact instance

ui.label().bind_text_from(fact, ""fact"").classes(

""text-lg sm:text-3xl text-gray-800 bg-gray-100 rounded-lg shadow-lg p-6""

)

Now let us go through it step by step:

First, we make the necessary imports and define the possible categories.

Then, we define the class that will store and update our random fact:

class Fact:

def __init__(self):

self.fact = None # Initialize the fact attribute to None

# Method to update the fact based on a given category

def update_fact(self, category):

url = f""https://api.chucknorris.io/jokes/random?category={category}"" # URL to Chuck Norris API

for i in range(10): # Try up to 10 times to fetch a valid fact

result = requests.get(url) # Make a GET request to the Chuck Norris API

if result.status_code == 200: # If the request is successful

result_json = result.json() # Parse the JSON response

if self.fact != result_json[""value""]: # If the fetched fact is different from the current one

self.fact = result_json[""value""] # Update the fact attribute

break # Exit the loop

This class stores the fact in the attribute “fact” and has a method update_fact that calls the Chuck Norris facts api. https://api.chucknorris.io

Next, we define our page in the “chuck” function. NiceGUI adopts a modular approach that lets you define your app over multiple modules and python files.

We define an instance of our data class fact = Fact() This is a specific instance to each user. Next, we init the fact using the update_fact method.

Now, we start defining our UI elements.

We define a grid with two columns:

A first column that has our category options and generate button. This one has the following tailwind classes: col-span-4 sm:col-span-2. It means that for very small screens it will use up 4/12 of the screen, otherwise it will use up 2/12. This makes the design work in mobile phones too.

A second column where we will display the fact.

For the first column:

A radio menu ui.radio.

A button to generate a random fact.

Both elements, when clicked or changed will use a callback that calls fact.update_fact

For the second column:

We have a ui.label that binds its value to fact.fact so each time this variable changes, it will update the display automatically.

The label has the following tailwind classes: text-lg sm:text-3xl This makes it so the text is smaller on small screens.

This gives you the following app:

Neat! right?

Deployment

Deploying such app is easy! Using CloudRun for example. You just have to create a Dockerfile and then run the following gcloud instructions:

PROJECT_ID=$(gcloud config get-value project)

REPO=""demo""

LOCATION=""europe-west1""

IMAGE=""nicegui_app""

SERVICE_NAME=""nicegui-app""

VERSION=""0.0.1""

GAR_TAG=$LOCATION-docker.pkg.dev/$PROJECT_ID/$REPO/$IMAGE:$VERSION

# Create repository

gcloud artifacts repositories create $REPO --repository-format=docker \

--location=$LOCATION --description=""Docker repository"" \

--project=$PROJECT_ID || true # If fails because already exist then its fine

# Build image

gcloud builds submit --tag $GAR_TAG

# Deploy Cloud run

gcloud run deploy $SERVICE_NAME --image=$GAR_TAG --max-instances=1 --min-instances=0 --port=8080 \

--allow-unauthenticated --region=europe-west1 --memory=0.5Gi --cpu=1 -q --no-cpu-throttling --session-affinity

This builds the docker image using cloud build and then deploys it to CloudRun.

The only key options here are: “ — no-cpu-throttling — session-affinity” This allows the same user to be routed the same container when possible and keeps the CPU alive between requests. You can try it out here: https://nicegui-app-dfmj3maizq-ew.a.run.app/

In Conclusion

NiceGUI is a great choice if you want to make user interfaces quickly and easily with Python. It will help you build powerful python apps where you retain full control of the internal state and that you can test and deploy easily. Hopefully, it can allow you to express your creativity in your data science projects without being limited by tools.

What was shown here is just a small fraction of what you can do with NiceGUI. You can learn more by following the links below.

Resources:"
https://hub.jhu.edu/2024/04/11/data-science-institute-plans-presented-to-city-panel/,Johns Hopkins University presents building plans for Data Science and AI Institute to city panel,"Johns Hopkins University on Thursday presented design plans for the Data Science and Artificial Intelligence (DSAI) facility to the Baltimore City Department of Planning's Urban Planning Architecture Advisory Panel (UDAAP).

DSAI, a cornerstone of JHU's Ten for One strategic plan, will be a leading hub for data science and artificial intelligence to drive research and teaching in every corner of the university and magnify our impact in every corner of the world. The institute will bring together world-class experts in artificial intelligence, machine learning, applied mathematics, computer engineering and computer science to fuel data-driven discovery in support of research activities across the institution.

In all, 80 new affiliated faculty will join JHU's Whiting School of Engineering to support the institute's pursuits, in addition to 30 new Bloomberg Distinguished Professors with substantial cross-disciplinary expertise to ensure the impact of the new institute is felt across the university.

The initiative is led by the Whiting School of Engineering and the new facility will sit adjacent to existing engineering buildings on the south side of the Homewood campus. ""The basic idea is to place the people who generate the data beside the people who analyze the data,"" said Whiting School Dean Ed Schlesinger.

The two-building facility will be organized into ""neighborhoods,"" purposely collocating disciplines including bioengineering, materials, energy and environment with thematic wings dedicated to areas such as health and medicine, scientific discovery, and engineering systems. Unlike traditional academic silos, these groupings will create a world-class AI space for cross-disciplinary research and translation and will help establish an innovation district in the heart of Baltimore.

Just this fall, the federal government designated the greater Baltimore region as a ""Tech Hub."" Through DSAI, Hopkins can make vital contributions to Baltimore's growth as a tech hub, creating long-term jobs, attracting top talent, and spurring the growth of new companies that will compete in one of the world's most promising fields.

""This institute intends to spur a virtuous cycle of new research, product innovation, startups, private investment, and jobs,"" says Christy Wyskiel, senior adviser to the president for innovation and entrepreneurship. ""Our vision is that researchers, entrepreneurs, investors, and companies will look to Baltimore as the place to develop and launch products and companies based on data science and AI technology.""

Design architect and architect of record, ZGF, is designing the DSAI facility to appear as a series of smaller buildings arranged along the site, creatively dispersed and rotated to provide setbacks featuring a raised hillside, trees, and rich landscaping along Remington Avenue.

""This is an amazing site, part of the main campus, yet so connected to the experience of Remington,"" said ZGF design architect Vlad Pajkic. ""The building's concept, based on the deliberate and inventive arrangement of thematic research neighborhoods, will give the facility a more human scale, appropriate for its location and its function.""

The building will target a USGBC LEED Gold Rating. With on-site energy production and electrification, DSAI will be the Homewood campus' first net zero ready carbon facility (excluding emergency generation as mandated by the City of Baltimore). The design, especially storm water and erosion control, will strictly abide by the city's rigorous Site Plan Review Committee process, which prohibits overcharge into adjacent natural habitats or city infrastructure. No building or associated site work will encroach on the university's Forest Conservation Easement.

This project will include significant improvements to the Remington Avenue streetscape and replace three existing structures: the temporary facility that housed the Early Learning Center since 2015, a chiller plant facility that until recently served the Wyman Park Precinct, and the central plant that served the original Merchant Marine Hospital complex. The new facility and the associated open greenspace will also complement the soon-to-be-completed SNF Agora Institute.

The Whiting-Turner Contracting Company and Mahogany Inc. are managing construction for the project, which is anticipated to add 500 trade jobs to boost Baltimore's economy and will indirectly contribute to thousands of new jobs around the city. In alignment with JHU's HopkinsLocal program, the project will also include 20% MBE/WBE and 20% LBE participation. According to Jeff Hargrave, founder and president of Mahogany Inc.: ""Being part of such a transformative project means everything to Mahogany and our city. Johns Hopkins' commitment to improving our city is truly remarkable.""

Preparatory work is scheduled to begin in fall 2024. JHU anticipates the buildings will be occupied by summer 2029."
https://news.unchealthcare.org/2024/04/haendel-to-join-unc-genetics-pediatrics-data-science-society-to-advance-precision-medicine-in-nc/,"Haendel to join UNC Genetics, Pediatrics, Data Science & Society to Advance Precision Medicine in NC","Melissa Haendel, PhD, and her lab of 25-plus members will join UNC-Chapel Hill to focus on early diagnosis of childhood diseases and significantly improve quality of life outcomes.

The University of North Carolina at Chapel Hill is delighted to welcome Dr. Melissa A. Haendel, PhD, FACMI, as the Sarah Graham Kenan Distinguished Professor in the Department of Genetics within the School of Medicine, starting April 15. Haendel’s groundbreaking work in biomedical informatics is set to significantly contribute to our pursuit of advanced healthcare solutions. In addition to her primary appointment, she will bring her considerable knowledge to the roles of professor in both the Department of Pediatrics and the forward-thinking School of Data Science and Society.

She joins UNC-CH from the University of Colorado Anschutz Medical Campus, where she leads the Translational and Integrative Sciences Laboratory and is the Chief Research Informatics officer, Marsico endowed chair in data science, and a Professor of Biomedical Informatics in the CU School of Medicine.

Expressing her enthusiasm, Haendel remarks, “The opportunity to collaborate with the vibrant communities at UNC-CH, UNC Health, and throughout North Carolina is incredibly exciting. We are poised to make genomic medicine a reality for all North Carolinians, leveraging our team’s diverse skills to tackle the most pressing issues in precision medicine.”

Haendel will serve as the Director of Precision Health & Translational Informatics and contribute her expertise as Deputy Director of Computational Science at NC TraCS, the hub of the UNC Clinical and Translational Science Award. Additionally, she will advise on Research Data Interoperability within the UNC Health System and participate in both the Computational Medicine Program and the Program in Precision Medicine and Healthcare. This combination of roles is expected to greatly extend the reach of her impactful work.

Emily Pfaff, PhD, assistant professor in the UNC Department of Medicine,commented “Melissa’s emphasis on the importance of collaboration and team science in informatics will make her an asset to our CTSA. She brings a number of exciting projects emphasizing critical areas in translational science, including real world data analysis, data linkage, and using informatics methods to address rare diseases and rural health disparities. As a long-time collaborator of Melissa’s, I could not be more excited to welcome her and her team to UNC Chapel Hill.”

“We are absolutely delighted that Dr. Melissa Haendel is joining us in the UNC School of Medicine,” said Blossom Damania, PhD, Vice Dean for Research, School of Medicine. “Dr. Haendel is an international leader in informatics and data science. She is an exceptional scientist with a remarkable vision to advance public health surveillance for rare diseases. Melissa has already established significant collaborations with many faculty across the School of Medicine, UNC campus, and UNC Health. Her research program will advance the early diagnosis of childhood diseases and significantly improve quality of life outcomes. We are thrilled to have Dr. Haendel as part of our community.”

Haendel characterizes her work as “the art of data translation,” leading initiatives that aim to improve data integration and promote collaborative education. She has played a pivotal role in enhancing national data sharing and interoperability – particularly notable during the COVID-19 pandemic with the creation of the National COVID Cohort Collaborative Data (N3C), which has been vital in our understanding of the virus. This work earned her and her team the NIH/FASEB DataWorks! Grand Prize in 2023.

“We are enormously excited and grateful that Melissa has decided to join us in the Department of Genetics. Her recruitment is perfectly aligned with the department’s strategic investments over the past four years in support of team science,” said Fernando Pardo-Manuel de Villena, PhD, professor and chair of the Department of Genetics. “Her program is an exceptional example of how to accelerate and multiply the impact of research conducted by faculty and trainees in a basic science department in the School of Medicine.”

Haendel also co-founded the Monarch Initiative, an international consortium dedicated to the integration of model organism and human data to support rare disease diagnostics and mechanism discovery. She brings with her to UNC a National Human Genome Research Institute Center of Excellence in Genome Sciences that is dedicated to making phenotypic data computable for genomic health applications.

“The talents and expertise brought by Haendel and her team will enable us to dramatically improve and streamline the way that patients with rare disease are identified, diagnosed, and cared for within the UNC Health system. We are also excited about the many opportunities for collaboration on genomic medicine research projects led by faculty in the Department of Genetics”, said Jonathan Berg, MD, PhD, the Bryson Distinguished Professor in the UNC Departments of Genetics and Medicine.

After earning her doctorate in neuroscience at the University of Wisconsin, she completed post-doctoral fellowships in developmental biology at the University of Oregon and in toxicology at Oregon State University. In 2010, Haendel joined the Oregon Health & Science University faculty. She joined the University of Colorado Anschutz Medical Campus in 2021. Haendel is currently a principal investigator on 10 externally funded programs totaling more than $25 million per year. She is the author of more than 190 peer-reviewed research articles and 57 book chapters, editorials, and reviews. Her work is frequently referenced in the scientific literature, with more than 20,000 citations to date."
https://news.vanderbilt.edu/2024/03/25/vanderbilt-to-establish-a-college-dedicated-to-computing-ai-and-data-science/,"Vanderbilt to establish a college dedicated to computing, AI and data science","Vanderbilt has begun work to establish a transformative college dedicated to computer science, AI, data science and related fields, university leaders announced today. In addition to meeting the growing demand for degrees in technological fields and advancing research in rapidly evolving, computing-related disciplines, the new, interdisciplinary college will collaborate with all of Vanderbilt’s schools and colleges to advance breakthrough discoveries and strengthen computing education through a “computing for all” approach.

The College of Connected Computing will be led by a new dean, who will report to Provost and Vice Chancellor for Academic Affairs C. Cybele Raver and to School of Engineering Dean Krishnendu “Krish” Roy. The search for the college’s dean is scheduled to begin in late August, and recruiting of faculty will begin in the coming months. It will be the first new college at Vanderbilt since the university and the Blair School of Music merged in 1981.

“Of all the factors shaping society, few are more influential than the rapid emergence of advanced computing, AI and data science,” Chancellor Daniel Diermeier said. “To continue to carry out our mission, prepare all our students for their careers and advance research across the university, Vanderbilt must contribute even more to the study, understanding and innovative application of these fast-changing disciplines. Our aim is to make Vanderbilt a global leader in these fields, ensuring our continued academic excellence and capacity for world-changing innovation.”

“Our new college will enable us to build upon our strong programs and catapult Vanderbilt to the forefront of breakthrough discovery and innovation—in key areas of computer science and also in a wide range of other disciplines that capitalize on advanced computational methods. In launching this new college, we will provide students with highest-caliber educational opportunities at the intersection of these pathbreaking fields,” Raver said. “The creation of this college represents a tremendous win and will be transformative for our entire university community.”

Raver noted the ways that Vanderbilt is forging a bold and distinct strategic path to address burgeoning research and educational opportunities, including increasing demand for expertise in computing-related fields. Moreover, she said, the global interest in AI “aligns perfectly” with Vanderbilt’s leading work in that field. She said a dedicated college will enable Vanderbilt to keep making groundbreaking discoveries at the intersections of computing and other disciplines and will more effectively leverage advanced computing to address some of society’s most pressing challenges.

“The establishment of this interdisciplinary, ‘cross-cutting’ college is a watershed moment—not only for the School of Engineering, but also for the entire university,” Roy said. “The future of education, research and thinking in all disciplines is now inherently tied to, and will be greatly influenced by, the knowledge and power of computing. The idea of ‘computing for all’ is fundamental to the future of learning.”

Many of the specific details about the college—including its departments, degree programs and research infrastructure—will be informed by the recommendations of a task force on connected computing composed of faculty from across the university. In addition, Vice Provost for Research and Innovation Padma Raghavan will launch a Computing Catalyst working group that will engage faculty and staff leaders in computing from across campus and solicit their input on strategically expanding the university’s computing resources. “The decision to establish this new college is rooted in conversations with faculty,” Raver said. “We are continuing that faculty engagement with this working group, and we’re fortunate to have the advice of some of the best minds in these fields as we embark on this exciting journey.”

The members of the Connected Computing Task Force include:

Krishnendu Roy, Chair

Bruce and Bridgitt Evans Dean of Engineering

University Distinguished Professor of Biomedical Engineering; Pathology, Microbiology and Immunology; and Chemical and Biomolecular Engineering

Douglas Adams

Vice Dean of the School of Engineering

Daniel F. Flowers Chair

Distinguished Professor of Civil and Environmental Engineering

Professor of Mechanical Engineering

Faculty Affiliate, VINSE

Hiba Baroud

Associate Chair and Associate Professor of Civil and Environmental Engineering

James and Alice B. Clark Foundation Faculty Fellow

Associate Professor of Computer Science

Faculty Affiliate, VECTOR, Data Science Institute

Gautam Biswas

Cornelius Vanderbilt Professor of Computer Science and Computer Engineering

Professor of Engineering Management

Senior Research Scientist, ISIS

Faculty Affiliate, Data Science Institute

Erin Calipari

Associate Professor of Pharmacology

Associate Professor of Molecular Physiology & Biophysics

Associate Professor of Psychiatry & Behavioral Sciences

Director, Vanderbilt Center for Addiction Research

Faculty Affiliate, Vanderbilt Brain Institute

Laurie Cutting

Patricia and Rodes Hart Professor and Professor of Special Education

Professor of Psychology

Professor of Pediatrics

Professor of Electrical and Computer Engineering

Professor of Radiology & Radiological Sciences

Associate Provost in the Office of the Vice Provost of Research and Innovation

Associate Director of the Vanderbilt Kennedy Center

Faculty Affiliate, Vanderbilt Brain Institute

Benoit Dawant

Cornelius Vanderbilt Professor of Electrical Engineering

Incoming Chair of the Department of Electrical and Computer Engineering

Director and Steering Committee Chair, Vanderbilt Institute for Surgery & Engineering

Professor of Biomedical Engineering

Professor of Computer Science

Abhishek Dubey

Associate Professor of Computer Science

Associate Professor of Electrical and Computer Engineering

Director, SCOPE lab at ISIS

Faculty Affiliate, Institute for Software Integrated Systems and Data Science Institute

Bennett Landman

Stevenson Professor of Electrical and Computer Engineering and Chair of the Department of Electrical and Computer Engineering

Professor of Biomedical Engineering

Professor of Computer Science

Professor of Neurology

Associate Professor of Biomedical Informatics

Associate Professor of Psychiatry and Behavioral Sciences

Associate Professor of Radiology and Radiological Sciences

Faculty Affiliate, Vanderbilt Institute for Surgery and Engineering (VISE), Vanderbilt Brain Institute, Vanderbilt Kennedy Center, Vanderbilt University Institute of Image Science (VUIIS), Data Science Institute

Michael Matheny

Professor of Biomedical Informatics

Professor of Biostatistics

Professor of Medicine

Director, Center for Improving the Public’s Health Through Informatics

Sandeep Neema

Professor of Computer Science

Professor of Electrical and Computer Engineering

Chair of the Executive Council, Institute for Software Integrated Systems

Ipek Oguz

Assistant Professor of Computer Science

Assistant Professor of Biomedical Engineering

Assistant Professor of Electrical & Computer Engineering

Faculty Affiliate, Vanderbilt Institute for Surgery and Engineering (VISE)

J.B. Ruhl

David Daniels Allen Distinguished Chair of Law

Director, Program in Law and Innovation

Co-Director, Energy, Environment and Land Use Program

Faculty Affiliate, Data Science Institute

Jesse Spencer-Smith

Professor of the Practice of Computer Science

Adjunct Professor of Psychology

Interim Director and Chief Data Scientist, Data Science Institute

Jonathan Sprinkle

Professor of Computer Science

Professor of Electrical & Computer Engineering

Professor of Civil & Environmental Engineering

Faculty Affiliate, Institute for Software Integrated Systems

Yuankai “Kenny” Tao

Associate Professor of Biomedical Engineering

Associate Professor of Ophthalmology & Visual Sciences

SPIE Faculty Fellow in Engineering

Faculty Affiliate, Vanderbilt Institute for Surgery & Engineering

Holly Tucker

Mellon Foundation Chair in the Humanities

Professor of French

Director, Robert Penn Warren Center for the Humanities

Kalman Varga

Vice Chair of the Department of Physics & Astronomy

Professor of Physics

Director, Minor in Scientific Computing

Faculty Affiliate, VINSE

Steven Wernke

Chair of the Department of Anthropology

Associate Professor of Anthropology

Director, Vanderbilt Institute for Spatial Research (VISR)

Faculty Affiliate, Data Science Institute

Jules White

Professor of Computer Science

Associate Professor of Biomedical Informatics

Senior Advisor to the Chancellor for Generative AI in Education and Enterprise Solutions

Faculty Affiliate, Institute for Software Integrated Systems, Data Science Institute

Dan Work

Director of Graduate Studies in Civil Engineering

Professor of Civil & Environmental Engineering

Professor of Computer Science

Faculty Affiliate, VECTOR, Institute for Software Integrated Systems, Data Science Institute

Tracey George

ex officio

Vice Provost for Faculty Affairs and Professional Education

Charles B. Cox III and Lucy D. Cox Family Chair in Law and Liberty

Professor of Law

Tiffiny Tung

Ex officio

Vice Provost for Undergraduate Education

Gertrude Conaway Vanderbilt Chair in the Social and Natural Sciences

Professor of Anthropology"
https://towardsdatascience.com/how-i-became-a-data-scientist-as-an-international-student-with-broken-english-cce01d6db840,How I Became a Data Scientist as an International Student with Broken English,"Took a long time but I found what I enjoy doing for the rest of my life

Currently, I am a data scientist over 4 years of experience. I want to delve into my own journey — a gradual process of discovering my passion for data science. It took me quite a while to figure out my career path, but the journey was certainly worthwhile. I hope my story serves as inspiration to anyone out there who may be struggling to become a data scientist or doubting their own abilities.

Arriving in the States with limited English Skills

“I work at a meth lab”. This was how poor my English was when I first moved to the States all by myself. I didn’t know there was a difference between “meth” and “math”. It took me about a year to finally grasp the distinction. I wasn’t involved in making drugs; instead, I was a math tutor at The Math Lab at City College of San Francisco (CCSF).

After failing the college entry exam in South Korea, I relocated myself to the United States, believing I can build a new life here. I was a bold and naive 18 years old girl. I vividly remember the first few days in downtown San Francisco, where I couldn’t even manage to order a simple cup of coffee at Starbucks. I stumbled over my words, leaving the employee perplexed, and she responded in rapid English. Feeling overwhelmed, I resorted to a bow of thanks, a gesture from Korean culture, before hastily leaving the store.

Discovering my passion for Statistics at a Community College

To improve my English skills, I enrolled in a community college. There, I explored various subjects, including German, Swimming, Computer Science, Math, English and Statistics. Amidst this exploration, I found my passion. My childhood dream was to become a math teacher, driven by my love for Mathematics and children. As I pursued relevant courses, I found that taking Statistics was a game-changer. I fell in love with every aspect of it, which ultimately led me to pursue a major in Statistics when transferring.

Becoming a First Generation College Student

My parents never left South Korea, let alone attended a college. When I gained the admission to multiple universities, they were unfamiliar with prestigious institutions like UC Berkeley. Nonetheless, they were willing to support me financially, covering tuition and living expenses, proud in the knowledge that their daughter was embarking on a college education.

Struggling to Pursue Actuarial Career

As a junior majoring Statistics at UC Berkeley, I explored potential career paths. I joined both Statistics club and Actuarial club to gain insights. Initially, becoming an actuary seemed like a logical choice — I enjoyed solving math problems, passed a few actuarial exams, and completed an actuarial internship. However, I encountered difficulties in securing a full-time actuarial position. Despite this setback, I now see it as a learning experience. Looking back, I realize that my current job brings me more satisfaction than I would have found in an actuarial role.

Introduction to Data Science in Business

Upon graduating, I had two job offers: a data analytics internship at a startup and a merchandise planner position at an e-commerce company. I chose to become a merchandise planner and had the opportunity to collaborate with data scientists there. They were working on developing a machine learning model for demand forecasting and pricing, a topic I had throughly enjoyed studying during my time at UC Berkeley. Witnessing the practical application of machine learning in business was incredibly rewarding. Seeking guidance, I turned to a data scientist I knew at the company. He advised me to pursue further education to become a data scientist, especially considering the visa challenges I faced as an international student.

The Value of a Master’s Degree in Statistics (now known as Applied Data Science)

I moved to Pittsburgh, PA to pursue my master’s degree at Carnegie Mellon University (CMU). Taking the Statistical Computing course with Professor Alex Reinhart enhanced my Python skills, while the Data Mining course from Professor Sivaraman Balakrishnan prepared me well for machine learning interviews. I went to their office hours almost every week and they were tremendously helpful. The quality education I received at CMU enabled me to leverage my coding skills, project experiences, and coursework knowledge to successfully navigate data science interviews.

Finally Landing 4 Job Offers for a Data Analyst & Data Scientist

It wasn’t easy. Over a span of 4–5 months, I applied to approximately 700 jobs, targeting junior data scientist positions. I didn’t know which company was hiring foreign employees, so I applied all. Despite the uncertainty, I received responses from over 20 companies and progressed to the final stages with 4 of them, all of which extended job offers.

The Lesson Learned

It took considerable time and effort to reach this point, and the journey was challenging and unpredictable. Job hunting was fraught with setbacks and stress, but my belief in my abilities kept me going and ultimately led me to success in this field. I firmly believe that anyone equipped with the right skills and a positive mindset can forge a career in data science. I hope my story serves as inspiration to others!"
https://towardsdatascience.com/addressing-spatial-dependencies-674c6d670071,How to Address Spatial Dependencies,"Remote sensing, a field that deals with tons of spatial data extracted and processed from satellite images, aerial photos, and other sensor-based technologies, or any field using data with spatial features, presents a non-trivial challenge. When we analyze all this data, we have to deal with spatial dependencies (i.e., how things that are close together can influence each other). As Crawford (2009) aptly puts it:

Spatial dependence refers to the degree of spatial autocorrelation between independently measured values observed in geographical space.

These spatial dependencies can often lead to autocorrelated errors in statistical models, where observations near each other tend to exhibit similar error characteristics not captured by the explanatory variables alone.

To dig deep into spatial autocorrelation, check a nice YouTube video of a lecture by Luc Anselin at the University of Chicago (October 2016). I also invite you to briefly check my previous post, Spatial Cross-Validation in Geographic Data Analysis (March 22, 2024), where I expose the importance of modeling spatial relationships accounting for spatial correlation to improve the performance, reliability, and predictive power of a model.

One technique particularly useful in spatial analysis to address spatial dependencies in the error terms of a regression model is the Spatial Error Model (SEM).

What is the SEM?

This is a statistical technique that incorporates spatial autocorrelation into regression analyses. Unlike traditional regression models, which assume independence among observations, spatial regression models such as SEM consider the location-based interdependencies among data points.

Due to proximity, regressing spatial data often yields error terms correlated with each other. That means we can hypothesize that missing processes (not captured by the considered covariates) likely spillover into our outcomes. Therefore, this correlation can lead to biased and inefficient estimates if not properly addressed.

Well… SEM handles this by incorporating spatial weights or adding spatial autocorrelation structure…"
https://www.simplilearn.com/data-analyst-job-description-article,"Data Analyst Job Description [Skills, Roles and Responsibilities]","Reviewed and fact-checked by Sayantoni Das

Data analysis is a critical field that is pivotal in interpreting complex data to help businesses make informed decisions. With the advent of big data, the demand for skilled data analysts has surged across various industries. Here's a detailed exploration of the data analyst job, including what data analysis entails, the role of a data analyst, their importance in today's data-driven world, and what skills are required for data analysts.

Key Takeaways:

Data Analysts plan decision-making, improve efficiency, enhance customer experiences, and manage risks by interpreting complex data sets.

Success in data analysis demands a blend of technical skills (data cleaning and statistical analysis) and soft skills (critical thinking and communication).

The surge in data usage has significantly increased the demand for skilled data analysts across various sectors.

Watch the video below that will help you have an understanding of the various responsibilities, skills required, and the salary structure of top Data Analytics job roles.

What Is Data Analysis?

Data analysis involves collecting, processing, and performing statistical analyses on large datasets to discover useful information, suggest conclusions, and support decision-making. It encompasses various techniques under various umbrellas, such as descriptive statistics, exploratory data analysis (EDA), and inferential statistics, to interpret and understand the patterns and behaviors within data. Data analysis aims to extract actionable insights from raw data that can influence strategies and operations.

Become a Data Science & Business Analytics Professional

28%Annual Job Growth By 2026

11.5 MExpected New Jobs For Data Science By 2026

Data Analyst

Industry-recognized Data Analyst Master’s certificate from Simplilearn

Dedicated live sessions by faculty of industry experts

Post Graduate Program in Data Analytics

Post Graduate Program certificate and Alumni Association membership

Exclusive hackathons and Ask me Anything sessions by IBM

prevNext

Here's what learners are saying regarding our programs:

Gayathri Ramesh

Associate Data Engineer , Publicis Sapient

The course was well structured and curated. The live classes were extremely helpful. They made learning more productive and interactive. The program helped me change my domain from a data analyst to an Associate Data Engineer.

Felix Chong

Project Manage , Codethink

After completing this course, I landed a new job & a salary hike of 30%. I now work with Zuhlke Group as a Project Manager.

prevNext

Not sure what you’re looking for?View all Related Programs

What Does a Data Analyst Do?

A data analyst systematically collects, processes, and performs statistical analyses on data sets. Their responsibilities include:

Data Cleaning and Preparation: This involves filtering the data, handling missing values, and preparing the dataset for analysis to ensure accuracy and relevance.

Data Exploration and Analysis: Analysts use statistical tools and techniques to explore and analyze data, identifying patterns, relationships, and trends.

Data Visualization: They create visual representations of data findings through charts, graphs, and dashboards to make the data understandable at a glance.

Reporting: Data analysts prepare reports and presentations to communicate the insights and findings from the data to stakeholders, which can influence policy and decision-making processes.

Collaboration: They often work with other departments to understand their data needs and help them make informed decisions based on data insights.

Importance of Data Analysts in Today’s Data-Driven World

In today's data-driven world, data analysts are indispensable and play a crucial role in various aspects:

Strategic Decision-Making: Data analysts provide the groundwork for strategic decision-making by uncovering trends and insights that can guide business strategies and improve outcomes.

Improving Efficiency: By identifying areas of inefficiency within operations, data analysts help organizations streamline processes, reduce costs, and increase productivity.

Enhancing Customer Experiences: Analyzing customer data allows businesses to understand customer behaviors and preferences, leading to improved products and services.

Risk Management: Data analysis helps identify potential risks and challenges, enabling businesses to devise strategies to mitigate these risks.

Data Analyst Job Description: Roles and Responsibilities

A Data Analyst job description typically outlines the key roles, responsibilities, and qualifications required for the position. Data Analysts are tasked with turning data into information, information into insight, and insight into business decisions. Below is a detailed job description highlighting the roles and responsibilities of a Data Analyst position.

Job Overview

The Data Analyst is responsible for overseeing our data systems and reporting frameworks, guaranteeing the integrity and precision of data. The ideal candidate will transform raw data into structured information, which will then be analyzed to glean insights that drive strategic business decisions. This position encompasses a comprehensive analysis lifecycle, covering requirement gathering, activity execution, and design planning. Data analysts are tasked with enhancing analytical and reporting functions, as well as supervising performance and quality assurance processes to pinpoint areas for enhancement.

Roles and Responsibilities

Gather data from primary and secondary sources, ensuring the upkeep of databases and data systems.

Detect, examine, and decode trends or patterns within intricate datasets.

Cleanse data and scrutinize computer-generated reports and outputs to identify and rectify coding errors.

Coordinate with management to align business and informational priorities.

Identify opportunities for process enhancements.

Employ statistical techniques to scrutinize data and produce actionable business insights.

Collaborate with the management team to determine and rank the needs of different business units.

Develop data dashboards, charts, and visual aids to support decision-making across departments.

Convey insights through both reports and visual presentations.

Partner with engineering and product development teams to understand business requirements.

Engage with managers from various departments to specify data requirements for analysis projects tailored to their unique business processes.

Skills and Qualifications

Possess a solid foundation in statistics and practical experience with statistical software (such as Excel, SPSS, SAS) and mastery in data analysis languages including SQL, Python, and R.

Exhibit exceptional analytical abilities to compile, structure, examine, and present substantial data sets with precision and thoroughness.

Capable of critically evaluating data to derive meaningful, actionable insights.

Demonstrate superior communication and presentation capabilities, adept at simplifying complex data insights for audiences without a technical background.

A bachelor's degree in Computer Science, Information Management, Statistics, or a comparable discipline is required, with prior experience in data analysis or a related field being advantageous.

Additional Requirements

Adept at report writing and presenting findings.

Ability to work under pressure and meet tight deadlines.

A deep understanding of the industry and business operations is a plus.

Become a Data Science & Business Analytics Professional

28%Annual Job Growth By 2026

11.5 MExpected New Jobs For Data Science By 2026

Data Analyst

Industry-recognized Data Analyst Master’s certificate from Simplilearn

Dedicated live sessions by faculty of industry experts

Post Graduate Program in Data Analytics

Post Graduate Program certificate and Alumni Association membership

Exclusive hackathons and Ask me Anything sessions by IBM

prevNext

Here's what learners are saying regarding our programs:

Gayathri Ramesh

Associate Data Engineer , Publicis Sapient

The course was well structured and curated. The live classes were extremely helpful. They made learning more productive and interactive. The program helped me change my domain from a data analyst to an Associate Data Engineer.

Felix Chong

Project Manage , Codethink

After completing this course, I landed a new job & a salary hike of 30%. I now work with Zuhlke Group as a Project Manager.

prevNext

Not sure what you’re looking for?View all Related Programs

20 Essential Data Analyst Skills

Data analysts are pivotal in transforming raw data into insights that can drive business decisions. To excel in this field, the skills for data analyst range from technical proficiency to soft skills. Here’s a detailed look at the 20 essential skills for data analysts:

1. Data Cleaning and Preparation

The ability to clean and prepare data is fundamental. This involves handling missing data, removing outliers, and ensuring that the dataset is in a usable format for analysis.

2. Data Analysis and Exploration

Data analysts must use statistical methods and techniques to explore and analyze data, identifying patterns, trends, and relationships within the dataset.

3. Statistical Analysis

A robust understanding of statistical concepts and methods is crucial for interpreting data and performing analyses that can inform decision-making processes.

4. Programming

Knowledge of languages such as Python, R, or SQL is essential for manipulating data, automating tasks, and performing complex analyses.

5. Database Management

Skills in managing and querying databases are vital for accessing and managing large datasets, using SQL for structured databases or NoSQL for unstructured data.

6. Creating Dashboards and Reports

The ability to create interactive dashboards and detailed reports is important for presenting data insights in a clear and accessible manner to stakeholders.

7. Data Visualization

Proficiency in data visualization tools and techniques, such as Tableau or Power BI, helps present data findings visually to enhance understanding and decision-making.

8. Machine Learning

Understanding basic machine learning concepts and algorithms enables data analysts to apply predictive models and enhance their analysis with predictive insights.

9. Excel

Mastery of Excel is crucial for data analysis, especially for handling smaller datasets, performing quick analyses, and creating pivot tables and charts.

10. Critical Thinking

Thinking critically and evaluating information from multiple perspectives is essential for drawing accurate conclusions from data.

11. Attention to Detail

Data analysis requires a deep understanding and a keen eye for detail to ensure data cleaning, analysis, and reporting accuracy.

12. Communication

Strong communication skills (oral and written) are necessary for translating complex data findings into understandable insights for non-technical stakeholders.

13. Problem-Solving

The ability to identify problems, analyze potential solutions, and implement the most effective solution is critical in data analysis projects.

14. Teamwork

Collaboration with other team members, departments, and stakeholders is essential for successfully completing projects and achieving business objectives.

15. Ethical Judgment

Data analysts must navigate ethical considerations, ensuring privacy, data security, and ethical use of data in their analyses.

16. Domain Knowledge

Understanding the industry or sector in which they operate helps analysts contextualize data findings and provide more relevant insights.

17. Statistical Programming

Skills in statistical programming languages like R can enhance an analyst’s ability to perform advanced statistical analyses and modeling

18. Management

The ability to manage projects, time, and resources effectively is important for meeting deadlines and managing multiple tasks simultaneously.

19. Modeling

Knowledge of data modeling techniques and tools is essential for creating representations of complex data systems to support analysis and decision-making.

20. Python

Proficiency in Python is highly valued due to its versatility, extensive libraries for data analysis (Pandas, NumPy) and machine learning (Scikit-learn), and its readability and ease of use.

These Data Analyst skills empower them to navigate their role's complexities, making them invaluable assets in leveraging data for strategic advantages.

How Do You Highlight Your Skills in a Resume?

Highlighting your data analyst technical skills in a resume is crucial to stand out in the job application process. It's not just about listing your skills but presenting them in a way that demonstrates your proficiency and how they align with the job you're applying for. Here are strategic ways to highlight your skills in a resume:

1. Tailor Your Skills to the Job Description

Analyze the Job Posting: Identify the skills and qualifications the employer is looking for by carefully reading the job description.

Match Your Skills: Tailor your skills section and professional experience to reflect the skills listed in the job description, emphasizing those where you have strong competencies.

2. Use a Dedicated Skills Section

Create a Skills Section: Include a specific section titled ""Skills"" or ""Core Competencies"" near the top of your resume, after your contact information and summary statement.

Categorize Your Skills: Organize your skills into categories such as Technical Skills, Soft Skills, and Languages.

3. Quantify Your Achievements

Use Numbers and Metrics: Use quantitative measures to add context to your achievements wherever possible. For instance, ""Increased sales by 20% through targeted data analysis and customer segmentation.""

Project-Based Examples: Highlight specific projects or tasks that demonstrate your skills and the positive outcomes that resulted from your actions.

4. Incorporate Skills into Your Professional Experience

Action Verbs: Start bullet points that showcase your skills in action, such as ""Analyzed,"" ""Developed,"" and ""Managed.""

Skill Application: Describe how you applied specific skills to achieve results in your previous roles, focusing on scenarios that align with the prospective job's requirements.

5. Highlight Transferable Skills

For Career Changers: If you're changing careers, emphasize transferable skills. For example, project management, communication, and problem-solving skills are valuable in many roles.

Contextualize Your Skills: Provide examples of how you've successfully applied these skills in different settings or industries.

6. Leverage the Resume Summary or Objective

Summarize Key Skills: Use your resume summary or objective to highlight critical skills that make you a strong candidate for the position, especially if they are directly mentioned in the job listing.

Personalize Your Introduction: Tailor this section to reflect relevant skills that align with the job you're applying for.

7. Incorporate Keywords from the Job Description

ATS Optimization: Companies use Applicant Tracking Systems to screen resumes. Including keywords from the job description ensures your resume passes these initial screenings.

Natural Integration: Integrate these keywords naturally into your skills section, professional experience, and summary to improve your resume's visibility.

8. Proofread and Format Consistently

Attention to Detail: Ensure your resume is free from typos and grammatical errors, which can detract from your professionalism and attention to detail.

Consistent Formatting: Use a clean, professional format with consistent fonts, sizes, and bullet points to make your resume easy to read.

Become a Data Science & Business Analytics Professional

28%Annual Job Growth By 2026

11.5 MExpected New Jobs For Data Science By 2026

Data Analyst

Industry-recognized Data Analyst Master’s certificate from Simplilearn

Dedicated live sessions by faculty of industry experts

Post Graduate Program in Data Analytics

Post Graduate Program certificate and Alumni Association membership

Exclusive hackathons and Ask me Anything sessions by IBM

prevNext

Here's what learners are saying regarding our programs:

Gayathri Ramesh

Associate Data Engineer , Publicis Sapient

The course was well structured and curated. The live classes were extremely helpful. They made learning more productive and interactive. The program helped me change my domain from a data analyst to an Associate Data Engineer.

Felix Chong

Project Manage , Codethink

After completing this course, I landed a new job & a salary hike of 30%. I now work with Zuhlke Group as a Project Manager.

prevNext

Not sure what you’re looking for?View all Related Programs

Data analysts employ many tools to collect, process, analyze, and visualize data. These tools extract insights from complex datasets, facilitating data-driven decision-making. The choice of tools can depend on the requirements of the task at hand, including the nature of the data, the complexity of the analysis, and the preferred reporting methods. Below, we delve into some of data analysts' most commonly used tools and the reasons for their usage.

1. SQL (Structured Query Language)

Usage: SQL is used for managing and querying relational databases. It allows analysts to extract and manipulate data captured in a structured format within a database.

Why: SQL is essential for data analysts due to its powerful querying capabilities, enabling them to retrieve, filter, and transform data for analysis efficiently.

2. Python

Usage: Python is a versatile programming language that's widely used for data analysis, machine learning, automation, and data visualization. Libraries like Pandas, NumPy, and Matplotlib expand their functionality for data tasks.

Why: Python's simplicity, readability, and extensive libraries make it a favorite among data analysts for handling and analyzing large datasets, as well as for building complex data models.

3. R

Usage: R is a programming language and environment specialized for statistical computing and graphics. It's used for data analysis, statistical modeling, and data visualization.

Why: R is particularly valued for its vast array of packages for statistical analysis, making it ideal for conducting sophisticated statistical tests and exploratory data analysis.

4. Excel

Usage: Microsoft Excel is a spreadsheet program for data entry, manipulation, and basic analysis. It's particularly useful for handling small to medium-sized datasets and performing quick analyses.

Why: Excel's ease of use, widespread availability, and powerful features like pivot tables and functions make it a staple for preliminary data analysis, reporting, and visualization tasks.

5. Tableau

Usage: Tableau is a data visualization tool for creating interactive and shareable dashboards. It allows analysts to visualize data insights and trends in an accessible format.

Why: Tableau is favored for its user-friendly interface, ability to handle large volumes of data, and the dynamic visualizations it creates, facilitating better data storytelling and decision-making.

6. Power BI

Usage: Power BI is a business analytics service by Microsoft that provides tools for aggregating, analyzing, visualizing, and sharing data.

Why: It integrates seamlessly with other Microsoft products and offers robust data visualization capabilities, making it an excellent tool for creating comprehensive reports and dashboards.

7. Google Analytics

Usage: Google Analytics serves as a web analytics tool, monitoring and reporting on website traffic. It plays a crucial role in analyzing user interactions on websites and assessing the effectiveness of digital marketing initiatives.

Why: Data analysts use Google Analytics to gather insights into user engagement, demographics, and acquisition channels, which are crucial for optimizing web presence and marketing strategies.

8. SAS (Statistical Analysis System)

Usage: SAS is a comprehensive software suite designed for sophisticated analytics, including multivariate analysis, business intelligence, data management, and predictive analytics.

Why: Renowned for its powerful statistical analysis features, it is apt for tackling intricate data analysis challenges across sectors such as healthcare, finance, and pharmaceuticals.

9. Statistical Package for the Social Sciences

Usage: SPSS is a software package used for statistical analysis. It's commonly used in social sciences for analyzing survey data, market research, and experiment data.

Why: SPSS is preferred for its user-friendly interface, making it accessible for analysts who may not have a strong programming background.

10. Git

Usage: Git is a version control system that lets multiple users collaborate on the same projects without conflict. It's used for code management in data analysis projects.

Why: It's essential for data analysts working in teams to ensure that changes to code and analysis are tracked, allowing for collaboration and historical comparison of data analysis projects.

Data Analyst Qualifications: What Does it Take

Becoming a data analyst requires a combination of educational background, technical skills, and certain soft skills that enable one to analyze data and communicate findings effectively. Here’s a comprehensive breakdown of what it takes to become a data analyst:

Educational Qualifications

Bachelor’s Degree: Most data analyst positions require at least a bachelor's degree.

Master’s Degree (Optional): While not always necessary, a master's degree can be advantageous for more advanced positions or specialized fields.

Data Analyst Technical Skills

Programming Languages: Proficiency in languages for data manipulation, statistical analysis, and machine learning. SQL knowledge is crucial for extracting and querying data from databases.

Statistical Analysis: A foundation in statistics is essential for interpreting data and conducting various analyses to extract meaningful insights.

Data Visualization: Understanding tools like Tableau, Power BI, or even Python libraries (e.g., Matplotlib, Seaborn) to create compelling visual representations of data findings.

Machine Learning: Understanding basic machine learning concepts and algorithms can be beneficial, especially for roles that overlap with data science.

Software Proficiency: Familiarity with spreadsheet tools like Microsoft Excel for data entry, manipulation, and preliminary analysis. Experience with database management software and data analytics platforms is also valuable.

Soft Skills

Analytical Thinking: Think critically and analytically to solve problems and make data-driven decisions.

Attention to Detail: Precision is key in data analysis to ensure data cleaning, analysis, and reporting accuracy.

Communication Skills: Verbal and written communication skills are necessary to effectively translate technical findings into understandable insights for non-technical stakeholders.

Problem-Solving: The capacity to approach complex data challenges with innovative solutions.

Curiosity and Continuous Learning: A genuine interest in data and its implications for businesses, coupled with continuous learning and staying updated with industry trends and tools.

Professional Certifications

Certification Programs: Certifications can enhance a data analyst's qualifications, especially in specific tools or methodologies. Examples include the Professional Certificate Course In Data Analytics and Tableau Training.

Specialized Training: Online courses and bootcamps offer specialized training in data analytics, machine learning, and specific programming languages or tools.

Practical Experience

Internships: Gaining practical experience through internships in data analysis can provide hands-on experience with real-world data, tools, and projects.

Projects: Working on personal or open-source projects can help develop and showcase your analytical skills and proficiency with data analysis tools.

Industry Knowledge

Domain Expertise: Understanding the specific industry you wish to enter can be a significant advantage. Domain knowledge enables a data analyst to make more informed analyses and recommendations relevant to the business context.

Adaptability and Teamwork

Adaptability: Adapt to new tools, technologies, and methodologies as the field evolves.

Collaboration: Data analysts often work as part of a team, requiring good interpersonal skills and the ability to work effectively with others, including technical and non-technical colleagues.

Types of Data Analysts

The field of data analytics is diverse, with various types of data analysts specializing in different sectors or aspects of data analysis. This specialization allows professionals to focus on specific areas where they can apply their data analyst skills and knowledge most effectively. Below are some common types of data analysts, each with unique roles and areas of expertise:

1. Business Analysts

Focus: Business analysts primarily analyze data for business decisions. They work closely with management and stakeholders to identify business needs, growth opportunities, and improvement areas.

Skills and Tools: They often use tools like SQL, Excel, and business intelligence software like Tableau or Power BI. Understanding business processes and strong communication skills are crucial.

2. Data Analysts in Finance

Focus: These analysts analyze financial data to help organizations make investment decisions, forecast future financial performance, and manage risk.

Skills and Tools: They use statistical software, Excel, and financial modeling tools. Knowledge of financial principles and regulations is important.

3. Marketing Analysts

Focus: Marketing analysts examine data related to market trends, consumer behavior, sales data, and marketing strategies. Their insights help in shaping marketing campaigns, product development, and targeting strategies.

Skills and Tools: They utilize CRM software, Google Analytics, and data visualization tools. Skills in market research and digital marketing analytics are valuable.

4. Operations Analysts

Focus: Operations analysts focus on a company's internal processes. They analyze supply chain management, production processes, and service delivery data to improve efficiency and reduce costs.

Skills and Tools: Proficiency in process mapping tools, SQL, and ERP systems. Understanding the industry’s best practices and operational processes is essential.

5. Data Analysts in Healthcare

Focus: These analysts work with healthcare data, including patient records, treatment outcomes, and healthcare operations. Their analysis supports patient care improvements, operational efficiency, and policy development.

Skills and Tools: Knowledge of healthcare IT systems (like EHRs), statistical software, and data privacy regulations (such as HIPAA in the U.S.) are critical.

6. Web Analysts

Focus: Web analysts scrutinize website analytics to understand user behavior, optimize website performance, and improve user experience.

Skills and Tools: Google Analytics, Adobe Analytics, and knowledge of SEO practices are important. They often work closely with marketing and web development teams.

7. Quantitative Analysts

Focus: Often found in finance, quantitative analysts (quants) use statistical and mathematical models to inform financial and risk management decisions. They're heavily involved in trading strategies and investment modeling.

Skills and Tools: Deep knowledge of mathematics and statistics, programming skills (Python, R, C++), and experience with mathematical modeling tools are required.

8. Social Media Analysts

Focus: These analysts specialize in analyzing social media data to gain insights into consumer sentiment, brand presence, and the effectiveness of social media campaigns.

Skills and Tools: Experience with social media analytics tools (like Hootsuite Insights and Brandwatch), understanding social media platforms, and knowledge of content marketing strategies are crucial.

9. Data Quality Analysts

Focus: Data quality analysts ensure data accuracy, completeness, and reliability within an organization. They identify data quality issues, implement corrections, and develop data governance practices.

Skills and Tools: Proficiency in data profiling and cleansing tools, knowledge of data governance principles, and attention to detail are essential.

10. BI (Business Intelligence) Analysts

Focus: BI analysts use data analytics and visualization tools to develop insights, reports, and dashboards that inform business strategies. They translate complex data findings into actionable business intelligence.

Skills and Tools: Expertise in Power BI, Tableau, and SQL BI tools. Strong business acumen and the ability to communicate complex concepts clearly are important.

Become a Data Science & Business Analytics Professional

28%Annual Job Growth By 2026

11.5 MExpected New Jobs For Data Science By 2026

Data Analyst

Industry-recognized Data Analyst Master’s certificate from Simplilearn

Dedicated live sessions by faculty of industry experts

Post Graduate Program in Data Analytics

Post Graduate Program certificate and Alumni Association membership

Exclusive hackathons and Ask me Anything sessions by IBM

prevNext

Here's what learners are saying regarding our programs:

Gayathri Ramesh

Associate Data Engineer , Publicis Sapient

The course was well structured and curated. The live classes were extremely helpful. They made learning more productive and interactive. The program helped me change my domain from a data analyst to an Associate Data Engineer.

Felix Chong

Project Manage , Codethink

After completing this course, I landed a new job & a salary hike of 30%. I now work with Zuhlke Group as a Project Manager.

prevNext

Not sure what you’re looking for?View all Related Programs

Data Analyst Salary: How Much Does a Data Analyst Make?

Here's an overview of data analyst salaries across different regions, including the United States, India, Europe, and the UK.

United States

Entry-Level: Entry-level data analysts in the United States can earn between $50,000 and $70,000 annually, depending on the location and sector.

Mid-Level: With a few years of experience, salaries typically range from $70,000 to $90,000.

Senior-Level: Senior data analysts or those with specialized skills in high-demand areas can earn between $90,000 and $120,000 or more.

India

Entry-Level: In India, entry-level data analysts may earn between ₹3,00,000 and ₹6,00,000 annually.

Mid-Level: For professionals with a few years of experience, salaries can range from ₹6,00,000 to ₹9,00,000.

Senior-Level: Senior professionals can expect salaries in the range of ₹9,00,000 to ₹20,00,000 or more, especially in high-tech cities and for those with specialized data analyst skills.

Europe

Entry-Level: In Western European countries like Germany or France, entry-level analysts might earn between €30,000 and €50,000. In Eastern European countries, the range might be slightly lower.

Mid-Level: Mid-level salaries can range from €50,000 to €70,000 in Western Europe.

Senior-Level: Senior data analysts can earn €70,000 to €100,000 or more, especially in countries with higher living costs.

United Kingdom (UK)

Entry-Level: Entry-level data analysts in the UK typically earn between £25,000 and £35,000.

Mid-Level: With experience, salaries can range between £35,000 and £50,000.

Senior-Level: Senior-level data analysts can expect to earn between £50,000 and £70,000 or more, depending on their expertise and the industry.

Become a Data Science & Business Analytics Professional

28%Annual Job Growth By 2026

11.5 MExpected New Jobs For Data Science By 2026

Data Analyst

Industry-recognized Data Analyst Master’s certificate from Simplilearn

Dedicated live sessions by faculty of industry experts

Post Graduate Program in Data Analytics

Post Graduate Program certificate and Alumni Association membership

Exclusive hackathons and Ask me Anything sessions by IBM

prevNext

Here's what learners are saying regarding our programs:

Gayathri Ramesh

Associate Data Engineer , Publicis Sapient

The course was well structured and curated. The live classes were extremely helpful. They made learning more productive and interactive. The program helped me change my domain from a data analyst to an Associate Data Engineer.

Felix Chong

Project Manage , Codethink

After completing this course, I landed a new job & a salary hike of 30%. I now work with Zuhlke Group as a Project Manager.

prevNext

Not sure what you’re looking for?View all Related Programs

Top Companies Hiring Data Analysts

The need for data analysts is widespread across multiple sectors. Businesses understand the importance of making decisions based on data and are searching for proficient analysts to unlock the potential of their data resources. Here's a list of top companies known for hiring data analysts, reflecting a diverse range of sectors:

Google: A leader in the tech industry, Google hires data analysts to work on various projects, from improving search algorithms to analyzing user behavior.

Amazon: The e-commerce giant relies on data analysts to optimize its supply chain, enhance customer experience, and drive sales strategies.

Facebook (Meta): With billions of users, Meta hires data analysts to understand social media trends, user engagement, and advertising effectiveness.

Microsoft: Offers roles for data analysts in product development, sales strategies, and customer insights across its various services and platforms.

Apple: Hires data analysts to improve user experiences across its product lines and services, including hardware, software, and media offerings.

JPMorgan Chase & Co.: One of the largest banks in the U.S., it employs data analysts for risk management, customer analytics, and financial forecasting.

Goldman Sachs: Invests in data analytics for market analysis, investment strategies, and risk assessment.

American Express: Utilizes data analysts to enhance customer service, fraud detection, and loyalty programs.

Pfizer: The pharmaceutical giant hires data analysts for drug research, patient data analysis, and market trends.

Johnson & Johnson: Employs analysts to enhance healthcare products, analyze clinical trial data, and optimize supply chains.

Walmart: The world’s largest retailer uses data analytics for inventory management, customer behavior analysis, and sales optimization.

Target: Employs data analysts to enhance shopping experiences, both online and in-store, through personalized marketing and supply chain efficiencies.

McKinsey & Company: A leading consulting firm that hires data analysts to provide insights across various industries, from finance to healthcare.

Deloitte: Offers roles in data analytics to help clients with operational efficiency, market analysis, and strategy development.

Accenture: Provides analytics services, employing data analysts to help clients transform data into actionable insights.

Netflix: Uses data analytics extensively to understand viewer preferences and content performance and to drive production strategies.

The Walt Disney Company: Employs data analysts to enhance guest experiences in parks and resorts and analyze viewer data for its media properties.

IBM: Offers roles for data analysts in areas such as artificial intelligence, cloud services, and business intelligence solutions.

Salesforce: Hires data analysts to improve customer relationship management (CRM) tools and services through data-driven insights.

Uber: Utilizes data analytics for optimizing ride-sharing services, pricing strategies, and market expansion.

Choose the Right Program

Are you eager to embark on a career within the dynamic realm of data analytics? Our courses in Data Analytics are meticulously crafted to fill you with the essential data analyst skills and knowledge vital for thriving in this swiftly expanding field. Guided by our seasoned instructors, you'll engage in hands-on projects, tackle real-life situations, and delve into comprehensive case studies, all aimed at providing you with the practical experience necessary for success. Through our training, you'll master the art of data analysis, develop the ability to craft insightful reports and acquire the competence to make informed, data-driven decisions that contribute to achieving business objectives.

Program Name Data Analyst Post Graduate Program In Data Analytics

Data Analytics Bootcamp Program Available In All Geos All Geos US University Simplilearn Purdue Caltech Course Duration 11 Months 8 Months 6 Months Coding Experience Required No Basic No Skills You Will Learn 10+ skills including Python, MySQL, Tableau, NumPy and more

Data Analytics, Statistical Analysis using Excel, Data Analysis Python and R, and more Data Visualization with Tableau, Linear and Logistic Regression, Data Manipulation and more Additional Benefits Applied Learning via Capstone and 20+ industry-relevant Data Analytics projects Purdue Alumni Association Membership

Free IIMJobs Pro-Membership of 6 months Access to Integrated Practical Labs Caltech CTME Circle Membership Cost $$ $$$$ $$$$ Explore Program Explore Program Explore Program

Get Started to Become a Data Analyst Today!

Having explored the job description, essential skills, and qualifications for a data analyst, you might be curious about how to secure a position in this field. Let's outline the pathway to a career in data analysis. Securing an entry-level position in data analysis can be straightforward if you possess a certification from a highly regarded data analysis program, such as those provided by Simplilearn. Lack of prior experience in data analysis isn't a barrier; with the right training, you can embark on a successful data analyst career. By enrolling in our Data Analyst course, you can begin your journey into data analytics.

FAQs

1. What is the best way to start a career as a data analyst?

The best way to start a career as a data analyst is by gaining a strong foundation in statistics, programming (Python or R), and data visualization tools (e.g., Tableau, Power BI). Acquiring a relevant degree or certification from recognized programs can also be beneficial. Engaging in real-world projects or internships to apply your skills practically will enhance your resume and experience.

2. How important is programming knowledge for a data analyst?

Programming knowledge is crucial for a data analyst as it enables data manipulation, analysis, and the automation of tasks. Proficiency in languages such as Python or R is essential for performing complex data analysis and applying machine learning models to datasets.

3. Can someone without a technical background become a data analyst?

Yes, someone without a technical background can become a data analyst. It requires a commitment to learning key skills such as data analysis techniques, statistical knowledge, and programming languages. Many successful data analysts start from non-technical fields and transition into data roles through dedicated study and practice.

4. How often should I update my skills as a data analyst?

Data analysts should update their skills regularly, ideally several times a year, to keep pace with the rapidly evolving field of data science. Continuous learning through online courses, workshops, and conferences can help analysts stay current with new tools, technologies, and methodologies."
https://www.analyticsinsight.net/10-ways-banks-stay-ahead-with-data-science-solutions/,10 Ways Banks Stay Ahead with Data Science Solutions,"How banks stay ahead with Data Science solutions: 10 strategies revolutionizing the financial industry

As the financial industry is changing with time, it has become necessary for banks to adopt and include data science solutions in their day-to-day affairs. Data analytics, machine learning, and artificial intelligence help banks to make operations smooth and enhance customer experience. Not only that, these technologies are helping banks to mitigate risks associated with their work. In this article, we will discuss 10 ways banks are leveraging data science to stay ahead in this era of modernization.

Fraud Detection:

Detection and prevention of fraudulent activities is one of the crucial elements in this industry. Data science techniques, such as machine learning algorithms help banks to conduct this in real-time. These strategies help banks analyze enormous transaction data and eventually identify patterns that are suspicious. By this process, banks can take measures and safeguard customer assets.

Managing Customer Data:

Analyzing customer data is often a daunting task. Data science helps Banks to make this task easy as well. It makes the customer data comprehensive so that banks can get valuable information on their needs, preferences, and behaviors. With this information, banks can provide personalized services. This approach of offering tailored services increases customer satisfaction.

Risk Modeling for Investment Banks:

Data science facilitates risk modeling and financial accountancy regulation compliance in Investment banks. Leveraging data science, investment banks can determine the value of a company for many types of financial transactions, they can model the expected returns of different investments. Utilization of big data analytics enables investment banks to make the right choices, reduce risks, and get better fluctuation returns.

Personalized Marketing:

As mentioned earlier, data science aids in analyzing customer data thus predicting consumer behavior. With the knowledge of customer behavior banks can create targeted marketing campaigns. By delivering personalized offers and recommendations, banks improve customer engagement, drive sales.

Predictive Analytics:

Access to data science methods is conducive to utilization of predictive analytics which, in turn, helps banks to estimate customer lifetime value (CLV) and identify future trends. Using the selective customer portfolio approach and the accurate estimations of clients’ future demands, banks may be in a position to provide them with tailor-made service models to increase their profits.

Real-Time and Predictive Analytics:

Banks are leveraging real-time and predictive analytics to make decisions. They detect emerging trends, identify potential risks, and capitalize on opportunities.

Data Management and Quality:

Data science tools and technologies are to a large extent useful in the aspect of data enhancement i.e. quality and accessibility in data management. Through keeping the data clean and sound banks can thus ascertain true picture of the data and come to decisions that are accurate and based on the real picture, which is the backbone of business growth.

Regulatory Compliance:

The regulation is a must notably in customer identification (KYC) and anti-money laundering (AML) requirements by banks. These methods of data science allow banks to examine customers’ data carefully, identify risks, and stay in line with the regulations, so at the end of the day, the banks may make use of the financial resources prudently and avoid possible legal complications.

Artificial Intelligence (AI) and Machine Learning (ML):

Integration of AI and ML in the banking analytics industry will lead to a revolution that has been waiting for a long. AI and ML integrations allow banks to dig deeper into customer behavior patterns, market changes, and upcoming trends, therefore providing analysis-based strategic planning direction and growth solutions.

However, at the end, data science technological solutions are transforming the banking environment by giving banks a competitive advantage in an increasing dynamic financial destination. Through the employment of data analytics, machine learning, and artificial intelligence; banks will be able to elevate their operations, enhance the experiences of customers, and consequently manage risks. The ascending trajectory of technological advancements in regard to data science in banking automatically puts the field in a strategic position that will continue to facilitate innovation and progress in the industry."
https://www.simplilearn.com/tutorials/machine-learning-tutorial/machine-learning-interview-questions,Top 45 Machine Learning Interview Questions (2024),"Companies are striving to make information and services more accessible to people by adopting new-age technologies like artificial intelligence (AI) and machine learning. One can witness the growing adoption of these technologies in industrial sectors like banking, finance, retail, manufacturing, healthcare, and more.

Data scientists, artificial intelligence engineers, machine learning engineers, and data analysts are some of the in-demand organizational roles that are embracing AI. If you aspire to apply for these types of jobs, it is crucial to know the kind of machine learning interview questions that recruiters and hiring managers may ask.

This article takes you through some of the machine learning interview questions and answers, that you’re likely to encounter on your way to achieving your dream job.

Top Machine Learning Interview Questions

Let's start with some commonly asked machine learning interview questions and answers.

1. What Are the Different Types of Machine Learning?

There are three types of machine learning:

Supervised Learning

In supervised machine learning, a model makes predictions or decisions based on past or labeled data. Labeled data refers to sets of data that are given tags or labels, and thus made more meaningful.

Unsupervised Learning

In unsupervised learning, we don't have labeled data. A model can identify patterns, anomalies, and relationships in the input data.

Reinforcement Learning

Using reinforcement learning, the model can learn based on the rewards it received for its previous action.

Consider an environment where an agent is working. The agent is given a target to achieve. Every time the agent takes some action toward the target, it is given positive feedback. And, if the action taken is going away from the goal, the agent is given negative feedback.

Also Read: Supervised and Unsupervised Learning in Machine Learning

2. What is Overfitting, and How Can You Avoid It?

The Overfitting is a situation that occurs when a model learns the training set too well, taking up random fluctuations in the training data as concepts. These impact the model’s ability to generalize and don’t apply to new data.

When a model is given the training data, it shows 100 percent accuracy—technically a slight loss. But, when we use the test data, there may be an error and low efficiency. This condition is known as overfitting.

There are multiple ways of avoiding overfitting, such as:

Regularization. It involves a cost term for the features involved with the objective function

Making a simple model. With lesser variables and parameters, the variance can be reduced

Cross-validation methods like k-folds can also be used

If some model parameters are likely to cause overfitting, techniques for regularization like LASSO can be used that penalize these parameters

Also Read: Overfitting and Underfitting in Machine Learning

3. What is ‘training Set’ and ‘test Set’ in a Machine Learning Model? How Much Data Will You Allocate for Your Training, Validation, and Test Sets?

There is a three-step process followed to create a model:

Train the model

Test the model

Deploy the model

Training Set Test Set

The training set is examples given to the model to analyze and learn

70% of the total data is typically taken as the training dataset

This is labeled data used to train the model

The test set is used to test the accuracy of the hypothesis generated by the model

Remaining 30% is taken as testing dataset

We test without labeled data and then verify results with labels

Consider a case where you have labeled data for 1,000 records. One way to train the model is to expose all 1,000 records during the training process. Then you take a small set of the same data to test the model, which would give good results in this case.

But, this is not an accurate way of testing. So, we set aside a portion of that data called the ‘test set’ before starting the training process. The remaining data is called the ‘training set’ that we use for training the model. The training set passes through the model multiple times until the accuracy is high, and errors are minimized.

Now, we pass the test data to check if the model can accurately predict the values and determine if training is effective. If you get errors, you either need to change your model or retrain it with more data.

Regarding the question of how to split the data into a training set and test set, there is no fixed rule, and the ratio can vary based on individual preferences.

4. How Do You Handle Missing or Corrupted Data in a Dataset?

One of the easiest ways to handle missing or corrupted data is to drop those rows or columns or replace them entirely with some other value.

There are two useful methods in Pandas:

IsNull() and dropna() will help to find the columns/rows with missing data and drop them

Fillna() will replace the wrong values with a placeholder value

5. How Can You Choose a Classifier Based on a Training Set Data Size?

When the training set is small, a model that has a right bias and low variance seems to work better because they are less likely to overfit.

For example, Naive Bayes works best when the training set is large. Models with low bias and high variance tend to perform better as they work fine with complex relationships.

6. Explain the Confusion Matrix with Respect to Machine Learning Algorithms.

A confusion matrix (or error matrix) is a specific table that is used to measure the performance of an algorithm. It is mostly used in supervised learning; in unsupervised learning, it’s called the matching matrix.

The confusion matrix has two parameters:

Actual

Predicted

It also has identical sets of features in both of these dimensions.

Consider a confusion matrix (binary matrix) shown below:

Here,

For actual values:

Total Yes = 12+1 = 13

Total No = 3+9 = 12

Similarly, for predicted values:

Total Yes = 12+3 = 15

Total No = 1+9 = 10

For a model to be accurate, the values across the diagonals should be high. The total sum of all the values in the matrix equals the total observations in the test data set.

For the above matrix, total observations = 12+3+1+9 = 25

Now, accuracy = sum of the values across the diagonal/total dataset

= (12+9) / 25

= 21 / 25

= 84%

7. What Is a False Positive and False Negative and How Are They Significant?

False positives are those cases that wrongly get classified as True but are False.

False negatives are those cases that wrongly get classified as False but are True.

In the term ‘False Positive,’ the word ‘Positive’ refers to the ‘Yes’ row of the predicted value in the confusion matrix. The complete term indicates that the system has predicted it as a positive, but the actual value is negative.

So, looking at the confusion matrix, we get:

False-positive = 3

True positive = 12

Similarly, in the term ‘False Negative,’ the word ‘Negative’ refers to the ‘No’ row of the predicted value in the confusion matrix. And the complete term indicates that the system has predicted it as negative, but the actual value is positive.

So, looking at the confusion matrix, we get:

False Negative = 1

True Negative = 9

8. What Are the Three Stages of Building a Model in Machine Learning?

The three stages of building a machine learning model are:

Model Building

Choose a suitable algorithm for the model and train it according to the requirement

Model Testing

Check the accuracy of the model through the test data

Applying the Model

Make the required changes after testing and use the final model for real-time projects

Here, it’s important to remember that once in a while, the model needs to be checked to make sure it’s working correctly. It should be modified to make sure that it is up-to-date.

9. What is Deep Learning?

The Deep learning is a subset of machine learning that involves systems that think and learn like humans using artificial neural networks. The term ‘deep’ comes from the fact that you can have several layers of neural networks.

One of the primary differences between machine learning and deep learning is that feature engineering is done manually in machine learning. In the case of deep learning, the model consisting of neural networks will automatically determine which features to use (and which not to use).

This is a commonly asked question asked in both Machine Learning Interviews as well as Deep Learning Interview Questions

10. What Are the Differences Between Machine Learning and Deep Learning?

Learn more: Difference Between AI,ML and Deep Learning

Machine Learning Deep Learning

Enables machines to take decisions on their own, based on past data

It needs only a small amount of data for training

Works well on the low-end system, so you don't need large machines

Most features need to be identified in advance and manually coded

The problem is divided into two parts and solved individually and then combined

Enables machines to take decisions with the help of artificial neural networks

It needs a large amount of training data

Needs high-end machines because it requires a lot of computing power

The machine learns the features from the data it is provided

The problem is solved in an end-to-end manner

11. What Are the Applications of Supervised Machine Learning in Modern Businesses?

Applications of supervised machine learning include:

Email Spam Detection

Here we train the model using historical data that consists of emails categorized as spam or not spam. This labeled information is fed as input to the model.

Healthcare Diagnosis

By providing images regarding a disease, a model can be trained to detect if a person is suffering from the disease or not.

Sentiment Analysis

This refers to the process of using algorithms to mine documents and determine whether they’re positive, neutral, or negative in sentiment.

Fraud Detection

By training the model to identify suspicious patterns, we can detect instances of possible fraud.

Related Interview Questions and Answers

AI | Data Science

12. What is Semi-supervised Machine Learning?

Supervised learning uses data that is completely labeled, whereas unsupervised learning uses no training data.

In the case of semi-supervised learning, the training data contains a small amount of labeled data and a large amount of unlabeled data.

13. What Are Unsupervised Machine Learning Techniques?

There are two techniques used in unsupervised learning: clustering and association.

Clustering

Clustering problems involve data to be divided into subsets. These subsets, also called clusters, contain data that are similar to each other. Different clusters reveal different details about the objects, unlike classification or regression.

Association

In an association problem, we identify patterns of associations between different variables or items.

For example, an e-commerce website can suggest other items for you to buy, based on the prior purchases that you have made, spending habits, items in your wishlist, other customers’ purchase habits, and so on.

14. What is the Difference Between Supervised and Unsupervised Machine Learning?

Supervised learning - This model learns from the labeled data and makes a future prediction as output

Unsupervised learning - This model uses unlabeled input data and allows the algorithm to act on that information without guidance.

15. What is the Difference Between Inductive Machine Learning and Deductive Machine Learning?

Inductive Learning Deductive Learning

It observes instances based on defined principles to draw a conclusion

Example: Explaining to a child to keep away from the fire by showing a video where fire causes damage

It concludes experiences

Example: Allow the child to play with fire. If he or she gets burned, they will learn that it is dangerous and will refrain from making the same mistake again

16. Compare K-means and KNN Algorithms.

K-means KNN

K-Means is unsupervised

K-Means is a clustering algorithm

The points in each cluster are similar to each other, and each cluster is different from its neighboring clusters

KNN is supervised in nature

KNN is a classification algorithm

It classifies an unlabeled observation based on its K (can be any number) surrounding neighbors

17. What Is ‘naive’ in the Naive Bayes Classifier?

The classifier is called ‘naive’ because it makes assumptions that may or may not turn out to be correct.

The algorithm assumes that the presence of one feature of a class is not related to the presence of any other feature (absolute independence of features), given the class variable.

For instance, a fruit may be considered to be a cherry if it is red in color and round in shape, regardless of other features. This assumption may or may not be right (as an apple also matches the description).

18. Explain How a System Can Play a Game of Chess Using Reinforcement Learning.

Reinforcement learning has an environment and an agent. The agent performs some actions to achieve a specific goal. Every time the agent performs a task that is taking it towards the goal, it is rewarded. And, every time it takes a step that goes against that goal or in the reverse direction, it is penalized.

Earlier, chess programs had to determine the best moves after much research on numerous factors. Building a machine designed to play such games would require many rules to be specified.

With reinforced learning, we don’t have to deal with this problem as the learning agent learns by playing the game. It will make a move (decision), check if it’s the right move (feedback), and keep the outcomes in memory for the next step it takes (learning). There is a reward for every correct decision the system takes and punishment for the wrong one.

19. How Will You Know Which Machine Learning Algorithm to Choose for Your Classification Problem?

While there is no fixed rule to choose an algorithm for a classification problem, you can follow these guidelines:

If accuracy is a concern, test different algorithms and cross-validate them

If the training dataset is small, use models that have low variance and high bias

If the training dataset is large, use models that have high variance and little bias

20. How is Amazon Able to Recommend Other Things to Buy? How Does the Recommendation Engine Work?

Once a user buys something from Amazon, Amazon stores that purchase data for future reference and finds products that are most likely also to be bought, it is possible because of the Association algorithm, which can identify patterns in a given dataset.

21. When Will You Use Classification over Regression?

Classification is used when your target is categorical, while regression is used when your target variable is continuous. Both classification and regression belong to the category of supervised machine learning algorithms.

Examples of classification problems include:

Predicting yes or no

Estimating gender

Breed of an animal

Type of color

Examples of regression problems include:

Estimating sales and price of a product

Predicting the score of a team

Predicting the amount of rainfall

22. How Do You Design an Email Spam Filter?

Building a spam filter involves the following process:

The email spam filter will be fed with thousands of emails

Each of these emails already has a label: ‘spam’ or ‘not spam.’

The supervised machine learning algorithm will then determine which type of emails are being marked as spam based on spam words like the lottery, free offer, no money, full refund, etc.

The next time an email is about to hit your inbox, the spam filter will use statistical analysis and algorithms like Decision Trees and SVM to determine how likely the email is spam

If the likelihood is high, it will label it as spam, and the email won’t hit your inbox

Based on the accuracy of each model, we will use the algorithm with the highest accuracy after testing all the models

23. What is a Random Forest?

A ‘random forest’ is a supervised machine learning algorithm that is generally used for classification problems. It operates by constructing multiple decision trees during the training phase. The random forest chooses the decision of the majority of the trees as the final decision.

24. Considering a Long List of Machine Learning Algorithms, given a Data Set, How Do You Decide Which One to Use?

There is no master algorithm for all situations. Choosing an algorithm depends on the following questions:

How much data do you have, and is it continuous or categorical?

Is the problem related to classification, association, clustering, or regression?

Predefined variables (labeled), unlabeled, or mix?

What is the goal?

Based on the above questions, the following algorithms can be used:

25. What is Bias and Variance in a Machine Learning Model?

Bias

Bias in a machine learning model occurs when the predicted values are further from the actual values. Low bias indicates a model where the prediction values are very close to the actual ones.

Underfitting: High bias can cause an algorithm to miss the relevant relations between features and target outputs.

Variance

Variance refers to the amount the target model will change when trained with different training data. For a good model, the variance should be minimized.

Overfitting: High variance can cause an algorithm to model the random noise in the training data rather than the intended outputs.

26. What is the Trade-off Between Bias and Variance?

The bias-variance decomposition essentially decomposes the learning error from any algorithm by adding the bias, variance, and a bit of irreducible error due to noise in the underlying dataset.

Necessarily, if you make the model more complex and add more variables, you’ll lose bias but gain variance. To get the optimally-reduced amount of error, you’ll have to trade off bias and variance. Neither high bias nor high variance is desired.

High bias and low variance algorithms train models that are consistent, but inaccurate on average.

High variance and low bias algorithms train models that are accurate but inconsistent.

27. Define Precision and Recall.

Precision

Precision is the ratio of several events you can correctly recall to the total number of events you recall (mix of correct and wrong recalls).

Precision = (True Positive) / (True Positive + False Positive)

Recall

A recall is the ratio of the number of events you can recall the number of total events.

Recall = (True Positive) / (True Positive + False Negative)

28. What is a Decision Tree Classification?

A decision tree builds classification (or regression) models as a tree structure, with datasets broken up into ever-smaller subsets while developing the decision tree, literally in a tree-like way with branches and nodes. Decision trees can handle both categorical and numerical data.

29. What is Pruning in Decision Trees, and How Is It Done?

Pruning is a technique in machine learning that reduces the size of decision trees. It reduces the complexity of the final classifier, and hence improves predictive accuracy by the reduction of overfitting.

Pruning can occur in:

Top-down fashion. It will traverse nodes and trim subtrees starting at the root

Bottom-up fashion. It will begin at the leaf nodes

There is a popular pruning algorithm called reduced error pruning, in which:

Starting at the leaves, each node is replaced with its most popular class

If the prediction accuracy is not affected, the change is kept

There is an advantage of simplicity and speed

30. Briefly Explain Logistic Regression.

Logistic regression is a classification algorithm used to predict a binary outcome for a given set of independent variables.

The output of logistic regression is either a 0 or 1 with a threshold value of generally 0.5. Any value above 0.5 is considered as 1, and any point below 0.5 is considered as 0.

31. Explain the K Nearest Neighbor Algorithm.

K nearest neighbor algorithm is a classification algorithm that works in a way that a new data point is assigned to a neighboring group to which it is most similar.

In K nearest neighbors, K can be an integer greater than 1. So, for every new data point, we want to classify, we compute to which neighboring group it is closest.

Let us classify an object using the following example. Consider there are three clusters:

Football

Basketball

Tennis ball

Let the new data point to be classified is a black ball. We use KNN to classify it. Assume K = 5 (initially).

Next, we find the K (five) nearest data points, as shown.

Observe that all five selected points do not belong to the same cluster. There are three tennis balls and one each of basketball and football.

When multiple classes are involved, we prefer the majority. Here the majority is with the tennis ball, so the new data point is assigned to this cluster.

32. What is a Recommendation System?

Anyone who has used Spotify or shopped at Amazon will recognize a recommendation system: It’s an information filtering system that predicts what a user might want to hear or see based on choice patterns provided by the user.

33. What is Kernel SVM?

Kernel SVM is the abbreviated version of the kernel support vector machine. Kernel methods are a class of algorithms for pattern analysis, and the most common one is the kernel SVM.

34. What Are Some Methods of Reducing Dimensionality?

You can reduce dimensionality by combining features with feature engineering, removing collinear features, or using algorithmic dimensionality reduction.

Now that you have gone through these machine learning interview questions, you must have got an idea of your strengths and weaknesses in this domain.

35. What is Principal Component Analysis?

Principal Component Analysis or PCA is a multivariate statistical technique that is used for analyzing quantitative data. The objective of PCA is to reduce higher dimensional data to lower dimensions, remove noise, and extract crucial information such as features and attributes from large amounts of data.

36. What do you understand by the F1 score?

The F1 score is a metric that combines both Precision and Recall. It is also the weighted average of precision and recall.

The F1 score can be calculated using the below formula:

F1 = 2 * (P * R) / (P + R)

The F1 score is one when both Precision and Recall scores are one.

37. What do you understand by Type I vs Type II error?

Type I Error: Type I error occurs when the null hypothesis is true and we reject it.

Type II Error: Type II error occurs when the null hypothesis is false and we accept it.

38. Explain Correlation and Covariance?

Correlation: Correlation tells us how strongly two random variables are related to each other. It takes values between -1 to +1.

Formula to calculate Correlation:

Covariance: Covariance tells us the direction of the linear relationship between two random variables. It can take any value between - ∞ and + ∞.

Formula to calculate Covariance:

39. What are Support Vectors in SVM?

Support Vectors are data points that are nearest to the hyperplane. It influences the position and orientation of the hyperplane. Removing the support vectors will alter the position of the hyperplane. The support vectors help us build our support vector machine model.

40. What is Ensemble learning?

Ensemble learning is a combination of the results obtained from multiple machine learning models to increase the accuracy for improved decision-making.

Example: A Random Forest with 100 trees can provide much better results than using just one decision tree.

41. What is Cross-Validation?

Cross-Validation in Machine Learning is a statistical resampling technique that uses different parts of the dataset to train and test a machine learning algorithm on different iterations. The aim of cross-validation is to test the model’s ability to predict a new set of data that was not used to train the model. Cross-validation avoids the overfitting of data.

K-Fold Cross Validation is the most popular resampling technique that divides the whole dataset into K sets of equal sizes.

42. What are the different methods to split a tree in a decision tree algorithm?

Variance: Splitting the nodes of a decision tree using the variance is done when the target variable is continuous.

Information Gain: Splitting the nodes of a decision tree using Information Gain is preferred when the target variable is categorical.

Gini Impurity: Splitting the nodes of a decision tree using Gini Impurity is followed when the target variable is categorical.

43. How does the Support Vector Machine algorithm handle self-learning?

The SVM algorithm has a learning rate and expansion rate which takes care of self-learning. The learning rate compensates or penalizes the hyperplanes for making all the incorrect moves while the expansion rate handles finding the maximum separation area between different classes.

44. What are the assumptions you need to take before starting with linear regression?

There are primarily 5 assumptions for a Linear Regression model:

Multivariate normality

No auto-correlation

Homoscedasticity

Linear relationship

No or little multicollinearity

45. What is the difference between Lasso and Ridge regression?

Lasso(also known as L1) and Ridge(also known as L2) regression are two popular regularization techniques that are used to avoid overfitting of data. These methods are used to penalize the coefficients to find the optimum solution and reduce complexity. The Lasso regression works by penalizing the sum of the absolute values of the coefficients. In Ridge or L2 regression, the penalty function is determined by the sum of the squares of the coefficients.

Looking forward to a successful career in AI and Machine learning. Enrol in our Artificial Intelligence Course in collaboration with Caltech University now.

Become Part of the Machine Learning Talent Pool

With technology ramping up, jobs in the field of data science and AI will continue to be in demand. Candidates who upgrade their skills and become well-versed in these emerging technologies can find many job opportunities with impressive salaries. Looking forward to becoming a Machine Learning Engineer? Enroll in Simplilearn's Caltech Post Graduate Program in AI & ML and get certified today. Based on your experience level, you may be asked to demonstrate your skills in machine learning, additionally, but this depends mostly on the role you’re pursuing. These machine learning interview questions and answers will prepare you to clear your interview on the first attempt!

Apart from the above mentioned interview questions, it is also important to have a fair understanding of frequently asked Data Science interview questions.

Considering this trend, Simplilearn offers Caltech Post Graduate Program in AI & ML certification course to help you gain a firm hold of machine learning concepts. This course is well-suited for those at the intermediate level, including:

Analytics managers

Business analysts

Information architects

Developers looking to become data scientists

Graduates seeking a career in data science and machine learning

Facing the machine learning interview questions would become much easier after you complete this course."
https://ischool.syr.edu/discovering-my-path-data-science-and-beyond-at-syracuse-university/,Discovering My Path: Data Science and Beyond at Syracuse University - iSchool,"From my earliest memories in Miami, I was intrigued by everything from the unfolding of a story in a book to the evolving theories about our universe. Now, as a third-year student at Syracuse University, I’m living my dream, delving into the world of Applied Data Analytics with minors in Innovation, Design, and Startups, and Computer Engineering.

Being the first in my family to attend university, I had to navigate this new world largely on my own. But that’s the thing about Syracuse – it’s more than just a university. It’s a community where you’re encouraged to explore, make mistakes, and grow.

In my classes, whether it’s ‘Data in Society’ or ‘Intro to Networks & Cloud’, I find myself constantly challenged and intrigued. It’s not just about learning the theories; it’s about seeing how these concepts come alive in the real world. And speaking of the real world, my job at the ITS Service Center and the Digital Scholarship Space (DSS) at Syracuse University has been nothing short of eye-opening. There, I’m not just a student; I’m a problem-solver, a tech wizard in training, helping others make sense of the digital world.

But perhaps what really gets my heart racing is the work I do as a NEXIS Researcher in Data Science. It’s here that I get to explore the frontiers of technology – imagine being part of discussions on the next big thing in tech! This, coupled with my ongoing project, Pr0-Tech, is where I see my dreams converging with reality. It’s a thrilling journey of creating a blockchain-based solution that could redefine data security and privacy.

Looking ahead, I can’t wait for my summer internship at GE Aerospace. It feels like the next big leap towards my goal of being at the forefront of technology and innovation. I’m eager to dive into projects, to test my skills in a real-world setting, and to see how far my passion for data and technology can take me.

And let’s not forget my role as an iSchool Ambassador. Sharing my story, guiding prospective students, and being a part of their decision-making process is not just a responsibility – it’s a privilege. It’s my way of giving back, of showing others that their dreams are valid and achievable.

As I reflect on my time at Syracuse, I realize how each experience has been a stepping stone towards a future I once only dreamed of. This journey has been about finding my place in the world of technology and data, about pushing boundaries, and about discovering who I am and who I want to be.

When I think about how I ended up here, a big part of the story is the Posse Foundation Full-Tuition Leadership Scholarship. It wasn’t just a scholarship; it felt like a vote of confidence in a kid who loved the idea of being a forever learner and dreamed of making a difference. More than that, Posse connected me with a network of fellow scholars, individuals who have become more than peers – they are motivators, inspirers, and my closest friends. Together, we’ve shared experiences and challenges that have shaped me into a better person, deepening my commitment to learning and growing. Each of them, in their own unique way, has contributed to my journey, encouraging me to strive for excellence not just in academia, but in all facets of life. This heartfelt community of scholars that I’veive been able to meet at Syracuse has been instrumental in my development, constantly pushing me to explore new horizons and to be the best version of myself.

Adding to this enriching journey, I was recently honored with the Scholarship in Action award from the iSchool at Syracuse University. This recognition is not just an accolade; it is a testament to the hard work, dedication, and passion I’ve invested in my academic and extracurricular endeavors. Additionally, being an Our Time Has Come Scholar has brought another layer of enrichment to my university experience. These acknowledgments validate my efforts and reinforce my belief in the power of education and community. They serve as reminders of the responsibility I carry to not only excel academically but to also make a meaningful impact within my community and beyond. With these accolades, I feel even more empowered to pursue my goals and continue making a positive difference in the world.

For anyone considering Syracuse, especially the iSchool, know that it’s a place where dreams are given the space to grow. It’s where your passion for technology and innovation will find a nurturing home, and where your academic journey will be as exciting as it is enlightening."
https://www.unc.edu/discover/researcher-uses-data-science-to-address-homelessness/,Researcher uses data science to address homelessness,"In the U.S., more than 650,000 people don’t have homes — up 12% in 2023. That’s the largest jump seen since the government began collecting this data in 2007. The Triangle is no exception. More than 6,000 people identify as homeless in Raleigh and Wake County. Durham now has twice as many unsheltered individuals as in 2020.

These numbers drive Hsun-Ta Hsu, who’s spent the last decade working with some of the largest homeless populations in the country, in Los Angeles and St. Louis, using innovative tools to address this problem.

In July 2023, Hsu’s unique skillset led him to Carolina, where he is a professor in both the UNC School of Social Work and the new UNC School of Data Science and Society.

“Dr. Hsu is a prime example of how interdisciplinary data science can create insights that transform a seemingly intractable, multilevel social issue into something solvable,” SDSS Dean Stan Ahalt says.

Ramona Denby-Brinson, dean of social work, agrees about Hsu’s skills. “His work advances our understanding of neighborhood structures, the development of effective intervention programs and services, and how we can employ social networks in more practical terms to produce better health and behavioral outcomes for the unhoused.”

A human right

Hsu learned about social work in high school when his adviser recommended that he major in it based on his background and interests. In college, he earned bachelor’s, master’s and doctoral degrees in social work.

“I had relatives and people I was close to who were suffering with mental health-related issues, including suicide attempts and substance abuse,” he shares. “When I was younger, I didn’t know how to deal with it. So I was really thinking about that — and I wanted to do something about it.”

In 2010, at the start of his doctoral program at the University of Southern California, Hsu got his first look at the 50-block area of Los Angeles known as Skid Row. “I saw a young mother in a wheelchair breastfeeding her baby, surrounded by tents, bad smells and extreme poverty,” Hsu recalls. “That’s not OK. To me, housing is a human right.”

Hsu analyzed data from interviews with people housed by the Los Angeles Homeless Service Authority. He documented neighborhood characteristics for 50 blocks, a time-consuming, labor-intensive process that he thought technology could improve.

After a summer fellowship at the USC Center for Artificial Intelligence in Society, he started developing a mapping tool that uses machine learning to automate the identification of objects like garbage and broken-down cars.

Community-centered research

Since 2010, cities across the country have used another tool, the vulnerability index, to prioritize who gets housing.

“It’s a triage tool like we use in the emergency room,” Hsu explains. “We are measuring how vulnerable one is on the street and then bumping them up on the priority list to get them housing.”

In 2019, Hsu teamed up with CAIS researcher Eric Rice to improve this tool by combining demographic data with feedback from community stakeholders. They said they want to be considered for housing based on assets, not deficits. This “super important” feedback helped Hsu and Rice revise the vulnerability index survey to include questions focused on an individual’s positive traits.

Now Hsu is bringing this project model to rural communities, where nearly 87,000 Americans experience homelessness. Hsu believes his research in both rural and urban homeless populations will aid future projects in North Carolina and beyond.

“Homelessness is a national issue,” Ahalt stresses. “This research will create a replicable process that can be used in North Carolina and across the country.”"
https://hechingerreport.org/data-science-under-fire-what-math-do-high-schoolers-really-need/,Data science under fire: What math do high schoolers really need?,"OXNARD, Calif. — On a Wednesday morning this December, Dale Perizzolo’s math class at Adolfo Camarillo High School is anything but quiet. Students chat about the data analysis they’ve performed on their cellphone usage over a week, while Perizzolo walks around the room fielding their questions.

The students came up with the project themselves and designed a Google form to track their phone time, including which apps they used most. They also determined the research questions they’d ask of the data — such as whether social media use during class reduces comprehension and retention.

“It’s more real-world math,” said Nicolas Garcia, a senior in Perizzolo’s class. “We have the chance and freedom to choose what we’re doing our datasets on, and he teaches us how we’re going to work and complement it [in] our daily lives.”

Across town, students in Ruben Jacquez’s class at Rio Mesa High School use coding software to compile and clean data they’ve collected on student stress levels. A few miles away at Channel Islands High School, Miguel Hernandez’s students use pie and bar charts to analyze a dataset about how social media influences people’s shopping habits.

Perizzolo, Jacquez and Hernandez are among the eight math teachers of an increasingly popular data science course offered at most schools in the Oxnard Union High School district, an economically diverse school system northwest of Los Angeles, where 80 percent of students identify as Hispanic. The district rolled out the class in fall 2020, in an attempt to offer an alternative math course to students who might struggle in traditional junior and senior math courses such as Algebra II, Pre-Calculus and Calculus.

California has been at the center of a heated debate over what math knowledge students really need to succeed in college and careers. With math scores falling nationwide, some educators have argued that the standard algebra-intensive math pathway is outdated and needs a revamp, both to engage more students and to help them develop relevant skills in a world increasingly reliant on data. At least 17 states now offer data science (an interdisciplinary field that combines computer programming, math and statistics) as a high school math option, according to the group Data Science for Everyone. Two states — Oregon and Ohio — offer it as an alternative to Algebra II.

But other math educators have decried a move away from Algebra II, which they argue remains core to math instruction and necessary for students to succeed in STEM careers and beyond. In California, that disagreement erupted in October 2020, after the group that sets admission requirements for the state’s public university system (known as A-G) announced it would allow students to substitute data science for Algebra II to help more students qualify for college. Math professors, advocates and even some high school educators argued that the state was watering down standards and setting students up for failure in college.

Then, in July last year, the group reversed its earlier decision, and in February released new recommendations reiterating that data science courses (and, to the surprise of some experts, even long-approved statistics classes) cannot be used as an alternative to Algebra II. It remains unclear how the decision will reshape college admissions; additional guidance is expected in May.

In Oxnard, educators say they have been left in the dark about how these decisions affect course offerings for their students. They argue that, more than ever, students need real-world math to help them succeed in the subject, and that the expansion of data science — some 500 Oxnard district students have taken it to date — has reoriented teachers’ and students’ approach to math.

“Data science is changing their view of math,” said Jay Sorensen, Oxnard’s educational technology coordinator, who helped design the class. “It changed their perspective, or their view of what math is, because they maybe didn’t enjoy math or were frustrated with math or hated math before.”

Related: Inside the new middle school math crisis

Many kids in Oxnard stop taking any math after junior year of high school and the district has been trying to fix this for almost a decade. In 2015, Tom McCoy, then the assistant superintendent of education services, jokingly asked Sonny Sajor, the district’s math instructional specialist, “Can I get some math for poets?”

That started a conversation on what math classes might benefit and engage high schoolers who struggled in the subject and who didn’t plan to pursue science or math fields or attend a four-year college, said McCoy, who became Oxnard’s superintendent in 2020.

“Too many kids that dislike math would stop taking math the minute they could,” said Sajor, who co-designed the course at Oxnard. In the year before the district launched Data Science, only about 45 percent of students who took Math I in ninth grade made it to Math III by their junior year.

Inspired by a University of California, Los Angeles, seminar they attended on data science for high schoolers, Sajor and Sorensen designed the new course and partnered on it with the ed tech vendor Bootstrap.* Oxnard’s first data science classes generated enough student interest that the district expanded the course to more schools, and its popularity has continued to grow. Perizzolo’s class, for example, was meant to have 30 students but enrolls 39; he says he won’t turn away a student who signs up for a math class.

But not all educators in Oxnard were on board. Some math teachers, for example, questioned whether the Data Science course — which had been approved as an advanced statistics course equivalent to general statistics courses — was really equivalent to an advanced math course.* They noted that the statistics content in the course was at a ninth-grade level, Sajor said.

Oxnard Union’s data science teachers, though, say they’ve seen benefits.

“It’s giving kids exposure to really practical math, and it’s also creative,” said Allison Ottie Halstead, who teaches Data Science along with Honors Pre-Calculus and A.P. Statistics at Rancho Campana High School.

Alicia Bettencourt, who teaches Data Science at Hueneme High School, said the course has helped her to “incorporate more real-world problems, more authentic assessments, when I’m teaching” other math classes including Algebra II.

Most of Oxnard’s Data Science classes enroll a mix of students who are using the course to fulfill their required third year of math and those who’ve already taken Algebra II. According to district data, students who took Data Science as juniors in the 2022-2023 year were more likely to sign up for a math class their senior year. (Only about 10 percent of those students enrolled in Math III, an integrated math class that’s equivalent to Algebra II; larger shares enrolled in Statistics, Math for Finance Literacy and other classes). Meanwhile, the share of students receiving a D or F in Math III has dropped slightly since the Data Science course was introduced in 2020, the district said.

Nizcialey Dimapilis, a senior in Hernandez’s class at Channel Islands High School, said she is taking Data Science and A.P. Calculus simultaneously to prepare for computer engineering courses in college. “I thought this class would be more useful because it involves coding, which is completely kind of new to me,” Dimapilis said. The course has helped her understand graphs and create and read data in her other classes as well, she said.

Some students said it helped them grasp math concepts they’d been introduced to in past classes and made them more interested in pursuing math in the future. Jaya Richardson, a senior taking Data Science at Oxnard High School, said she doesn’t consider herself “a math person.” As a junior, she took Math III and barely passed with a D.

Richardson considered repeating the class for a higher grade, but her counselor suggested Data Science instead. She said she’s happy with the decision, and even plans to pursue a degree in biology at a UC or CSU.

“This is way better,” she said of the Data Science course. “It’s still stressful, it’s still hard, but it’s more beneficial. We still do math in here, but it breaks it down in a way where I’m able to understand it without being overwhelmed.”

Related: Teachers conquering their math anxiety

But many STEM professors are worried about the consequences of experiments like Oxnard’s.

Jelani Nelson, professor of electrical engineering and computer sciences at the University of California, Berkeley, argues that most data science courses offered in high schools are low level and don’t comply with UC and CSU college admission criteria that alternatives to Algebra II build on students’ earlier math coursework.

Without an understanding of what he calls “foundational math” — Algebra I, Geometry, Algebra II — he says students won’t succeed in college courses in computer science, math, technology and economics. Even art can draw on foundational math, he noted (perspective drawing, for example, uses geometry).* Introductory college classes in data science also build on those math concepts, he said, so students who’ve taken data science in high school but not Algebra II are unlikely to succeed in the subject.

Many four-year colleges don’t teach Algebra II, Nelson said, so there’s little opportunity to make up that work later. “If you want to get back on track,” he said, “how are you going to do it?”

Adrian Mims, founder of the Calculus Project, a nonprofit that works to increase the number of Black, Hispanic, Indigenous and low-income students in advanced mathematics, said swapping out data science for Algebra II has unintended consequences.

Standardized tests including the SAT and college math placement exams cover Algebra II, he said. He said he worries that students who opt for data science instead will be stuck in remedial math courses “not because they can’t learn the math, but because they made decisions in high school that deprive them of the opportunity to learn the content for them to do well.”

Rather than replacing Algebra II, data science concepts could be infused into Algebra II courses, and data science courses that include some Algebra II and geometry could be offered as electives to students who’ve already completed Algebra II, Nelson and others argue.

Others, though, don’t share those concerns. Pamela Burdman, founder of Just Equations, a nonprofit rethinking the role of traditional math pathways in high school, points to data showing that many students who take Algebra II in high school learn little.* She said emerging research suggests that courses like data science could have “more potential for bringing students into STEM” than the traditional preparatory math courses.

Despite the recent focus on the UC admissions requirements, only about 400 applicants out of roughly 206,000 in the last admissions cycle listed that they’d taken data science or statistics in lieu of Algebra II, she noted.

“I do worry that the debate over data science versus Algebra II is sort of a distraction,” she said.

Zarek Drozda, director of Data Science for Everyone, the national initiative based at the University of Chicago, agreed. “In the 21st century, if we can’t find opportunities to teach students about data, data science and AI basics, that is a huge problem,” he said.

Related: How can schools dig out from a generation’s worth of lost math progress?

Teachers and school guidance counselors in Oxnard are wary of wading into the math debate with their higher ed peers. But they aren’t afraid to voice their discontent with what they view as a disconnect between students’ needs and higher education.

“They’ve always moved the goal posts and I don’t know if they ever think about the students,” Hugo Tapia, a guidance counselor at Adolfo Camarillo High School, said about the state’s A-G university system.

Daniel Cook, a learning, instruction and technology coach at Camarillo, said that students come into high school behind in math and that the pandemic only made the problem worse. Yet colleges still expect students to have mastered Algebra II concepts and shut the door on those who haven’t.

“If one A-G math is the only reason why a kid doesn’t get into college, we’re robbing those kids,” he said.

Cook said that at Camarillo High School, some 44 percent of sophomores are not on track to be A-G eligible because of math, so they’re getting a message early on that they’re not college material. By senior year, the figure is about 25 percent.

Traditional math curriculum “is essentially focused on preparing students for STEM pathways in college,” Cook said. The July vote and subsequent policy recommendations to nix data science as an option for college applicants, he said, are a “slap in the face to students who have interests that are not STEM related.”

Related: How one district has diversified its advanced math classes — without the controversy

Educators in Oxnard are trying to cope with the uncertainty created by the state’s higher education system. With data science no longer counting toward college admission, Oxnard will eventually limit the course to students who’ve already taken, or are taking, Algebra II, according to Sajor. The district is also considering a pilot course that would integrate Algebra II and Data Science.

Such a course might ultimately be better for the district, Sajor said, because it would help more students engage with Algebra II concepts while also introducing them to coding and data science. “It’s maybe a step back, but it also might be two steps forward,” he said.

Still, current data science students, like Emma-Dai Valenzuela, say the class in its current form has been invaluable. A senior in teacher Stefanie Davison’s class at Pacifica High School, Valenzuela said it has allowed her to fulfill her graduation requirements while actually succeeding in a math class.

She transferred into the class after struggling in Math III, the integrated Algebra II course, she said. Valenzuela plans to join the Navy before attending college, and said her recruiters told her this course would offer a basic understanding of coding and math she can build on later.

“This is more hands-on,” she said. “We’re constantly doing new things.”

* Corrections: This story has been updated to say that data science courses were equivalent to general statistics classes under University of California system admissions rules, and to clarify Pamela Burdman’s comment about student performance in Algebra II.

It has also been updated to clarify Jelani Nelson’s comment about the importance of foundational math for college coursework.

The name of the ed tech vendor Bootstrap has also been updated.

This story about data science was produced by The Hechinger Report, a nonprofit, independent news organization focused on inequality and innovation in education. Sign up for the Hechinger newsletter.

Related articles"
https://pulse2.com/ai-squared-13-8-million-raised-to-deliver-data-and-insights-into-business-apps/,AI Squared: $13.8 Million Raised To Deliver Data And Insights Into Business Apps,"AI Squared, a company that helps organizations deliver data and AI insights into business applications, announced today that it has raised $13.8 million in Series A funding led by Ansa Capital with participation from existing investors NEA and Ridgeline.

Ansa Capital co-founder and General Partner Allan Jean-Baptiste will join AI Squared’s board in connection with the funding round. Roger W. Ferguson Jr., former Vice Chairman of the Federal Reserve and board member of Alphabet, has also invested and will join the company’s Board of Directors. AI Squared will use this funding round to expand the team and mature its platform, helping businesses integrate AI into their workflows.

As investments in artificial intelligence are continuously growing, data science teams in businesses and governments are focused on implementing AI models that can extract much more value from their data, improving their decision-making and the efficiency of their operations. And AI Squared’s platform drastically increases companies’ ROI in AI-driven projects by making it easier to integrate and adopt AI-powered insights into the tools and apps they use daily.

AI Squared’s founding team, including founder and CEO Benjamin Harvey, Ph.D., taps into deep data science expertise gained over a decade in the National Security Agency and within Databricks’ data science team.

The company has estimated that up to 90% of AI models developed by enterprises do not make it into production mode, meaning they struggle to generate more value from their AI investments. And the company’s solution reduces the time to integrate data and AI into workflows from four months to four minutes and reduces the cost of implementing even one model by roughly 100 times.

Model developers can use AI Squared’s platform to build pipelines that connect data sources and AI models to business applications, rendering relevant insights directly into their workflows. With AI Squared, users can connect machine-learning models and other advanced analytics to business applications directly and in an app-agnostic way. Then, AI Squared’s platform creates feedback loops to improve model performance and UI design. The company’s solutions are being implemented across the finance, manufacturing, and health sectors, including Fortune 500 enterprises — and government organizations.

AI Squared – which is one of the few Black-founded AI businesses – is also committed to expanding accessibility on the broader ecosystem to ensure underrepresented communities help drive forward progress in AI. And the company recently funded the AI Squared Innovation Lab, offering computers and supplies for supporting programming and technology advancement. AI Squared will also continue its internship programs for underserved students.

KEY QUOTES:

“Far too many companies aren’t getting enough ROI from AI. Deploying a single model often requires the use of over 10 tools. AI Squared’s tools directly tackle this ‘last mile’ problem, and make it much easier for businesses to deploy, use, and improve the use of AI within their teams.”

– AI Squared’s founder and CEO Benjamin Harvey, Ph.D.

“While AI’s capabilities are rapidly growing, organizations’ ability to deploy them are not. With new state-of-the-art models being released practically every week, enterprises risk getting left behind. We see a massive market opportunity for AI Squared to solve significant corporate hurdles in AI implementation by simplifying integration into existing workflows and tools while enabling faster time to value for AI investments.”"
https://towardsdatascience.com/the-limitations-and-advantages-of-retrieval-augmented-generation-rag-9ec9b4ae3729,The Practical Limitations and Advantages of Retrieval Augmented Generation (RAG),"The Value of RAG

Imagine RAG as highly intelligent librarian who can sift through a digital library in seconds to answer your questions. Sometimes the librarian finds relevant and useful information to answer your questions , but other times they miss the mark.

Let’s explore situations in which RAG excels and those in which it falls short. In a future work, I will explore a series of approaches that can be used individually or in combination to improve RAGs capabilities — which will support better responses when used with a language model.

Where RAG Falls Short

Even the most intelligent librarian has their challenges , some of which include the ability to reason iteratively, ensuring that they are retrieving the most useful documents, and ensure that the information they are sourcing from is relevant and unbiased.

Piecing Together the Puzzle with Iterative Reasoning: One of the key limitations of current RAG is its lack of iterative reasoning capabilities. RAG is unable to fully understand whether the data that is being retrieved is the most relevant information the language model needs to effectively solve the problem.

For example, if you were to pose a question such as “What does the impact of new environmental regulations passed in 2024 have on my latest white paper?” a RAG-enabled system would attempt to retrieve the data most semantically similar to the query. It might return the top X documents that have information on new policies, but are they the relevant policies for the specific paper the user is referencing?

As humans, we would approach this problem with reasoning skills. We would first read the white paper to understand its content and then determine what type of environmental policies best apply. Then based on that knowledge we would perform a search for those white papers. This iterative reasoning process — understanding the problem, formulating a more targeted search strategy, and then retrieving the most useful information — is a capability that current RAG implementations lack.

Organization Matters: The performance and effectiveness of RAG is heavily dependent on the organization and structure of the underlying data it is accessing. The ability for the retrieval algorithm to identify and surface the most useful documents is greatly influenced by how that information is cataloged and stored as well as how semantically similar the query is to the data retrieved.

In our library analogy, imagine a scenario where 500 books on various subjects are simply placed haphazardly on a single shelf, without any categorization or tagging. Trying to find the most relevant resources to answer a specific query would be a feat. You may stumble across some potentially useful books, but have no reliable way to assess which ones contain the most pertinent information. If those same 500 books were organized by genre, with clear metadata and subject tags, the retrieval process becomes significantly more efficient and effective. Rather than blindly scanning the entire shelf, the RAG implementation could quickly zero in on the most relevant section(s).

The same principles apply to how data is stored and indexed for RAG implementations in real-world applications. If the underlying datasets lack coherent organization, categorization, and metadata, the retrieval algorithms will struggle to identify the most valuable information. Ensuring data is properly structured, cataloged, and accessible is a critical.

The Good, the Bad, and the Biased : The quality of the data retrieved by a RAG implementation is only as good as the data it has access to. If the information in the underlying source systems, be it databases, online file storage, or other data repositories, contains outdated, incomplete, or biased content, the RAG implementation will have no way to discern this. It will simply retrieve and pass along this flawed information to the language model responsible for generating the final output.

Where RAG Models Shine

Accessing Domain Specific and Confidential Information: One of the key advantages of RAG is the ability to leverage domain-specific and even confidential information that may not be included in a language model’s standard training data. This can be particularly beneficial for organizations working on proprietary, cutting-edge research and projects. For example, if a company is conducting groundbreaking research in quantum computing that has not yet been publicly released, a RAG implementation could be granted access to these internal data sources. This would allow the language model to access specialized knowledge to engage in discussions about the company’s latest developments, without needing to be trained on that confidential information.

However, exposing sensitive, internal data to externally hosted language models (such as GPT, LLAMA, etc.) is not risk free. Organizations must exercise due diligence to ensure proper data security measures are in place to protect their intellectual property and confidential information.

Bringing the Latest News to Your Conversation: One of the key advantages of RAG is its ability to provide language models with access to the most up-to-date information, going beyond the fixed cutoff date of the language model’s original training data.If a language model were to rely solely on its inherent knowledge, its information would be limited to what was available at the time it was trained.

RAG implementations, on the other hand, can be integrated with live data sources such as the internet, constantly updating databases, news feeds, etc. This allows the language model to utilize current information when generating responses.

Conclusion

Retrieval Augmented Generation (RAG) is a powerful technique that can enhance language models by providing access to a wealth of information beyond their initial training. However, it is important to be aware of the limitations of RAG, such as the need for iterative reasoning, the importance of well organized data, and the potential for biased or outdated information. In a future work, I will explore a series of approaches to improve the capabilities of RAG — enhancing the quality of responses generated by a language model."
https://indiaai.gov.in/article/manisha-banthia-vice-president-data-analytics-global-services-fiserv,"Manisha Banthia, Vice President, Data & Analytics, Global Services, Fiserv","Manisha Banthia is the Vice President of Data and analytics at Fiserv Global Services, where she leads a team of experts in developing cutting-edge analytics solutions that leverage AI and ML. She has 25 years of experience building analytics teams across various organisations. At Fiserv, she is responsible for integrating analytics solutions with Fiserv products and providing advisory services to its clients. She also oversees the data management and analytics solutions that were recently added to the analytics portfolio.

Can you tell us about your AI journey?

My career journey started over 25 years ago when AI was just beginning to find its place in financial services. It all began with a keen interest in data analysis and technology, eventually leading me to an enriching career path. My professional journey started with a large bank where I handled data-centric responsibilities encompassing risk, marketing analytics, and financial profitability computations. This experience laid the groundwork for my venture into creating analytical solutions, extending my expertise across the fintech sector. Transitioning to a leadership role in analytics and data science at a multinational IT firm, I honed my skills, innovated solutions, and identified growth opportunities through advanced technologies. I joined Fiserv in 2021 as Vice President of Data and Analytics, focusing on harnessing data's transformative power and establishing a high-performing team to drive value for our clients. Overseeing the Data, Analytics, and Research teams, I focus on delivering innovative solutions, evaluating new technologies, and fostering collaboration with business leaders and clients. Throughout my journey, I've received prestigious recognitions like 'Data Leader of the Year' at Bonhill's Women in IT Asia Awards 2023 and the 'Techinist' Award from Wequity, reaffirming my dedication to advancing AI in financial services. I am committed to exploring new horizons and finding fulfilment in continually learning and leveraging AI to drive meaningful change in the industry.

What is your area of expertise in AI, and what made you choose it?

My area of specialisation in AI centres on its strategic application within the business realm, which transcends mere model development or data analysis to cover the utilisation of AI to drive tangible outcomes. This encompasses the thoughtful integration of AI technologies to solve complex business challenges, enhance decision-making processes, and unlock new opportunities for growth and efficiency. By focusing on the practical implications of AI, my approach aims to leverage these advanced technologies as tools for automation or analytics and as catalysts for transformation and innovation within organisations. My journey into this field stems from a blend of my Master of Business Administration background and a passion for technology.

During my formative years, I immersed myself in the banking world and the potential of artificial intelligence and machine learning to revolutionise traditional practices. My love for coding and analytical thinking —skills I honed through various computer science courses undertaken alongside my MBA—propelled my fascination further. The data query and analysis process, especially its application in solving business problems, resonated with me, igniting a desire to explore this synergy further. My expertise thus lies at the confluence of domain-specific knowledge and technical acumen. Whether crafting algorithms or deciphering complex datasets, I thrive on the challenge of bridging the gap between technology and business strategy. This holistic approach, honed over years of experience, defines my dedication to leveraging AI to address real-world business challenges.

How did generative AI impact your field of work?

In the swiftly advancing domain of AI, Generative Artificial Intelligence (GenAI) has already had a profound impact, serving as a pivotal force in reshaping industry paradigms, and the Fintech sector is no exception. Introducing GenAI into the ecosystem can significantly enhance operational efficiency, data integrity, and client engagement methodologies. By automating complex tasks, GenAI has dramatically accelerated processes, ensuring tasks that once took hours are now completed in minutes with enhanced accuracy. This leap in operational efficiency has streamlined internal workflows and bolstered data integrity, leading to more reliable insights and decision-making.

Describe some challenges you have faced in reaching where you are now.

Initially, there was a belief that success in Data and AI required an engineering background. However, my economics degree proved valuable, offering strategic insights. To fully engage in AI, I pursued coding skills and data analysis to complement my economics and finance knowledge. Over time, Data Analytics evolved from a niche to a cornerstone of modern business, paralleling my career journey. I remain dedicated to its potential, which has become central to strategic decision-making.

Do you see enough female leadership roles in corporates? In your opinion, what should change?

The fintech sector has made meaningful progress in gender diversity, with increasing emphasis on women in senior leadership. However, full gender parity remains a work in progress, highlighting the need for sustained efforts to dismantle barriers. A significant barrier is women's reluctance to pursue leadership roles due to acceptance of the status quo and fear of failure. To counter this, empowering women through direct responsibilities is crucial. Mentorship and sponsorship play pivotal roles in supporting women's leadership journeys.

Fiserv has initiated innovative efforts to bridge this gap, such as the Women's Impact Network (WIN) ERG, offering professional development, networking, and leadership opportunities. Additionally, the Fiserv Leading Women Program fast-tracks women's career growth through networking, skill development, and mentorship. At the same time, the Rise Up program supports women in new leadership roles through specialised training modules. Blended training approaches ensure associates stay updated with technology and prepared for their roles.

What do you want to say to women who wish to build careers in AI and other tech-related fields?

To aspiring women in AI and tech: Invest time in learning—it's crucial. Pursue knowledge through education and self-guided exploration. Apply what you learn, integrating AI into your roles. Seek mentors for guidance. Learning opportunities often arise unexpectedly. Network and seek advice from seasoned professionals. Follow your passion in engineering and tech; it requires commitment, analytical skills, and problem-solving passion. Embrace your interests and strengths for success."
https://towardsdatascience.com/how-to-generate-videos-with-open-sora-plan-video-generation-model-fdee4151ec90,How to Generate Videos with Open-Sora-Plan Video Generation Model,"In this article, you will learn how to use the Open-Sora-Plan video generation model [1], a powerful model that allows you to create your own videos, as you have seen with OpenAI Sora. I will discuss different tasks to which you can apply the model to, like generating animated videos and creating synthetic datasets. I will then give my thoughts on the model's performance and discuss its strengths and weaknesses. Ultimately, you should have a clearer picture of the utility you can get from this model.

Motivation

My motivation for this article is that an essential part of working as a data scientist is to keep up with the latest models within machine learning. Keeping up with the constant advances in AI takes time and effort. Therefore, I bring up some promising models I discovered on pages like PapersWithCode, GitHub, and HuggingFace in a series of articles. After finding a model interesting, I test it myself to see if it can be helpful for anything I am working with, which could be for work or personal projects. If the model could be beneficial, I then consider applying the model to the tasks I need it for.

Keeping up with the newest model is essential to stay caught up on the constant advancements in AI. This also makes me better at solving future problems, considering I will be more aware of the potential models that can be used to solve problems. My first article in the series of discovering the newest AI models was time series forecasting with Amazon’s Chronos model, and my second article was on the fantastic DocOwl vision-language model, which I highly recommend checking out below:

Table of contents"
https://edsource.org/2024/uc-confirms-data-science-cant-sub-for-algebra-ii-unresolved-what-can-it-qualify-for/707043,UC professors’ math problem: How does data science fit in?,"An influential committee of the UC Academic Senate weighed in again last month on the contentious issue of how much math high school students must take to qualify to attend a four-year California state university.

It ruled that high school students taking an introductory data science course or AP Statistics cannot substitute it for Algebra II for admission to the University of California and California State University, starting in the fall of 2025.

The Board of Admissions and Relations with Schools or BOARS reaffirmed its position by accepting the recommendations of a workgroup of math and statistics professors who examined the issue. That workgroup determined that none of these courses labeled as data science “even come close” to qualifying as a more advanced algebra course.

Robert Gould, a teaching professor and vice chair of undergraduate studies in the statistics department at UCLA and lead author of Introduction to Data Science, said that he disagrees with BOARS’ decision. The course was created under the auspices of the National Science Foundation through a math and science partnership grant.

“We are disappointed, of course,” he said. “We believe our course is rigorous and challenging and, most importantly, contains knowledge and skills that all students need for both career and academic success.”

But how, then, will UC and CSU ultimately fit popular data science courses like CourseKata, Introduction to Data Science, and YouCubed’s Explorations in Data Science into course requirements for admission? That bigger question won’t be determined until May when the math workgroup will issue its next report.

Data science advocates are worried that BOARS, which commissioned the review, may disqualify data science and possibly statistics under the category of math courses meeting the criteria for admissions. Increasing numbers of high school students are turning to introductory data courses in a world shaped by artificial intelligence and other data-driven opportunities and careers. They see them as approachable alternatives to trigonometry, pre-calculus and other rigorous courses students must take to major in science, technology engineering or math (STEM) in college.

Dozens of high school math teachers and administrators have signed a letter being circulated that will go to the UC regents. It reiterates support for data science and statistics courses and criticizes BOARS for not consulting high school teachers and data science experts for their perspectives.

“Our schools and districts have adopted such courses because they provide an innovative 21st-century experience that excites and engages students, impart tangible quantitative skills needed for a wide variety of today’s careers and academic fields, and offer new ways for students to interact with and learn mathematics,” the letter states.

Pamela Burdman, executive director of the nonprofit Just Equations, agreed in a blog post titled “The Latest in the Inexplicable War on High School Data Science Courses.” “The bottom line is that districts are increasingly offering these courses because they are relevant and engaging for many students who otherwise would be turned off by mathematics,” she wrote.

Will it help or hinder equity?

Critics of substituting introductory data sciences courses for advanced algebra include STEM professors at UC and CSU. Many say they support data science, but not courses lacking the full range of math topics in high schools that students need for STEM or any major requiring quantitative skills. Skipping foundational math in high school will set back the cause of equity for underserved students of color, not advance it, they argue, by creating the illusion that students are ready for statistics, computer science and data science majors when they aren’t. That may force them to take catch-up courses in community college.

“The only way we’re going to diversify STEM fields is to keep historically excluded young students on the algebraic thinking pathway just a little bit longer,” Elizabeth Statmore, a math teacher at Lowell High in San Francisco and former software executive, wrote to EdSource last year. “That will give them the mathematical competencies they will need to make their own decisions about whether or not they want to pursue rigorous quantitative majors and careers.”

Proponents of holding the line on Algebra II and encouraging more students to pursue STEM majors are circulating their own attention-grabbing letter titled Strong Math Foundations are Important for AI. The signers, including Sam Altman, CEO of OpenAI, his nemesis Elon Musk, founder of Tesla, SpaceX and CEO of X, and executives from Apple, NVIDIA, Microsoft and Google, “applaud” UC for maintaining the math requirements.

“While today’s advances might suggest classic mathematical topics like calculus or algebra are outdated, nothing could be further from the truth. In reality, modern AI systems are rooted in mathematics, making a strong command over math necessary for careers in this field,” it reads. “Failure to maintain standards in the mathematical curriculum in public education will increase the gap between public schools — especially those of under-resourced districts — and private schools, hampering efforts to diversify STEM.”

Surprise actions by UC Office of President

For decades, UC and CSU have required that students complete three years of math with at least a “C” — usually in the sequence Algebra I, Geometry, and Algebra II, also called Advanced Algebra – as the math component of A-G, the 15 courses needed for admission. For students taking integrated math, it is Math I, II and III. Both university systems recommend a fourth year of math, and most students take at least that; aspiring STEM majors take two or more additional courses leading to Calculus.

BOARS establishes policies on admissions, but a small office in the UC President’s Office, the High School Articulation Unit, vets tens of thousands of courses that developers and high school teachers submit for approval. Starting in 2014, the unit began authorizing AP statistics and new data science courses as “validating” or satisfying Algebra II or Integrated Math III content requirements. That meant they either built on the content standards that students had covered or would cover in the course.

Although AP Statistics doesn’t cover most Algebra II topics, the rationale for validating it and data science courses — mistakenly so, BOARS determined in retrospect — was that Algebra II includes some statistics, and most teachers never get around to teaching it. That was problematic for introductory data science courses, because the state hasn’t set standards for what should be covered in the courses. The College Board, the creator of AP Statistics, states that the course is designed for students who have completed Algebra II.

During the last few years, the staff in the review office approved the three most popular data science courses in more than 400 high schools. After analyzing the three courses, the UC workgroup professors concluded, “We find these current courses labeled as ‘data science’ are more akin to data literacy courses.”

UC academic committee meetings, including BOARS, are closed to the public. But minutes from the July 2023 meeting indicated that some faculty members were dismayed that the articulation office had validated so many data science courses without their knowledge. “At least one member repeatedly suggested that UCOP has misinterpreted/misapplied the advanced math standard for years — and absent correction, will continue to do so — and so review of all current courses potentially implicated is needed,” the minutes state.

BOARS hasn’t ruled out approving future data science courses that include more advanced algebra as a substitute for Algebra II; the articulation office has validated Financial Algebra for that purpose. BOARS invited course alternatives in a June 2020 statement, saying it saw the expanded options “as both a college preparation and equity issue.”

But data science proponents are concerned that the math workgroup will take the opposite position and recommend that the three introductory data science courses be treated as elective courses for A-G but not fourth-year math courses. Ruling that way, they argue, would discourage future non-STEM majors from taking an alternative quantitative reasoning course as seniors. Such a position would reinforce a narrow view that only courses leading to Calculus are legitimate math offerings in the senior year.

“Revocation of Area C (math) status will significantly reduce our ability to foster students’ statistical and data competency or incentivize enrollment in these programs, at a time when such quantitative abilities are increasingly necessary for functioning personally and professionally in the 21st Century,” the letter to the UC regents says.

Lai Bui, a veteran math teacher at Mills High School in the San Mateo Union High School District, said there’s no justification for treating CourseKata, an introduction to data science course, differently from AP Statistics, which BOARS has qualified as a fourth-year math course. Students in CourseKata use coding to analyze datasets, while AP Stats students use graphing calculators, which have limitations, she said.

UCLA and CSU Los Angeles created CourseKata in 2017 as a semester course for college and as a two-semester course for high schools; otherwise, they are similar, said Bui, who has taught it for four years.

“CourseKata is definitely not data literacy,” she said. “It’s a math course, like AP Statistics, only more real-world connected. I see students succeeding in math instead of thinking, ‘I am not a math person.’”

In 2023, the CSU Academic Senate expressed frustration that UC was approving courses in data science in lieu of Algebra II without consulting it and urged more joint decision-making involving A-G decisions. In January, three CSU professors were added to the 10-member UC math workgroup.

Mark Van Selst, a psychology professor at San Jose State and member of the Academic Preparation and Education Programs Committee, considered CSU’s counterpart of BOARS, said this week he fully supports the decision not to retreat from Algebra II as a base of knowledge. But he also favors qualifying non-traditional fourth-year math courses that strengthen quantitative reasoning. He said he hopes the UC math workgroup drafts standards or learning outcomes for data science to distinguish between electives and advanced math courses.

Gould said he would need to review the possible criteria before deciding whether to revise the content of Introduction to Data Science.

“A data science education is essential for all students, and all students deserve a relevant and useful math education,” he said. “Despite the committee’s decision, we think it’s important that data science and statistics courses continue to qualify as fourth-year math courses.”"
https://news.wfu.edu/2024/03/27/program-aims-to-ignite-youth-excitement-in-data-science-careers/,Program aims to ignite youth excitement in data science careers,"The goal of the program is to engage kids, promote future career opportunities, and celebrate the contributions of women to these fields. Although best known as a pioneer in nursing, Nightingale also had a significant impact on the use of statistics to improve health outcomes.

“It’s an immersive way of bringing middle and high schoolers into statistics and data science. We try to make it very interactive,” said Sarah Lotspeich, also an assistant professor of statistics.

Merging fun with math and statistics

The day is filled with lots of hands-on activities, including a catapult that students will use to explore experimental design concepts. To learn about machine learning, kids will build a classification algorithm of cats and dogs.

These types of exercises help develop valuable analytical and problem-solving skills.

All students 13 years old and up can participate.

“It’s not just an event – it brings kids to a college campus,” said David Kline, assistant professor at Wake Forest University School of Medicine. “Kids get to be in a college classroom and experience a college environment for an afternoon.”

Meeting the experts

A highlight of the program is a diverse panel of field experts who will talk about their career experiences. Three women speakers representing different careers in statistics (industry, academia, and medicine) will also answer questions from students at the end of the session.

This year’s panelists are Wake Forest alumna Amy Zinnia, ‘22 B.S., a biostatistician at Wake Forest University Medical Center, Emily Griffith, Ph.D., director of consulting, associate professor of the practice (Statistics) at North Carolina State University, and Portia Exum, M.S. manager, software development engineer in Test at SAS.

“I’m excited to share and answer questions from youth about what I do for work and my journey in getting there,” Zinnia said. “I had little to no exposure to statistics until senior year of high school. I did not fully know what I could do with it. You don’t have to have a Ph. D to find career opportunities in data science and I hope these stories inspire and motivate kids that they can do it too.”

Partnering with WSSU

The event is cosponsored by Wake Forest’s Department of Biostatistics and Data Science at Wake Forest University School of Medicine and the Department of Statistical Sciences on the Reynolda Campus.

This year, organizers are partnering with Winston-Salem State University.

“This partnership is building synergy between the two universities in the community and our goal is to have a lasting impact,” said Felicia Simpson, chair of the math department at WSSU and a co-organizer of this year’s event.

Simpson was one of the expert panelists at the inaugural Florence Nightingale Day held at Wake Forest last spring. She’s heavily involved in educational community outreach programs for youth in Forsyth County.

“Early exposure is so important,” she said. “The event that we are having on April 20 changes what it looks like to be a statistician. It doesn’t matter if you are a woman or a male, it doesn’t matter your race or your ethnicity – if you love math and you love numbers then let’s tie it to your interests. It’s about meeting students where they are,” added Simpson.

According to a recent report, few students take statistics before college. In 2023, just over 242,000 of approximately 15.4 million U.S. high schoolers took the Advanced Placement (AP) statistics exam– a slight increase from 2022.

“When you see the growth in North Carolina alone, with industries like biotech and pharmaceuticals in the Research Triangle and the expansion even right here in Winston-Salem with Innovation Quarter, you get an idea of why planting seeds of interest about these fields are so important to our communities, our state and our future,” Kline said.

Overall employment of mathematicians and statisticians is projected to grow 30 percent from 2022 to 2032, much faster than the average for all occupations, according to Bureau of Labor Statistics data.

Florence Nightingale Day was launched in 2018 at a handful of higher education institutions across the country. During the Crimean War, she applied quantitative and visualization data techniques in her work to care for wounded soldiers who were hospitalized.

Registration is encouraged for the event. Families can find out more here."
https://towardsdatascience.com/callbacks-and-pipeline-structures-in-langchain-925aa077227e?source=rss----7f60cf5620c9---4,Callbacks and Pipeline structures in LangChain,"Learn about the structure of LangChain pipelines, callbacks, how to create custom callbacks and integrate them into your pipelines for improved monitoring

Roshan Santhosh

·

Follow

Published in

Towards Data Science

·

11 min read

·

1 day ago

--

Callbacks are an important functionality that helps with monitoring/debugging your pipelines. In this note, we cover the basics of callbacks and how to create custom ones for your use cases. More importantly, through examples, we also develop an understanding of the structure/componentization of LangChain pipelines and how that plays into the design of custom callbacks.

This note assumes basic familiarity with LangChain and how pipelines in LangChain work.

Basic Structure of Callbacks

To learn about the basics of callbacks in LangChain, we start with the official documentation where we can find the definition of the BaseCallbackHandler class.

BaseCallbackManager code

As you can see this is an abstract class that defines quite a few methods to cover various events in your LangChain pipeline. These methods can be grouped together into the following segments :

LLM [start, end, error, new token]

Chain [start, end, error]

Tool [start, end, error]

Agent [action, finish]

If you have worked with LangChain pipelines before, the methods along with their provided descriptions should be mostly self explanatory. For example, the on_llm_start callback is the event that gets triggered when the LangChain pipeline passes input to the LLM. And that on_llm_end is subsequently triggered when the LLM provides its final output.

NOTE : There are events triggers that can be used in addition to whats shown above. These can be found here. These cover triggers relating to Retrievers, Prompts, ChatModel etc.

Understanding how Callbacks work

Callbacks are a very common programming concept that have been widely used for a while now, so the high level concept of how callbacks work is well understood. So in this post, we focus on the specific nuances of how callbacks work in LangChain and how we could use it to satisfy our specific use cases.

Keeping in the mind the base Callback class that we saw in the previous section, we explore Callbacks in LangChain through a series of increasingly complex examples and in the process gain a better understanding of the structure of pipelines in LangChain. This would be a top-down approach to learning where we start with examples first and actual definitions later as I found that to be more useful personally for this specific topic.

Example 1

We start with a simple dummy chain that has 3 components : 2 prompts and a custom function to join them. I refer to this as a dummy example because its very unlikely that you would need two separate prompts to interact with each other, but it makes for an easier example to start with for understanding callbacks and LangChain pipelines.

Implementing this in code would look like :

The above code is pretty textbook stuff. The only possibly complex piece is the retrieve_text and RunnableLambda function thats being used here. The reason this is necessary is because the format of the output from qa_prompt1 is not compatible with the format of the output required by qa_prompt2.

Defining the custom Callback

For our custom callback, we define a new subclass of BaseCallbackHandler called CustomCallback1 which defines the on_chain_start method. The method definition is straightforward as it simply takes the input values passed to it and saves it in 2 specific variables : chain_input and serialized_input

Invoking the custom callback

The above code shows one of the possible ways to pass your custom callback to your pipeline : As a list of callback objects as the value to a corresponding key of ‘callbacks’. This also makes it easy to guess that you can pass multiple callbacks to your LangChain pipeline.

Decoding the Callback/Pipeline Structure

Now comes the interesting part. After we have defined the callbacks and passed it on to our pipeline, we now perform a deep dive into the callback outputs

We first look at the values stored in chain_input

Observations :

Though there are 3 components in our chain, there are 4 values in chain_input. Which corresponds to the on_chain_start method being triggered 4 times instead of 3.

For the first two chain_input values/ on_chain_start triggers, the input is the same as the user provided input.

We next look at the outputs of serialized_input

Observations :

The first component is a RunnableSequence which is a component that wasnt added by the user but was automatically added by LangChain. The rest of the components correspond directly to the user-defined components in the pipeline.

The full contents of serialized_input is extensive! While there is a definite structure to that content, its definitely out of scope for this post and possibly doesnt have much practical implications for an end user.

How do we interpret these results

For the most part, the outputs seen in the chain_input and serialized_input make sense. Whether its the input values or the names/IDs of the components. The only largely unknown part is the RunnableSequence component, so we take a closer look at this.

As I mentioned previously, the full contents of serialized_input is extensive and not easy to digest. So to make things easier, we look at only the high level attributes described in serialized_input and try to intrepret the results through these attributes. For this, we make use of a custom debugging function called getChainBreakdown (code in notebook).

We call getChainBreakdown on all values of serialized_input and observe the output. Specifically for the first RunnableSequence element, we look at the keys of the kwargs dict : first, midde, last, name.

On closer inspection of the kwargs argument and their values, we see that they have the same structure as our previous pipeline components. In fact, the first, middle and last components correspond exactly to the user-defined components of the pipeline.

The above details form the basis of the final conclusion that we make here. That the structure of the pipeline is like shown below :

We do make a bit of a leap here as the above flowchart was confirmed after going through a bunch of examples and observing the format in which these components are created internally by LangChain. So bear with me as we go through these other examples which will solidify the conclusion that we make here.

With the above defined structure, the other pieces of the puzzle fit together quite well. Focusing on the chain_input values, lets map them to the components (with their ordering) defined above.

Observations :

For RunnableSequence, as it acts like a wrapper for the whole pipeline, the input from the user acts as the input for the RunnableSequence component as well.

For the first ChatPromptTemplate (qa_prompt1), as the first ‘true’ component of the pipeline, it receives the direct input from the user

For RunnableLambda (retrieve_text), it receives as input the output from qa_prompt1, which is a Message object

For the last ChatPromptTemplate (qa_prompt2), it receives as input the output from retrieve_text, which is a dict with ‘prompt’ as its single key

The above breakdown shows how the structure of the pipeline described above fits perfectly with the data seen in serialized_input and chain_input

Example 2

For the next example, we extend Example 1 by adding a LLM as the final step.

For the callback, since we have now added a LLM into the mix, we define a new custom callback that additionally defines the on_llm_start method. It has the same functionality as on_chain_start where the input arguments are saved into the callback object variables : chain_input and serialized_input

Proposing the Pipeline structure

At this stage, instead of evaluating the callback variables, we switch things up and propose the potential structure of the pipeline. Given what we had learnt from the first example, the following should be the potential structure of the pipeline

So we would have a RunnableSequence component as a wrapper for the pipeline. And additionally include a new ChatOpenAI object thats nested within the RunnableSequence component.

Validating proposed structure using data

We now look at the values of in the callback object to validate the above proposed structure.

We first look at the values stored in chain_input

And then the serialized_input values :

As well as a deeper inspection of the RunnableSequence components

Observations :

The values of serialized_input validate the activation/trigger sequence that was proposed in the pipeline structure : RunnableSequence -> ChatPromptTemplate(qa_prompt1) -> RunnableLambda(retrieve_text) -> ChatPromptTemplate(qa_prompt2) -> ChatOpenAI

The values of chain_input also map correctly to the proposed structure. The only new addition is the fifth entry, which corresponds to the output from qa_prompt2, which is fed as input to the ChatOpenAI object

The components of the RunnableSequence kwargs also verify the proposed structure as the new ‘last’ element is the ChatOpenAI object

By this stage, you should have an intuitive understanding of how LangChain pipelines are structured and when/how different callback events are triggered.

Though we have only focused on Chain and LLM events so far, these translate well to the other Tool and Agent triggers as well

Example 3

For the next example, we progress to a more complex chain involving a parallel implementation (RunnableParallel)

Chain/Callback Implementation

The chain has a parallel implementation as its first block which computes two values : context and question, which are then passed on to a prompt template to create the final prompt. The parallel functionality is required because we need to pass both context and question to the prompt template at the same time, where the context is retrived from a different source while the question is provided by the user.

For the context value, we use a static function get_data that returns the same piece of text (this is a dummy version of an actual retriever used in RAG applications).

For the callback implementation, we use the same callback as the first example, CustomCallback1

Decoding the Callback/Pipeline Structure

Similar to previous examples, we start by looking at the outputs of chain_input and serialized_input

We also look do a deep dive into the RunnableSequence (index 0) and RunnableParallel (index 1) components

Observations :

Consistent with previous examples, the RunnableSequence acts as a wrapper to the whole pipeline. Its first component is the RunnableParallel component and its last component is the ChatPromptTemplate component

The RunnableParallel in turn encompasses two components : the RunnablePassthrough and the RunnableLambda (get_data).

The inputs to the first 4 components : RunnableSequence, RunnableParallel, RunnablePassthrough and RunnableLambda (get_data) are the same : the provided user input. Only for the final ChatPromptTemplate component do we have a different input, which is a dict with question and context keys.

Based on these observations, we can infer the final structure of the pipeline as such :

Example 4

Same as Example 3, but with an additional processing function for retrieving context

Chain/Callback Implementation

Decoding the Callback/Pipeline Structure

Similar to previous examples, we again look at the usual data points

We observe that there are now 2 RunnableSequence components in our pipeline. So for the next step, we deep dive into both of these RunnableSequence components to see its internal components

Observations :

For the first RunnableSequence components, its components are the same as the previous example. Starts with RunnableParallel and ends with ChatPromptTemplate

For the second RunnableSequence, its first component is the RunnableLambda (get_data) component and the last component is the RunnableLambda (format_docs) component. This is basically the part of the pipeline responsible for generating the ‘context’ value. So its possible for a LangChain pipeline to have multiple RunnableSequence components to it. Especially when you are creating ‘sub-pipelines’

In this case, the creation of the ‘context’ value can be considered a pipeline by itself as it involves 2 different components chained together. So any such sub-pipelines in your primary pipeline will be wrapped up by a RunnableSequence component

3. The values from chain_input also match up well with the pipeline components and their ordering (Not going to breakdown each component’s input here as it should be self-explanatory by now)

So based on the above observations, the following is the identified structure of this pipeline

Conclusion

The objective of this post was to help develop an (intuitive) understanding of how LangChain pipelines are structured and how callback triggers are associated with the pipeline.

By going through increasingly complex chain implementations, we were able to understand the general structure of LangChain pipelines and how a callback can be used for retrieving useful information. Developing an understanding of how LangChain pipelines are structured will also help facilitate the debugging process when errors are encountered.

A very common use case for callbacks is retrieving intermediate steps and through these examples we saw how we can implement custom callbacks that track the input at each stage of the pipeline. Add to this our understanding of the structure of the LangChain pipelines, we can now easily pinpoint the input to each component of the pipeline and retrieve it accordingly.

Resources

Notebook with code/examples : Contains few additional examples not covered in this note.

Unless specified otherwise, all images are created by the author.

In addition to Medium, I share my thoughts, ideas and other updates on Linkedin."
https://today.ucsd.edu/story/using-ai-and-data-science-to-renourish-food-deserts,Using AI and Data Science to ReNOURISH Food Deserts,"Article Content

Twenty-four million Americans live in food deserts where ultraprocessed foods are abundant and fresh food is scarce, giving rise to large health disparities in diabetes and related cardiometabolic diseases. To address this problem, an interdisciplinary team of researchers from UC San Francisco and UC San Diego conceptualized the NOURISH platform, winning support last year from the U.S. National Science Foundation (NSF) Convergence Accelerator program to design the tool. Now, with continued NSF and U.S. Department of Agriculture funding, the team of experts has moved into the platform-building phase.

NOURISH is meant to provide small business owners in food desert communities with access to loans and grants, online maps that optimize the placement of fresh food outlets for foot traffic, help with navigating the convoluted business permitting process and AI-enabled guidance on affordable ways to locally source fresh ingredients.

“Our solution complements government efforts to get fresh food into food deserts by incentivizing grocery stores and big box outlets to sell more fresh food,” said Laura Schmidt of UC San Francisco, principal investigator for the project. “But our approach builds upon the often-overlooked assets of these communities, including the entrepreneurial talent of small business owners, rich and diverse food heritages, and an unmet demand for fresh food.”

Under the leadership of Amarnath Gupta, a team of computer scientists, software developers and students at the San Diego Supercomputer Center (SDSC) at UC San Diego are combining government, private sector and crowdsourced information to create dynamic, interactive maps of local food systems across the U.S. Gupta is a leading computer scientist in the Cyberinfrastructure and Convergence Research and Education (CICORE) Division at SDSC, directed by Ilkay Altintas.

“NOURISH embodies our vision at SDSC’s CICORE Division, where our deep expertise in data science and knowledge management seamlessly integrates with the diverse needs of our interdisciplinary and cross-sector partners. Together, we co-create solutions that are not just equitable but deeply impactful, tackling complex societal challenges head-on,” said Altintas, who also serves as SCSC’s chief data science officer. “In an era where access to equitable access to fresh food is still hard, NOURISH emerges as a solution to leverage cutting-edge technology to bridge the gap between communities and an ecosystem of entrepreneurship, innovation and cultural diversity. We look forward to seeing the growing impact of this project over the years to come.”

Accessible from a mobile phone in multiple languages, the NOURISH platform will include patented recommendation algorithms that customize business plans based on local consumer preferences for price, convenience and flavor.

“Recent advances in scalable data systems and artificial intelligence give us an unprecedented opportunity to use NOURISH to democratize data access, creating a more level playing field between large food companies and small businesses,” Gupta said.

Small businesses have relatively low start-up costs, are adaptive to local needs and can help to keep economic resources circulating within low-income communities. Community partners assisting with NOURISH also emphasize the benefits of promoting culturally appropriate food.

“A major asset of so-called ‘food deserts’ are immigrants who bring diverse cuisines featuring traditional dishes that are typically healthier than the standard American diet. This platform will help people from the community make wholesome food for the community,” said Paul Watson, a California-based food equity advocate and director of community engagement for NOURISH.

Other scientists on the team include Keith Pezzoli and Ilya Zaslavsky (UC San Diego), Hans Taparia (New York University), Tera Fazzino (University of Kansas) and Matthew Lange (IC-FOODS). In 2024-25, the NOURISH team will test the platform in lower-income areas within San Diego and Imperial counties in California, and then scale it nationally."
https://www.channelnewsasia.com/advertorial/powered-women-utilising-data-science-and-technology-drive-positive-change-4239431,Powered by women: Utilising data science and technology to drive positive change,"Despite being located thousands of kilometres away from Australia’s Great Barrier Reef, Dell Technologies’ regional headquarters in Singapore is deeply engaged in preserving the reef’s biodiversity from the adverse effects of climate change.

Committed to advancing sustainability, Dell invests in collaborations and initiatives that harness its technology, scale and talent to address complex challenges such as climate change, driving the circular economy and fostering inclusive workplaces.

In 2022, in partnership with conservation non-governmental organisation Citizens of the Reef, Dell launched a deep-learning artificial intelligence (AI) model to process the extensive reconnaissance data amassed as part of the Great Reef Census. The census is an annual survey that assesses the health and structures of the 2,300km-long coral reef system.

The model’s development was led by Ms Aruna Kolluru, chief technologist, AI, Dell Technologies (Asia Pacific and Japan), and supported by Ms Soo Mei May, director, data science, Dell Technologies Singapore and her data science team in Singapore.

INNOVATING WITH AI TO DRIVE CLIMATE ACTION

Dell’s model accurately categorises each pixel of an image into a class or object, leveraging a high-performance Dell computing system optimised for machine learning tasks. Data storage is facilitated by the Dell PowerScale system while the backbone of the AI training cluster and inference engines is supported by Dell PowerEdge servers.

These technologies enabled the data science team, in collaboration with marine experts, to classify the reef’s 144 coral species into five critical conservation categories based on their level of health and vulnerability. This facilitates precise and efficient conservation strategies for protecting and restoring the reefs.

Ms Soo highlighted the initial challenge of training the model from the ground up to identify corals. This became achievable through Dell’s advanced infrastructure that is capable of handling computationally intensive training tasks. “The outcome is a robust deep-learning model, whose accuracy will further improve with additional training data,” said Ms Soo.

Presently, a dataset comprising 13,000 images can be reviewed in under 200 hours, a notable acceleration compared to the 1,516 hours required for manual review. This rapid processing provides timely insights into reef health.

This project is now one of the world’s largest marine citizen science initiatives, engaging citizen scientists, including tourists and leisure divers, in capturing and analysing over 42,000 images from more than 315 reefs.

Ms Kolluru sees the project as a testament to AI’s capacity to tackle major global challenges, underscoring its significant impact on conservation through technological innovation and interdisciplinary collaboration.

PUSHING BOUNDARIES, CHAMPIONING INCLUSION

Both Ms Soo and Ms Kolluru are at the forefront of utilising technology to drive meaningful change.

Formerly an economist in the shipping industry, Ms Soo’s transition to data science was fuelled by a deep fascination with statistics, predictive analytics, as well as the transformative power of technology. “Joining Dell marked a pivotal moment in my career, providing me the chance to pioneer innovative solutions,” she said.

In addition to her expertise in AI and machine learning, Ms Soo plays a key role as the mentoring pillar lead in the Singapore chapter of Dell Technologies’ Women in Action employee resource group, where she drives MentorConnect, Dell’s cross-company, women-focused mentorship programme. The initiative promotes diverse leadership development and helps mentees cultivate the skills needed to advance their leadership endeavours.

Said Ms Soo: “I encourage all aspiring tech professionals, particularly women, to embrace the benefits of mentorship, broaden their networks and actively pursue opportunities for learning and exchanging best practices.”

Ms Kolluru is also a strong believer in mentorship, noting that she has seen first-hand how diverse viewpoints have led to the creation of innovative, inclusive and impactful solutions at the workplace. “My mission is to bridge the gender gap in tech and nurture a supportive community where young women feel a sense of belonging and safety as they navigate the tech world,” she added.

Ms Kolluru is involved in numerous initiatives, such as Dell’s Girls in Engineering and Technology, AI Avengers and Dell’s Code like a Girl. “Seeing the passion, determination and talent in these young women inspires me as well, reaffirming my belief that strong mentorship plays a critical role in fostering the next generation of female leaders in the tech industry,” she said.

Learn more about how Dell Technologies is committed to creating a better, more sustainable future."
https://www.theguardian.com/world/2024/apr/11/idf-colonel-discusses-data-science-magic-powder-for-locating-terrorists,IDF colonel discusses ‘data science magic powder’ for locating terrorists,"A video has surfaced of a senior official at Israel’s cyber intelligence agency, Unit 8200, talking last year about the use of machine learning “magic powder” to help identify Hamas targets in Gaza.

The footage raises questions about the accuracy of a recent statement about use of artificial intelligence (AI) by the Israeli Defense Forces (IDF), which said it “does not use an artificial intelligence system that identifies terrorist operatives or tries to predict whether a person is a terrorist”.

However, in the video, the head of data science and AI at Unit 8200 – named only as “Colonel Yoav” – said he would reveal an “example of one of the tools we use” before describing how the intelligence division used machine learning techniques in Israel’s May 2021 offensive in Gaza for “finding new terrorists”.

“Let’s say we have some terrorists that form a group and we know only some of them,” he said. “By practising our data science magic powder we are able to find the rest of them.”

The descriptions in the video of technology used by Unit 8200 bear similarities with recent testimony from six IDF insiders about their use of an AI tool called “Lavender” during its offensive on Hamas. They said that the AI-generated database had been used to assist intelligence officers involved in the bombing campaign in Gaza, helping identify tens of thousands of potential human targets.

In its rebuttal, the IDF said some of the accounts were “baseless”. However, the accounts are consistent with the remarks by Yoav during an AI conference at Tel Aviv university in February last year. The video, in which Yoav can be heard talking but not seen, was hosted on the university’s YouTube channel, and until recently it had fewer than 100 views.

As he took to the stage wearing a military uniform, the audience was instructed not to take any photos of Yoav or record his presentation. “It’s good because it’s a bad hair day for me,” he joked.

In the 10-minute presentation – titled “digital transformation and artificial intelligence in the intelligence domain” – the colonel offered a rare insight into how opaque AI systems are being used by secretive military and intelligence bodies.

When using AI to predict whether someone is a terrorist, he explained, Unit 8200 takes information it has about people it believes are members of terrorist groups and aims “to find the rest of the group”.

Referring to a specific example, the official said that in the IDF’s May 2021 military operation in Gaza, his department applied this principle to “find Hamas squad missile commanders and anti-tank missile terrorists in Gaza in order to operate against them”.

He explained that using a form of machine learning – known as “positive unlabelled learning” – “we take the original sub-group, we calculate their close circles, we then calculate relevant features, and at last we rank the results and determine the threshold.”

The colonel said intelligence officers’ feedback is used “to enrich and improve our algorithm” and stressed that “people of flesh and blood” make decisions. “Ethically speaking we put a lot of emphasis on this,” he said, adding that “these tools are meant to help break their barriers”.

According to Yoav, Unit 8200 was able to break “the human barrier” during the May 2021 offensive when it managed to produce more than 200 new targets. “There were times when this amount took us almost a year,” he said.

Contacted for comment about the video, the IDF said the colonel’s participation in the conference had been approved by the military. However, a spokesperson denied that his remarks conflict with the IDF’s recent denials about its use of AI. In a subtle change of wording not used in its original statement, the IDF told the Guardian its AI systems do not “choose targets” for attack.

“The IDF never denied the existence of a database of operatives in terrorist organisations, that cross-checks existing information on such operatives,” it said. “At the same time, the IDF fully stands by its statement that it does not use AI systems that choose targets for attack, and that the database in question is not a list of operatives eligible to attack. There is no contradiction.”

In their testimony, the six intelligence officers who spoke out last week said that the Lavender tool had been used to help identify potential targets at an unprecedented scale and pace. The IDF was not accused of using systems that automatically select targets for attack.

Four of the sources said that, at one stage early in the war, Lavender listed as many as 37,000 men in the enclave who had been linked by the AI system to Hamas or Palestinian Islamic Jihad. None of the sources denied that humans were involved in the process of authorising strikes, although some confessed to minimal human oversight.

“I would invest 20 seconds for each target at this stage, and do dozens of them every day,” one intelligence officer said. “I had zero added-value as a human, apart from being a stamp of approval. It saved a lot of time.”

Their accounts were published by the Israeli-Palestinian publication +972 magazine, its Hebrew-language outlet Local Call and the Guardian.

Col Yoav’s description of the partnership between AI and intelligence personnel echoes a model for targeting operations envisioned by his commander, the Unit 8200 chief Yossi Sariel, who the Guardian revealed left his identity exposed online when he secretly authored a book published in 2021, The Human Machine Team.

At one stage, the colonel explained that the AI and data science department he runs at Unit 8200 is also known internally as “the human machine integration centre”.

Speaking eight months before the IDF commenced operations in Gaza after the Hamas-led 7 October attacks, the colonel spoke optimistically about how the IDF is moving “from the postcard age to the digital era” where “suddenly you can react during battle with applied data-science driven solutions”.

Looking ahead, he added: “I’m curious with respect to how will the next operation look like, digitally speaking”."
https://miamioh.edu/news/2024/02/spirit-of-collaboration-mcvey-data-science-brings-miamians-together.html,‘Spirit of collaboration’: McVey Data Science brings Miamians together,"After only a few days into the 2023-2024 spring semester, many already were impressed with what they’ve seen from the newest addition to Miami University’s academic buildings.

Count Bob Davis among that number. Davis chairs Statistics, one of the departments that now calls the McVey Data Science building home. The 92,000-square-foot facility officially opened for students on Jan. 29. They quickly started utilizing spaces meant for collaboration in the three-story building located along Tallawanda Road.

“I walk past those spaces and students are there with their books open and their computers open, talking and working on things,” Davis said. “I think the way it’s set up with all the collaborative spaces makes it an attractive place for anyone.”

Increasing collaboration was one of the goals behind the construction of McVey Data Science, which was funded through a generous $20 million gift by alumnus Richard M. McVey ’81. A groundbreaking ceremony for the new facility between Withrow and Benton Halls was held in fall 2021.

Along with shared spaces to gather, McVey Data Science includes instructional space, offices, and research and project areas.

With 14 classrooms, 12 conference and seminar rooms, and 88 offices, McVey Data Science was envisioned as a place to foster transdisciplinary research, a forum for industry partners to connect, and a venue for academic instruction, student activities, and informal conversation.

The Department of Statistics, the Department of Emerging Technology in Business + Design, the Department of Computer Science and Software Engineering, the Center for Analytics and Data Science, the Armstrong Institute for Emerging Technology, and the Lilly Leadership Institute are housed within McVey. Information Systems and Analytics also has a presence but not office space.

“We have some of the most cutting-edge programs in the same building,” said Eric Bachmann, chair of the Department of Computer Science and Software Engineering. “It generates a lot of excitement when prospective students come to campus and tour. It’s going to help with recruiting.

“There is a spirit here of collaboration.”

The many glass windows and doors allow natural light to fill the interior of the McVey Data Science building.

An innovative approach

Early in the project, data analytics were used to simulate what would be the most likely walking paths taken throughout the building. Data also was compiled to project the use of the building, which was then utilized in creating McVey’s atrium space.

Rick McVey ’81, the building’s namesake, is at the forefront of the financial technology industry. As founder and executive chairman of MarketAxess, McVey helms a leading electronic trading platform for global bond markets.

As a former student-athlete who later served on Miami’s Foundation Board, McVey also is a passionate supporter of the university as it advances the field of data science.

“The opportunity that Rick’s gift afforded us had a tremendous impact and allowed us to do a lot of things,” said John Porchowsky, Miami’s project manager for McVey Data Science. “A lot of thought went into creating the building. It’s a live space, and there is a lot going on.”

Pushing the Miami brand in innovative and energetic new ways was part of the process.

“We’re getting the most bang for our buck out of the square footage,” said Robert Bell, Miami’s director of Planning, Architecture, and Engineering. “We really wanted it to be a place we could show that Miami is in touch with today and with the future.”

The XR Stage area is one of the innovative elements of the McVey Data Science building.

An eye toward the future

For proof of the forward-thinking represented at McVey Data Science, look no further than some of the building’s centerpiece spaces — from its Experiential Learning Lab to the XR Stage, VR track space, and Cybersecurity Lab.

The Experiential Learning Lab consists of both open project space and lockable storage for student projects and specialized equipment.

The XR Stage combines augmented reality, mixed reality, and virtual reality as an LED-based workflow creates a live, virtual, immersive environment that allows content to be generated in real time.

The Cybersecurity Lab is an experiential learning environment for students to safely experiment with simulated cybersecurity methods.

Giving students access to cutting-edge resources such as the XR Stage is an example of Miami’s rising reputation for education in digital arts, data science, and digital technology. Plans are already in place this semester for the Department of Music to work in the space for Opera and Laptop Ensemble projects, said Michael Bailey-Van Kuren, chair of the Department of Emerging Technology in Business + Design.

“Our primary mission is to drive student engagement and student learning,” Bailey-Van Kuren said. “Being in Emerging Technology, we don’t always know how things are going to be used. We try to provide state-of-the-art equipment, and students might find ways to utilize it in a manner we’ve never thought of.

“No matter what we do and what the technology is, why we’re here and why we’re at Miami is the chance to work with students and see how they impact the world when they leave here.”

Fixtures like the XR Stage are signature spaces that “put us a step ahead,” said John “Skip” Benamati, chair of the Department of Information Systems and Analytics (ISA).

Benamati was part of the committee that worked with architects to design the building. With ISA continuing to grow as a department, space was at a premium. McVey Data Science is helping to relieve some of those issues.

One aspect of McVey that caught Benamati’s attention was the usage of light. An abundance of windows and glass doors lets natural light fill the building’s interior.

“It is an interesting, well-thought-out design,” Benamati said.

“I’m excited to see where this takes us. It will be fun to watch and be part of.”"
https://www.whatech.com/og/markets-research/industrial/810558-data-science-platform-market-analysis-with-cagr-of-27-7-as-revealed-in-new-report,Data Science Platform Market Analysis with CAGR of 27.7% As Revealed In New Report,"""The Data Science Platform market is witnessing rapid expansion, projected to grow at a compound annual growth rate (CAGR) of 27.7% by 2030. This growth is fueled by the increasing volume and complexity of data generated by organizations, the rise of artificial intelligence and machine learning technologies, and the growing demand for end-to-end data science solutions to extract insights and drive business innovation.

Data Science Platforms are comprehensive software environments that enable organizations to perform data analysis, build machine learning models, and deploy data-driven applications at scale. These platforms provide tools and capabilities for data ingestion, preparation, modeling, visualization, and collaboration, empowering data scientists and analysts to derive actionable insights from data.

The defection of Data Science Platforms lies in their ability to empower organizations to democratize data science, accelerate time-to-insight, and operationalize machine learning models. By leveraging data science platforms, organizations can break down data silos, foster collaboration between data science teams and business stakeholders, and drive innovation across the enterprise.

Despite the rapid expansion, challenges such as talent shortage, data quality issues, and model interpretability concerns remain pertinent in the Data Science Platform market. However, advancements in automated machine learning, augmented analytics, and model explainability techniques are driving innovation and enabling organizations to overcome these challenges effectively.

As organizations increasingly recognize the strategic importance of data science in gaining competitive advantage and driving business growth, the Data Science Platform market is poised for sustained growth. Thus, offering opportunities for data science platform vendors and service providers to deliver innovative solutions that address evolving data science needs and deliver measurable business value.''

[New York, April 2024] A comprehensive market analysis report on the Data Science Platform Market has been unveiled by Stats N Data, offering valuable insights and intelligence for both industry veterans and newcomers. This in-depth report not only provides revenue forecasts for the Data Science Platform market and its subsegments but also equips stakeholders with a deep understanding of the competitive landscape.

It empowers businesses to craft effective go-to-market strategies and positions them for success in the ever-evolving marketplace.

You can access a sample PDF report here: www.statsndata.org/downloa…hp?id=8388

Some of the major companies influencing this Data Science Platform market include:

• Domino Data LabInc.

• KNIME AG

• Dataiku

• AnacondaInc

• TIBCO Software India Pvt. Ltd

• AlteryxInc.

• ClouderaInc.

• Microsoft Corporation

• GoogleInc.

• BRIDGEi2i Analytics Solutions Pvt. Ltd

• Wolfram Research

• SAS InstituteInc.

• IBM Corporation

• H2O.ai

• Teradata Corporation

• RapidMinerInc.

• WNSGlobalServices Pvt. Ltd.

Moreover, this report keeps a finger on the pulse of the market, providing valuable insights into the key drivers, challenges, and opportunities in the industry.

The report delves into essential questions that industry players and investors are eager to address:

Which market segments will thrive in developed and emerging markets over the next 5 to 10 years?

How do regulatory policies impact the Data Science Platform industry?

Which types/application segments will witness significant adoption in the coming decade in Data Science Platform?

What innovative products are peer companies developing in the Data Science Platform sector through R&D activities?

How do different players, both big and small, strategize their channels in the Data Science Platform markets?

The regional scope of the Data Science Platform market is mostly mentioned in the region-focused report.

• North America

• South America

• Asia Pacific

• Middle East and Africa

• Europe

Get Access of Full Report: www.statsndata.org/checkou…hp?id=8388

Market Segmentation Analysis

The Data Science Platform market is segmented on the basis of type, product, end user, etc. Segmentation helps provide an accurate description of the market.

Market Segmentation: By Type

• BFSI

• Retail

• Healthcare

• IT

• Transportation

• Energy and Utilities

• Government and Defense

Market Segmentation: By Application

• On-Premises

• On-Demand

Key Features of the Report:

Competitive Analysis: Gain a comprehensive understanding of the evolving competitive landscape to adapt and strategize effectively.

Forward-Looking Perspective: Explore what's driving or hindering market growth with a forward-looking view.

Product Segmentation: Identify significant product segments and their growth prospects to align your strategies with market trends.

Informed Decision-Making: Deepen your understanding of the market and its segments to make well-informed business decisions.

Customization Requests: www.statsndata.org/request…hp?id=8388

'Related Reports

Gaming Peripheral Market Research Report 2024

Stats N Data’s newly published report Gaming Peripheral Market provides Detailed information about new product releases, untapped geographies, current events, and investments In the Gaming Peripheral market.

Now get a sample of this report at: www.statsndata.org/downloa…?id=202697

The information covered in these studies includes Gaming Peripheral market size, segmentation data, marketing growth strategies, Gaming Peripheral market share, Gaming Peripheral market export and import information, Gaming Peripheral market analysis and forecast and trends, competition, domestic production, statistical data and business practices, end-user analysis, contact points, and more.

Indoor LBS Market Research Report 2024

Stats N Data’s newly published report Indoor LBS Market provides Detailed information about new product releases, untapped geographies, current events, and investments In the Indoor LBS market.

Now get a sample of this report at: www.statsndata.org/downloa…?id=180396

The information covered in these studies includes Indoor LBS market size, segmentation data, marketing growth strategies, Indoor LBS market share, Indoor LBS market export and import information, Indoor LBS market analysis and forecast and trends, competition, domestic production, statistical data and business practices, end-user analysis, contact points, and more.

Online Ticket Reservation System Market Research Report 2024

Stats N Data’s newly published report Online Ticket Reservation System Market provides Detailed information about new product releases, untapped geographies, current events, and investments In the Online Ticket Reservation System market.

Now get a sample of this report at: www.statsndata.org/downloa…?id=173062

The information covered in these studies includes Online Ticket Reservation System market size, segmentation data, marketing growth strategies, Online Ticket Reservation System market share, Online Ticket Reservation System market export and import information, Online Ticket Reservation System market analysis and forecast and trends, competition, domestic production, statistical data and business practices, end-user analysis, contact points, and more.

DDoS Protection Tool Market Research Report 2024

Stats N Data’s newly published report DDoS Protection Tool Market provides Detailed information about new product releases, untapped geographies, current events, and investments In the DDoS Protection Tool market.

Now get a sample of this report at: www.statsndata.org/downloa…?id=172950

The information covered in these studies includes DDoS Protection Tool market size, segmentation data, marketing growth strategies, DDoS Protection Tool market share, DDoS Protection Tool market export and import information, DDoS Protection Tool market analysis and forecast and trends, competition, domestic production, statistical data and business practices, end-user analysis, contact points, and more.

B2B Telecommunication Market Research Report 2024"
https://www.simplilearn.com/power-bi-interview-questions-and-answers-article,60 Power BI Interview Questions and Expert Answers for 2024,"Back in 2011, the rise of Business Intelligence tools posed a challenge to Microsoft to build its own business intelligence tool. Microsoft introduced the Power BI to deliver compelling analytical capabilities to existing Microsoft Excel and upgrade it to be intelligent enough to generate interactive reports.

According to Gartner's Magic Quadrant, Microsoft Power BI is one of today’s top business intelligence tools, chiefly because most IT firms rely on Power BI for their business analytics. As a result, the current IT industry finds a massive demand for Power BI Experts.

This tutorial is solely dedicated to helping aspiring Power BI professionals grasp the essential fundamentals of Power BI and crack the interviews in real-time. The tutorial is organized based on three categories, outlined below.

Power BI Interview Questions - Beginner Level

Power BI Interview Questions - Intermediate Level

Power BI Interview Questions - Advanced Level

Most Asked Power BI Interview Questions

What is Power BI?

Difference between Power BI and Tableau

Difference between Power Query and Power Pivot

What is Power BI Desktop

What is Power Pivot?

What is Power Query?

What is DAX?

What are Filters in Power BI?

What are Custom Visuals in Power BI?

What is GetData in Power BI?

We have five dozen questions for you, so let’s begin by going through some refresher-level or frequently asked beginner-level Power BI interview questions.

Become a Business and Leadership Professional

Top 10 skills in demandBusiness Analysis As A Skill In 2020

14% Growth in JobsOf Business Analysis Profile By 2028

Business Analyst

Industry-recognized certifications from IBM and Simplilearn

Masterclasses from IBM experts

Post Graduate Program in Business Analysis

Certificate from Simplilearn in collaboration with Purdue University

Become eligible to be part of the Purdue University Alumni Association

prevNext

Here's what learners are saying regarding our programs:

Sauvik Pal

Assistant Consultant at Tata Consultancy Services , Tata Consultancy Services

My experience with Simplilearn has been great till now. They have good materials to start with, and a wide range of courses. I have signed up for two courses with Simplilearn over the past 6 months, Data Scientist and Agile and Scrum. My experience with both is good. One unique feature I liked about Simplilearn is that they give pre-requisites that you should complete, before a live class, so that you go there fully prepared. Secondly, there support staff is superb. I believe there are two teams, to cater to the Indian and US time zones. Simplilearn gives you the most methodical and easy way to up-skill yourself. Also, when you compare the data analytics courses across the market that offer web-based tutorials, Simplilearn, scores over the rest in my opinion. Great job, Simplilearn!

Vy Tran

I was keenly looking for a change in my domain from business consultancy to IT(Business Analytics). This Post Graduate Program in Business Analysis course helped me achieve the same. I am proficient in business analysis now and am looking for job profiles that suit my skill set.

prevNext

Not sure what you’re looking for?View all Related Programs

Power BI Interview Questions For Freshers

1. What is Power BI?

Power BI is a business analytics tool developed by Microsoft that helps you turn multiple unrelated data sources into valuable and interactive insights. These data may be in the form of an Excel spreadsheet or cloud-based/on-premises hybrid data warehouses. You can easily connect to all your data sources and share the insights with anyone.

2. Why should we use Power BI?

Because Power BI provides an easy way for anyone, including non-technical people, to connect, change, and visualize their raw business data from many different sources and turn it into valuable data that makes it easy to make smart business decisions.

3. Difference between Power BI and Tableau

Both Tableau and Power BI are the current IT industry's data analytics and visualization giants. Yet, there are a few significant differences between them. You will now explore the important differences between Tableau and Power BI.

4. Difference between Power Query and Power Pivot

The differences between Power Query and Power Pivot are explained as follows:

Become a Business and Leadership Professional

Top 10 skills in demandBusiness Analysis As A Skill In 2020

14% Growth in JobsOf Business Analysis Profile By 2028

Business Analyst

Industry-recognized certifications from IBM and Simplilearn

Masterclasses from IBM experts

Post Graduate Program in Business Analysis

Certificate from Simplilearn in collaboration with Purdue University

Become eligible to be part of the Purdue University Alumni Association

prevNext

Here's what learners are saying regarding our programs:

Sauvik Pal

Assistant Consultant at Tata Consultancy Services , Tata Consultancy Services

My experience with Simplilearn has been great till now. They have good materials to start with, and a wide range of courses. I have signed up for two courses with Simplilearn over the past 6 months, Data Scientist and Agile and Scrum. My experience with both is good. One unique feature I liked about Simplilearn is that they give pre-requisites that you should complete, before a live class, so that you go there fully prepared. Secondly, there support staff is superb. I believe there are two teams, to cater to the Indian and US time zones. Simplilearn gives you the most methodical and easy way to up-skill yourself. Also, when you compare the data analytics courses across the market that offer web-based tutorials, Simplilearn, scores over the rest in my opinion. Great job, Simplilearn!

Vy Tran

I was keenly looking for a change in my domain from business consultancy to IT(Business Analytics). This Post Graduate Program in Business Analysis course helped me achieve the same. I am proficient in business analysis now and am looking for job profiles that suit my skill set.

prevNext

Not sure what you’re looking for?View all Related Programs

5. What is Power BI Desktop

Power BI Desktop is an open-source application designed and developed by Microsoft. Power BI Desktop will allow users to connect to, transform, and visualize your data with ease. Power BI Desktop lets users build visuals and collections of visuals that can be shared as reports with your colleagues or your clients in your organization.

6. What is Power Pivot?

Power Pivot is an add-on provided by Microsoft for Excel since 2010. Power Pivot was designed to extend the analytical capabilities and services of Microsoft Excel.

7. What is Power Query?

Power Query is a business intelligence tool designed by Microsoft for Excel. Power Query allows you to import data from various data sources and will enable you to clean, transform and reshape your data as per the requirements. Power Query allows you to write your query once and then run it with a simple refresh.

8. Describe the components of Microsoft’s self-service BI solution.

Self-service business intelligence (SSBI) is divided into the Excel BI Toolkit and Power BI.

9. What is self-service BI, anyway?

SSBI is an abbreviation for Self-Service Business Intelligence and is a breakthrough in business intelligence. SSBI has enabled many business professionals with no technical or coding background to use Power BI and generate reports and draw predictions successfully. Even non-technical users can create these dashboards to help their business make more informed decisions.

10. What is DAX?

DAX stands for Data Analysis Expressions. It's a collection of functions, operators, and constants used in formulas to calculate and return values. In other words, it helps you create new info from data you already have.

11. What are Filters in Power BI?

The term ""Filter"" is self-explanatory. Filters are mathematical and logical conditions applied to data to filter out essential information in rows and columns. The following are the variety of filters available in Power BI:

Manual filters

Auto filters

Include/Exclude filters

Drill-down filters

Cross Drill filters

Drillthrough filters

Drillthrough filters

URL filters–transient

Pass-Through filters

12. What are Custom Visuals in Power BI?

Custom Visuals are like any other visualizations, generated using Power BI. The only difference is that it developes the custom visuals using a custom SDK. The languages like JQuery and JavaScript are used to create custom visuals in Power BI.

13. What is GetData in Power BI?

Get Data is a simple icon on Power BI used to import data from the source.

14. Mention some advantages of Power BI.

Some of the advantages of using Power BI:

It helps build an interactable data visualization in data centers

It allows users to transform data into visuals and share them with anyone

It establishes a connection for Excel queries and dashboards for fast analysis

It provides quick and accurate solutions

It enables users to perform queries on reports using simple English words

Become a Business and Leadership Professional

Top 10 skills in demandBusiness Analysis As A Skill In 2020

14% Growth in JobsOf Business Analysis Profile By 2028

Business Analyst

Industry-recognized certifications from IBM and Simplilearn

Masterclasses from IBM experts

Post Graduate Program in Business Analysis

Certificate from Simplilearn in collaboration with Purdue University

Become eligible to be part of the Purdue University Alumni Association

prevNext

Here's what learners are saying regarding our programs:

Sauvik Pal

Assistant Consultant at Tata Consultancy Services , Tata Consultancy Services

My experience with Simplilearn has been great till now. They have good materials to start with, and a wide range of courses. I have signed up for two courses with Simplilearn over the past 6 months, Data Scientist and Agile and Scrum. My experience with both is good. One unique feature I liked about Simplilearn is that they give pre-requisites that you should complete, before a live class, so that you go there fully prepared. Secondly, there support staff is superb. I believe there are two teams, to cater to the Indian and US time zones. Simplilearn gives you the most methodical and easy way to up-skill yourself. Also, when you compare the data analytics courses across the market that offer web-based tutorials, Simplilearn, scores over the rest in my opinion. Great job, Simplilearn!

Vy Tran

I was keenly looking for a change in my domain from business consultancy to IT(Business Analytics). This Post Graduate Program in Business Analysis course helped me achieve the same. I am proficient in business analysis now and am looking for job profiles that suit my skill set.

prevNext

Not sure what you’re looking for?View all Related Programs

15. List out some drawbacks/limitations of using Power BI.

Here are some limitations to using Power BI:

Power BI does not accept file sizes larger than 1 GB and doesn't mix imported data accessed from real-time connections.

There are very few data sources that allow real-time connections to Power BI reports and dashboards.

It only shares dashboards and reports with users logged in with the same email address.

Dashboard doesn't accept or pass user, account, or other entity parameters.

16. What are some differences in data modeling between Power BI Desktop and Power Pivot for Excel?

Power Pivot for Excel supports only single directional relationships (one to many), calculated columns, and one import mode. Power BI Desktop supports bi-directional cross-filtering connections, security, calculated tables, and multiple import options.

17. Name the different connectivity modes available in Power BI?

There are three main connectivity modes used in Power BI.

SQL Server Import

An SQL Server Import is the default and most common connectivity type used in Power BI. It allows you to use the full capabilities of the Power BI Desktop.

Direct Query

The Direct Query connection type is only available when you connect to specific data sources. In this connectivity type, Power BI will only store the metadata of the underlying data and not the actual data.

Live Connection

With this connectivity type, it does not store data in the Power BI model. All interaction with a report using a Live Connection will directly query the existing Analysis Services model. There are only 3 data sources that support the live connection method - SQL Server Analysis Services (Tabular models and Multidimensional Cubes), Azure Analysis Services (Tabular Models), and Power BI Datasets hosted in the Power BI Service.

18. What are the various types of refresh options provided in Power BI?

Four important types of refresh options provided in Microsoft Power BI are as follows:

Package refresh - This synchronizes your Power BI Desktop or Excel file between the Power BI service and OneDrive, or SharePoint Online.

Model or data refresh - This refreshes the dataset within the Power BI service with data from the original data source.

Tile refresh - This updates the cache for tile visuals every 15 minutes on the dashboard once data changes.

Visual container refresh - This refreshes the visible container and updates the cached report visuals within a report once the data changes.

19. Name the data sources can Power BI can connect to?

Several data sources can be connected to Power BI, which is grouped into three main types:

Files

It can import data from Excel (.xlsx, .xlxm), Power BI Desktop files (.pbix) and Comma-Separated Values (.csv).

Content Packs

These are a collection of related documents or files stored as a group. There are two types of content packs in Power BI:

Content packs from services providers like Google Analytics, Marketo, or Salesforce and Content packs are created and shared by other users in your organization.

Connectors

Connectors help you connect your databases and datasets with apps, services, and data in the cloud.

20. What is a dashboard in Power BI?

A dashboard is a single-layer presentation sheet of multiple visualizations reports. The main features of the Power BI dashboard are:

It allows you to drill through the page, bookmarks, and selection pane and also lets you create various tiles and integrate URLs

A dashboard can also help you set report layout to mobile view.

21. Explain how relationships are defined in Power BI Desktop?

Relationships between tables are defined in two ways:

Manually - Relationships between tables are manually defined using primary and foreign keys.

Automatic - When enabled, this automated feature of Power BI detects relationships between tables and creates them automatically.

22. Can you have more than one functional relationship between two tables in a Power Pivot data model?

No. There can be multiple inactive relationships, but only one active relationship between two tables in a Power Pivot data model. Dotted lines represent inactive relationships, and continuous lines represent active relationships.

23. Can you have a table in the model which does not have any relationship with other tables?

Yes. There are two main reasons why you can have disconnected tables:

The table is used to present the user with parameter values to be exposed and selected in slicers

It uses the table as a placeholder for metrics in the user interface

24. What is the CALCULATE function in DAX?

The CALCULATE function evaluates the sum of the Sales table Sales Amount column in a modified filter context. It is also the only function that allows users to modify the filter context of measures or tables.

Moving ahead, you will step up to the following Power BI Interview Questions from the Intermediate Level.

Power BI Interview Questions For Intermediate Level

25. Where is data stored in Power BI?

Most of the time, power BI gets assisted by the cloud to store the data. Power BI can use a desktop service. Microsoft Azure is used as the primary cloud service to store the data.

Azure SQL Database

Azure Blob Storage

26. What is row-level security?

Row-level security limits the data a user can view and has access to, and it relies on filters. Users can define the rules and roles in Power BI Desktop and also publish them to Power BI Service to configure row-level security.

27. Why should you apply general formatting to Power BI data?

Users can use general formatting to make it easier for Power BI to categorize and identify data, making it considerably easier to work with.

28. What are the different views available in Power BI Desktop?

There are three different views in Power BI, each of which serves another purpose:

Report View - In this view, users can add visualizations and additional report pages and publish the same on the portal.

Data View - In this view, data shaping can be performed using Query Editor tools.

Model View - In this view, users can manage relationships between complex datasets.

Become a Business and Leadership Professional

Top 10 skills in demandBusiness Analysis As A Skill In 2020

14% Growth in JobsOf Business Analysis Profile By 2028

Business Analyst

Industry-recognized certifications from IBM and Simplilearn

Masterclasses from IBM experts

Post Graduate Program in Business Analysis

Certificate from Simplilearn in collaboration with Purdue University

Become eligible to be part of the Purdue University Alumni Association

prevNext

Here's what learners are saying regarding our programs:

Sauvik Pal

Assistant Consultant at Tata Consultancy Services , Tata Consultancy Services

My experience with Simplilearn has been great till now. They have good materials to start with, and a wide range of courses. I have signed up for two courses with Simplilearn over the past 6 months, Data Scientist and Agile and Scrum. My experience with both is good. One unique feature I liked about Simplilearn is that they give pre-requisites that you should complete, before a live class, so that you go there fully prepared. Secondly, there support staff is superb. I believe there are two teams, to cater to the Indian and US time zones. Simplilearn gives you the most methodical and easy way to up-skill yourself. Also, when you compare the data analytics courses across the market that offer web-based tutorials, Simplilearn, scores over the rest in my opinion. Great job, Simplilearn!

Vy Tran

I was keenly looking for a change in my domain from business consultancy to IT(Business Analytics). This Post Graduate Program in Business Analysis course helped me achieve the same. I am proficient in business analysis now and am looking for job profiles that suit my skill set.

prevNext

Not sure what you’re looking for?View all Related Programs

29. What are the various versions of Power BI?

Power BI Desktop

Power BI service

Mobile Power BI apps for iOS and Android devices

30. Explain the building blocks of Microsoft Power BI.

The important building blocks of Power BI are as follows:

Visualizations

Visualization is the process of generating charts and graphs for the representation of insights on business data.

Datasets

A dataset is the collection of data used to create a visualization, such as a column of sales figures. Dataset can get combined and filtered from a variety of sources via built-in data plugins.

Reports

The final stage is the report stage. Here, there is a group of visualizations on one or more pages. For example, charts and maps are combined to make a final report.

Dashboards

A Power BI dashboard helps you to share a single visualization with colleagues and clients to view your final dashboard.

Tiles

A tile is an individual visualization on your final dashboard or one of your charts in your final report.

31. What are the critical components of the Power BI toolkit?

The critical components of Power BI are mentioned below.

Power Query

Power Pivot

Power View

Power Map

Power Q&A

32. What do you mean by the content pack?

A content pack is defined as a ready-made collection of visualizations and Power BI reports using your chosen service. You'd use a content pack when you want to get up and running quickly instead of creating a report from scratch.

33. Define bi-directional cross filtering.

Bidirectional cross-filtering lets data modelers to decide how they want their Power BI Desktop filters to flow for data, using the relationships between tables. The filter context is transmitted to a second related table that exists on the other side of any given table relationship. This procedure helps data modelers solve the many-to-many issue without having to complicated DAX formulas. So, to sum it up, bidirectional cross-filtering makes the job for data modelers easier.

34. What are the three fundamental concepts of DAX?

Syntax

This is how the formula is written—that is, the elements that comprise it. The Syntax includes functions such as SUM (used when you want to add figures). If the Syntax isn't correct, you'll get an error message.

Functions

These are formulas that use specific values (also known as arguments) in a particular order to perform a calculation, similar to the functions in Excel. The categories of functions are date/time, time intelligence, information, logical, mathematical, statistical, text, parent/child, and others.

Context

There are two types: row context and filter context. Row context comes into play whenever a formula has a function that applies filters to identify a single row in a table. When one or more filters are applied in a calculation that determines a result or value, the filter context comes into play.

35. Why and how would you use a custom visual file?

You will use a custom visual file if the prepackaged files don't fit the needs of your business. Developers create custom visual files, and you can import them and use them in the same way as you would the prepackaged files.

36. What are some familiar sources for data in the Get Data menu in Power BI?

A few familiar data sources are Excel, Power BI datasets, web, text, SQL server, and analysis services.

37. What are the categories of data types?

All

File

Database

Power BI

Azure

Online Services

Other

38. Name some commonly used tasks in the Query Editor.

Connect to data

Shape and combine data

Group rows

Pivot columns

Create custom columns

Query formulas

39. What do you mean by grouping?

Power BI Desktop helps you to group the data in your visuals into chunks. You can, however, define your groups and bins. For grouping, use Ctrl + click to select multiple elements in the visual. Right-click one of those elements and, from the menu that appears, choose Group. In the Groups window, you can create new groups or modify existing ones.

40. Explain responsive slicers in Power BI.

On a Power BI final report page, a developer can resize a responsive slicer to various sizes and shapes, and the data collected in the container will be rearranged to find a match. If a visual report becomes too small to be useful, an icon representing the visual takes its place, saving space on the report page.

41. What is query folding in Power BI?

Query folding is used when steps defined in the Query Editor are translated into SQL and executed by the source database instead of your device. It helps with scalability and efficient processing.

42. What is ""M language.""

M is a programming language used in Power Query as a functional, case-sensitive language similar to other programming languages and easy to use.

Power BI Interview Questions For Experienced

43. What are the major differences between visual-level, page-level, and report-level filters in Power BI?

Visual-level filters are used to filter data within a single visualization. Page-level filters are used to work on an entire page in a report, and different pages can have various filters.

Report-level filters are used to filter all the visualizations and pages in the report.

44. List the most common techniques for data shaping.

Adding indexes

Applying a sort order

Removing columns and rows

45. How is the Schedule Refresh feature designed to work?

Users can set up for an automatic refresh over data based on daily or weekly requirements. Users can schedule only one refresh maximum daily unless they have Power BI Pro. The Schedule Refresh section uses the pull-down menu choices to select a frequency, time zone, and time of day.

46. What information is needed to create a map in Power Map?

Power Map can display geographical visualizations. Therefore, some location data is needed—for example, city, state, country, or latitude and longitude.

47. Which in-memory analytics engine does Power Pivot use?

Power Pivot uses the xVelocity engine. xVelocity can handle huge amounts of data, storing data in columnar databases. All data gets loaded into RAM memory when you use in-memory analytics, which boosts the processing speed.

48. Mention important components of SSAS

Following are some of the important Components of SSAS:

OLP Engine

An OLAP Engine is used to extensively run the ADHOC queries at a faster pace by the end-users

Data Drilling

It describes data Drilling in SSAS as the process of exploring details of the data with multiple levels of granularity.

Slicers

The data Slicing process in SSAS is defined as the process of storing the data in rows and columns.

Pivot Tables

Pivot Tables helps in switching between the different categories of data stored between rows and columns

49. What are the three fundamental concepts of DAX?

Syntax: This is how the formula is written—the elements that comprise it. The syntax includes functions such as SUM (used when you want to add figures). If the syntax isn't correct, you'll get an error message.

Functions: These are formulas that use specific values (also known as arguments) in a certain order to perform a calculation, similar to the functions in Excel. The categories of functions are date/time, time intelligence, information, logical, mathematical, statistical, text, parent/child, and others.

Context: There are two types: row context and filter context. Row context comes into play whenever a formula has a function that applies filters to identify a single row in a table. When one or more filters are applied in a calculation that determines a result or value, the filter context comes into play.

50. Name the variety of Power BI Formats.

Power BI is available mainly in three formats, as mentioned below.

Power BI Desktop: Open-Source version for Desktop users

Power BI Services: For Online Services

Power BI Mobile Application: Compatible with mobile devices

51. What are the different stages in the working of Power BI?

There are three different stages in working on Power BI, as explained below.

Data Integration

Data Processing

Data Presentation

Data Integration

The primary step in any business intelligence is to establish a successful connection with the data source and integrate it to extract data for processing.

Data Processing

The next step in business intelligence is data processing. Most of the time, the raw data also includes unexpected erroneous data, or sometimes a few data cells might be empty. The BI tool needs to interpret the missing values and inaccurate data for processing in the data processing stage.

Data Presentation

The final stage in business intelligence is analyzing the data got from the source and presenting the insights using visually appealing graphs and interactive dashboards.

52. Which professionals use Power BI the most?

Beginners and experts prefer Power BI in business intelligence. Power BI is used mainly by the following professionals.

Business Analysts

Business Owners

Business Developers

Business Analysts

A business analyst is a professional who analyses the business data and represents the insights found using visually appealing graphs and dashboards

Business Owners

Business owners, decision-makers, or organizations use Power BI to view the insights and understand the prediction to make a business decision.

Business Developers

Business Developers are just software developers who get hired for business purposes to develop custom applications and dashboards to help the business process be smooth.

53. What is the advanced editor?

Advanced editor is used to view queries that Power BI is running against the data sources importing data. The query is rendered in M-code. Users wanting to view the query code select “Edit Queries” from the Home tab, then click on “Advanced Editor” to perform work on the query. Any changes get saved to Applied Steps in the Query Settings.

Become a Business and Leadership Professional

Top 10 skills in demandBusiness Analysis As A Skill In 2020

14% Growth in JobsOf Business Analysis Profile By 2028

Business Analyst

Industry-recognized certifications from IBM and Simplilearn

Masterclasses from IBM experts

Post Graduate Program in Business Analysis

Certificate from Simplilearn in collaboration with Purdue University

Become eligible to be part of the Purdue University Alumni Association

prevNext

Here's what learners are saying regarding our programs:

Sauvik Pal

Assistant Consultant at Tata Consultancy Services , Tata Consultancy Services

My experience with Simplilearn has been great till now. They have good materials to start with, and a wide range of courses. I have signed up for two courses with Simplilearn over the past 6 months, Data Scientist and Agile and Scrum. My experience with both is good. One unique feature I liked about Simplilearn is that they give pre-requisites that you should complete, before a live class, so that you go there fully prepared. Secondly, there support staff is superb. I believe there are two teams, to cater to the Indian and US time zones. Simplilearn gives you the most methodical and easy way to up-skill yourself. Also, when you compare the data analytics courses across the market that offer web-based tutorials, Simplilearn, scores over the rest in my opinion. Great job, Simplilearn!

Vy Tran

I was keenly looking for a change in my domain from business consultancy to IT(Business Analytics). This Post Graduate Program in Business Analysis course helped me achieve the same. I am proficient in business analysis now and am looking for job profiles that suit my skill set.

prevNext

Not sure what you’re looking for?View all Related Programs

54. What gateways does Power BI have and why should you use them?

Gateways function as bridges between the in-house data sources and Azure Cloud Services.

Personal Gateway: Used only by one person, data can be imported, and is only valid on Power BI Service.

On-Premises Gateway: This is an advanced form of the Personal Gateway, supporting Direct Query and usable by multiple users to refresh data.

55. Mention some applications of Power BI

There are multiple applications of Power BI; some of them are as follows:

Business Analysis

Data Analysis

Database Administration

IT Professional

Data Science

56. How can you depict a story in Power BI?

Every individual chart or visualization report generated is collected and represented on a single screen. Such an approach is called a Power BI Dashboard. A Dashboard in Power BI is used to depict a story.

57. What are KPIs in Power BI?

KPI is abbreviated as Key Performance Indicator. Any professional organization has teams and employees follow the KPI protocols. The organizations set up KPIs for all the employees. These KPIs act as their targets. These KPIs are compared to previous performance and analyze the progress.

58. What is a Slicer?

Slicers are an integral part of a business report generated using Power BI. The functionality of a slicer can be considered similar to that of a filter, but, unlike a filter, a Slicer can display a visual representation of all values and users will be provided with the option to select from the available values in the slicer’s drop-down menu.

59. Explain Power BI Designer.

It is a combined solution offered to upload the reports and dashboards to the PowerBI.com website for reference. It consists of Power Pivot, Power Query, and Power Table.

60. How do you reshape data in Power BI?

Power BI offers a wide variety of data source connectivity options. Data Editor is one of the tools used to manipulate rows and columns of data and helps you reshape it according to the requirements.

With that, you have come to an end to this tutorial on “Top 60 Power BI Interview Questions and Answers for 2024”.

Wrapping Up

Power BI Architecture and Features can be your next vital step in learning data analytics.

Are you interested in learning more about Business Analytics? Or do you wish to get trained and certified to become a successful Business Analyst? Then feel free to explore the Business Analytics certification course from Simplilearn. Ranked among the five topmost business analytics courses, this Simplilearn program is offered in partnership with Purdue University. This course is an outcome-driven training and certification program that helps you master the fundamental concepts of statistics and data analytics.

Do you have any questions for us on this tutorial on ""Top 60 Power BI Interview Questions and Answers for 2024”? If you do, or you have questions about our certification courses, do reach out to us by sharing them as comments below. Our team of experts will address them and will be happy to answer them at the earliest."
https://www.streetinsider.com/PRNewswire/MindSculpt+Analytics+engages+Happiest+Minds+to+build+advanced+AI+Medical+Preventive+%26amp%3B+Diagnostic+solutions/23065129.html,MindSculpt Analytics engages Happiest Minds to build advanced AI Medical Preventive & Diagnostic solutions,"BENGALURU, India, April 15, 2024 /PRNewswire/ -- Happiest Minds Technologies Limited (NSE: HAPPSTMNDS), a 'Born Digital. Born Agile', Mindful IT Company, today announced that it has been engaged by MindSculpt Analytics, a Healthcare Solutions Company, for reshaping the science of exploration of complex data to deliver tailored medical diagnostics solutions leveraging advanced Artificial Intelligence and Machine Learning techniques.

The significant advancements in engineering and data sciences, along with enhanced computational capabilities, have ushered in new possibilities beyond traditional medical science-based preventive and diagnostic approaches. Instead, there's a shift towards innovative technology-driven ""interceptive"" solutions. This project seeks to deliver precise mapping of individuals' physiology, facilitating a highly nuanced comprehension of health, wellness, and aging on an individual level.

Happiest Minds, with its technology, bioinformatics, and data science expertise, has been chosen by MindSculpt Analytics to build this preventive & diagnostics platform. The focus of the current engagement is to build a holistic health portrait of the individual and over time leverage this for an early and accurate diagnosis and personalized treatments of multiple ailments that include a range of age and neuro-related diseases. The health portrait will be equipped to track post-disease recovery also.

Dr. Paul Salins, Founder & CEO, MindSculpt Analytics, said, ""MindSculpt Analytics spearheads the creation of innovative approaches to analyzing complex data, harnessing the full potential of cutting-edge technology and advanced computational tools across various fields. As we move towards the future of healthcare, a departure from traditional disease-focused and physician-dependent medical strategies to predictive auto-diagnostics led by technology and focusing on the dynamics of personal wellness emerges. Our goal is to revolutionize the acquisition of individual-specific health data, tailored for the latest advancements in data science and computational resources, enabling early prediction and measurement of health indicators, disease progression, and treatment responses. We are thrilled to collaborate with Happiest Minds, renowned for its leading information technology and artificial intelligence technical capabilities and vast expertise in realizing groundbreaking multidisciplinary solutions, complementing our medical proficiency perfectly.""

Ashok Soota, Executive Chairman of Happiest Minds, said, ""We are delighted to have the opportunity to execute this highly significant project for MindSculpt Analytics. I am also pleased that the capabilities we are building in Happiest Minds, coupled with the expertise of SKAN Research Trust, is creating a unique position to provide innovative bioinformatics and hardware solutions for the market as forerunners in a space with enormous market potential in the domain of medical research.""

Sundar Ramaswamy, SVP and Head of Analytics CoE, Happiest Minds, said, ""Happiest Minds has partnered with clients on Artificial Intelligence and Machine Learning solutions to address their most challenging problems. Partnering with research trusts, healthcare providers and practitioners, we leverage our strong bioinformatics and data science capabilities to improve medical outcomes in early disease diagnosis & patient care. Our work with MindSculpt Analytics is to bring pioneering & path-breaking medical solutions with a novel data & AI-led approach. The end goal is to build a diagnostic platform that can be extended to provide accurate early detection & prevention of many ailments.""

About Happiest Minds Technologies

Happiest Minds Technologies Limited (NSE: HAPPSTMNDS), a Mindful IT Company, enables digital transformation for enterprises and technology providers by delivering seamless customer experiences, business efficiency and actionable insights. We do this by leveraging a spectrum of disruptive technologies such as: artificial intelligence, blockchain, cloud, digital process automation, internet of things, robotics/drones, security, virtual/ augmented reality, etc. Positioned as 'Born Digital. Born Agile', our capabilities span Product & Digital Engineering Services (PDES), Generative AI Business Services (GBS) and Infrastructure Management & Security Services (IMSS). We deliver these services across industry groups: Industrial, Manufacturing and Energy & Utilities, Healthcare & Life Sciences, Retail, CPG & Logistics, Banking, Financial Services and Insurance (BFSI), Hi-Tech and Media & Entertainment, and EdTech. The company has been recognized for its excellence in Corporate Governance practices by Golden Peacock and ICSI. A Great Place to Work Certified™ company, Happiest Minds is headquartered in Bangalore, India with operations in the U.S., UK, Canada, Australia, and the Middle East.

Media Contact: Kiran Veigas, [email protected]

About MindSculpt Analytics

MindSculpt Analytics, a company focused on building new generation analytical systems modeling varied & complex data. The company's objective is to design, develop, and implement analytics engines tailored for predictive medical diagnostics with a goal to improve the quality of healthcare in common medical ailments including Parkinson's, Alzheimer's, Strokes & other Cardiovascular ailments through early and accurate diagnosis and personalized treatments.

Logo - https://mma.prnewswire.com/media/1812236/4024169/Happiest_Minds_Logo.jpg

View original content:https://www.prnewswire.com/news-releases/mindsculpt-analytics-engages-happiest-minds-to-build-advanced-ai-medical-preventive--diagnostic-solutions-302116680.html

SOURCE Happiest Minds Technologies Limited"
https://miamioh.edu/news/2024/03/the-future-begins-now-for-data-science-at-miami-university.html,The future begins now for data science at Miami University,"Welcome to the future.

With those words, Miami University President Gregory Crawford set the stage — quite literally — for the dedication of the McVey Data Science building.

President Crawford delivered his remarks from the facility’s Extended Reality (XR) Stage, one of the groundbreaking features found in Miami’s cutting-edge building located along Tallawanda Road."
https://studentaffairs.virginia.edu/events/virtual-data-science-and-analytics-day,Virtual Data Science and Analytics Day,"Register now for Spring Virtual Data Science and Analytics Day. This evening event provides a unique opportunity for students to engage with organizations looking to hire for data science and analytics roles. Throughout this virtual event, you will have an opportunity to participate in one-on-one conversations and group sessions with employers and alumni. Spaces are first-come-first-served, so sign-up in advance."
https://www.insidehighered.com/news/tech-innovation/teaching-learning/2024/01/25/data-science-major-takes-across-college-campuses,Data science major takes off across college campuses,"The University of Connecticut always allowed flexibility in creating new, unique majors, but the immense student demand for one in particular—data science—came as a surprise.

“It was almost getting out of hand, in terms of interest from students,” said Elizabeth Schifano, UConn’s undergraduate program director for the Department of Statistics.

That interest is not unique to UConn. The National Center for Education Statistics reported a recent 968 percent jump in data science bachelor’s degrees awarded, from 84 in 2020 to 897 in 2022. The job market also shows increasing demand for data science skills, with the Department of Labor projecting 36 percent growth in jobs for data scientists over the next decade, outpacing statisticians, logisticians and research analysts.

Most Popular

“There are a lot of jobs—and very well-compensated jobs—but it also cuts across different industry sectors,” said Frederick Bonato, provost at Saint Peter’s University in New Jersey. “You could be a data scientist and specialize in higher ed, or transportation, or commerce. That’s attractive, because you can get the degree but also follow what you’re particularly interested in.”

As data science degree programs crop up at colleges and universities across the country, women in particular are pursuing data science in greater numbers compared to other computer-related and STEM fields.

Why Data Science?

While the definition of data science can vary, it generally falls under the statistics umbrella and includes a more interdisciplinary approach. For example, most of the UConn students in the individualized data science major also pursued biology or economics degrees.

Data science majors can go on to become software engineers, artificial intelligence engineers or data architects, but their roles reach beyond the tech industry. Nonprofits can use data to maximize fundraising, for example, and logistics companies could use data to avoid car accidents.

The University of California, Davis, launched its data science degree program in fall 2022. A year later, Maine-based Colby College, a small liberal arts institution, launched its program in fall 2023 after a number of students majored in statistics but had a heavy focus on data science.

“Data science is becoming more prominent, and we wanted to give students agency over what it says on their diploma and have it reflected in their degree,” said Jim Scott, Colby’s statistics department chair. Since the major launched last semester, eight students have signed up and two new faculty members have been hired.

A growing statistics program may not be an obvious fit for Colby, but Scott said it’s the college’s liberal arts focus that makes it a place where data science can thrive.

“Students want a liberal arts education and not just siloed in a discipline,” he said. “Data science allows students to follow their passion and also gives a useful skill to implement into whatever you’re doing. Data is everywhere; it touches all of us.”

That data pervasiveness touches Saint Peter’s University, which has been building its newly renamed Data Science Institute. Since beginning with one program in 2014, it has ballooned to eight programs spanning more than 1,000 students—an enrollment that has tripled since 2018.

Saint Peter’s added a bachelor’s degree and Ph.D. program in data science in 2022 after officials saw explosive growth.

“In my opinion, adding the programs was obvious,” Saint Peter’s Bonato said. “It wasn’t a hard sell at all [to add more], and it’s been steady growth.”

You could be a data scientist and specialize in higher ed, or transportation, or commerce. That’s attractive, because you can get the degree but also follow what you’re particularly interested in.”

—Frederick Bonato, provost at Saint Peter’s University

Like Colby and UConn, Saint Peter’s did not add the program to recruit new students but to keep up with student and employer demand.

“Right now, I think it’s the hot thing,” UConn’s Schifano said. “Having the right tools, knowing how to use them—it’s becoming more important in every aspect. Every discipline has data and wants to understand what it means.”

Women and Data Science

In addition to appealing to more students in general, data science, a recent study found, has a higher concentration of female students than comparable majors, such as computer science and cybersecurity.

For the last five years, the Association for Computing Machinery (ACM) has tracked the enrollment and retention of STEM-focused disciplines with the help of the National Student Clearinghouse Research Center. After anecdotally seeing the rise of data science interest, ACM spent two years looking at enrollment and retention for the major, spanning the 2021–22 and 2022–23 school years.

The interest among women is likely due, in part, to the field’s cross-disciplinary focus, allowing students to pursue their interests while having the safety net of an in-demand field, said Stuart Zweben, chair of the ACM task force on enrollment and retention.

“Students interested in analyzing data but also applying it to a passion of theirs might be interested in data science,” said Zweben, who co-authored the latest report. “They can have specializations in a variety of areas, and that’s more likely to attract a diverse group of students.”

There’s also spillover from the rising—and sometimes overwhelming—interest in computer science. Universities turning students away from computer science may push them into data science.

“Students see what the barriers are in computer science and find data science is even better for them, because it aligns with their interest and it’s easier to get into,” Zweben said.

There was a similar interest and growth in cybersecurity in previous years, Zweben said, although data science has already outpaced that. While he continues to expect growth in data science, there’s already a hot new area looming: artificial intelligence.

“Because of the heightened interest in AI and its strengths, weaknesses and fears, AI is of interest to a lot of people,” he said.

While Schifano agrees there is sure to be interest in AI, she expects data science majors to benefit by association.

“We’re creating more AI technology, but AI is very dangerous if you don’t know what you’re doing,” she said. “Coding might be easier with AI, but you still need the knowledge; some aspects of data science will be easier because of AI, but you still need to know the underlying principles.”"
https://elblog.pl/2024/04/18/egypts-university-of-informatics-hosts-premier-data-science-and-ai-conference/,Egypt’s University of Informatics Hosts Premier Data Science and AI Conference,"Egypt’s University of Informatics Takes the Spotlight in the Data and AI Arena

In a significant move to bolster the field of data science and artificial intelligence (AI) in the region, Egypt’s University of Informatics is proud to host the inaugural Data Science and AI Conference (DSC MENA 24) in the city of Knowledge at the New Administrative Capital. This conference is poised to be the region’s largest of its kind following its acclaim as Europe’s premier event in the domain of AI and data science.

The three-day event, spanning from April 18 to 20, will serve as a melting pot for AI and data specialists, offering high-level content and innovative business opportunities amidst a network of industry professionals. This is made possible through a strategic union between Egypt’s University of Informatics (EUI), Ntervento, and the Information Technology Industry Development Agency (ITIDA).

Forging Ahead: Data Science and AI Innovations

Tackling a spectrum of cutting-edge topics, the conference addresses generative AI, natural language processing, deep learning, data engineering, cloud data solutions, AI in medicine, and analytics in marketing. These subjects are indicative of the event’s ambition to stay at the forefront of technological advancement.

Dr. Reem Bahgat, President of the University of Informatics, emphasizes the unique platform that DSC MENA 24 offers. Academics and industry professionals alike are welcomed to share research outcomes, discuss AI applications, and ensure cybersecurity for new IT advancements.

The conference is seen as an enriching conduit to align academic Might with dynamic market needs, furthering the university’s stature as a leader in IT and communications in the Middle East and Africa. It symbolizes a concerted effort to provide a high-caliber, collaborative event for the MENA region and the global AI community, responding to the increasing demands for smart systems in business environments.

In taking this initiative, Egypt’s University of Informatics reinforces its dedication to being a pioneering academic hub in IT and digital arts, offering a plethora of specialized programs aimed at meeting the evolving needs of today’s workforce.

Most Important Questions and Answers:

Q1: What is the significance of the Data Science and AI Conference (DSC MENA 24) being held at Egypt’s University of Informatics?

A1: Hosting DSC MENA 24 at Egypt’s University of Informatics is significant because it reflects Egypt’s and the region’s growing investment in AI and data science. It further cements the university’s reputation as a regional leader in these fields and aims to bridge the gap between academia and industry.

Q2: What are the key challenges associated with data science and AI development in the MENA region?

A2: Key challenges include the need for skilled professionals, data privacy concerns, ethical considerations in AI deployment, and the alignment of AI applications with regional market needs. Overcoming technical and infrastructural barriers is also crucial for the advancement of these fields in the region.

Q3: What controversies surround the field of artificial intelligence?

A3: Controversies in AI often revolve around job displacement due to automation, surveillance and privacy issues, algorithmic biases, ethical use of AI, especially in critical sectors like healthcare, and the potential for AI-enabled weapons.

Advantages and Disadvantages:

Advantages:

– The conference promotes knowledge exchange and networking among experts, driving innovation.

– It encourages local investments in AI research and development, fostering economic growth.

– Industry professionals get to showcase new technologies and form partnerships.

– It offers educational benefits by aligning curricula with industry requirements.

Disadvantages:

– Misuse or misunderstanding of AI can lead to negative consequences for society.

– There may be economic costs involved in hosting a conference of this magnitude.

– The rapid pace of change in AI and data science can outstrip regulatory frameworks.

Related Links:

For those interested in further exploring the topics of AI and data science in the context of regional development, here are some useful links:

– Ntervento: Offering insights into one of the key organizers of the event.

– Information Technology Industry Development Agency (ITIDA): Providing information about governmental support for the IT industry in Egypt.

– Egypt’s University of Informatics (EUI): Showcasing the academic programs and initiatives of hosting university.

Please note that while these links pertain to EUI and its partners, connecting with their official websites will offer the most current details and resources related to the subject."
https://www.utsa.edu/today/2024/02/story/david-mongeau-steps-down-from-role.html,"David Mongeau to step down, interim director for country's only HSI data science school announced","FEBRUARY 28, 2024 — David Mongeau today announced plans to step down from his role as founding director of the School of Data Science, effective March 1. He has served in the position since 2021.

The School of Data Science is one of five data science schools in the United States and the only one of its kind at a U.S. Hispanic Serving Institution. The school was established in 2018 to educate top data scientists and lead the nation in data-intensive research. It officially opened in the 167,000-square-foot San Pedro I building in downtown San Antonio in January 2023.

“David Mongeau's leadership and ability to work across disciplines have been instrumental in firmly establishing UTSA's prominence in data science and setting a trajectory for future growth,” said Heather Shipley, UTSA interim provost and executive vice president for academic affairs. “Under David’s guidance, more than 1,000 students and researchers now are learning and collaborating at San Pedro I. I am grateful for his dedication and service and wish him continued success.”

A nationally recognized leader in the data science and artificial intelligence community, Mongeau brought to UTSA a distinguished record in leading research institutes and training programs, as well as in developing partnerships across government, industry, academia and the philanthropic community.

Under his leadership, the School of Data Science has recorded numerous achievements, including receiving $1.2 million in gift funding for data science, AI and machine learning student training and research programs. In addition to the undergraduate and graduate degree and certificate programs comprising the School of Data Science, school leaders now are developing a new certificate program in data engineering.

In partnership with the Association of Computing Machinery at UTSA and the National Security Agency, the School of Data Science in 2022 launched the annual Rowdy Datathon competition.

In April 2023, the school hosted the inaugural UTSA Draper Data Science Business Plan Competition, which highlights data science applications and student entrepreneurship; the second annual competition will be held at San Pedro I later this spring.

Also in 2023, the school hosted its inaugural Los Datos Conference. The school also now serves as administrative host to the university’s annual RowdyHacks competition; more than 500 students from across Texas participated in the 9th annual RowdyHacks at San Pedro I last weekend.

Mongeau has been driven to increase the reach and reputation of the School of Data Science from and back to San Antonio. In October 2023, the School of Data Science hosted the annual meeting of the Academic Data Science Alliance, bringing together more than 200 data science practitioners, researchers and educators from across the country to UTSA. The school also invested nearly $400,000 to create opportunities for UTSA students and faculty to pursue projects and participate in national data science and AI experiences at, for example, University of Chicago, University of Michigan, University of Washington, and the U.S. Census Bureau.

Through a collaboration with San Antonio-based start-up Skew the Script, the school has reached 20,000 high school teachers and 400,000 high school students with open-source training in statistics and math, which are core to success in data science and AI.

“I consider myself so fortunate to have been part of the creation of the School of Data Science at UTSA,” said Mongeau. “I thank the school’s dedicated staff and core faculty for their commitment to the school which is having an enduring impact on our students — the next generation of diverse data scientists — who have embraced the school’s vision to make our world more equitable, informed and secure. These Roadrunners are destined to become industry leaders and continue to advance the frontiers of data science and AI.”

Immediately prior to joining UTSA, Mongeau served as executive director of the Berkeley Institute for Data Science at the University of California, Berkeley. As executive director, he set the strategic direction for the institute, expanded industry and foundation engagement, and applied data science and AI in health care, climate change, and criminal justice.

Notably, he also initiated three data science fellowship programs and forged partnerships to enhance opportunities for legal immigrants and refugees in data science careers."
https://polsky.uchicago.edu/2024/03/21/transform-accelerator-announces-data-science-and-ai-startups-selected-for-cohort-3/,Transform Accelerator Announces Data Science and AI Startups Selected for Cohort 3,"The University of Chicago’s Polsky Center for Entrepreneurship and Innovation and Data Science Institute today announced the seven early-stage companies accepted into the third cohort of the Transform accelerator for data science and AI startups.

Powered by the Polsky Center’s Deep Tech Ventures, Transform provides full-spectrum support for the startups accepted into the accelerator, including access to business and technical training, industry mentorship, venture capital connections, and funding opportunities.

The seven startups will receive approximately $250,000 in total investment, including $25,000 in funding, credits for Google for Startups, workspace in the Polsky Exchange on Chicago’s South Side, and access to industry mentors, technical advisors and student talent from the University of Chicago Department of Computer Science, Data Science Institute (DSI), and the Chicago Booth School of Business.

Transform Cohort 3:

Autonoma: Making Modernizing Legacy Code Easy

Bettor Vision: Bringing All Your Fantasy Sports Betting Into One App

Complete Wellness Solutions: A Holistic, Data-Driven Approach to Population Health Management

Healee: Applying AI to Improve the Consumer Experience in Healthcare

iTrials: A User-Centric Design Philosophy to Transform Clinical Trial Patient Enrollment

Leaf Automation: Next-Generation AI-Enhanced CAD Plugins

Legman: Bringing AI to the Construction Industry

“I am excited to welcome cohort three into Transform, this cycle was particularly competitive and we are delighted with the seven companies we selected,” said Shyama Majumdar, director of Transform. “We have a good mix of healthcare, construction, manufacturing, and fintech companies represented as we continue to see generative AI startups leading the way, which is reflected in this cohort. After the success of cohort 2, we are ready to run with cohort 3 and help pave their way to success.”

The accelerator launched in Spring 2023 with its inaugural cohort and those startups are already seeing success. Echo Labs, a transcription platform in the previous cohort, has scaled up, hiring software engineers to meet the demand of partnerships with 150 universities to pilot their product. Blackcurrant, an online business-to-business marketplace for buying and selling hydrogen and member of the first cohort, recently was awarded a $250,000 co-investment from the George Shultz Innovation Fund after participating in the program.

“The continued success of Transform startups has been very encouraging,” said David Uminsky, executive director of the Data Science Institute. “The wide range of sectors this new cohort serves demonstrates AI’s increasing impact on business.”

Transform is partly supported by corporate partners McAndrews, Held & Malloy, Ltd and venture partner, True Blue Partners, a Silicon Valley-based venture capital firm investing in early-stage AI companies, founded by Chicago Booth alum Sunil Grover, MBA ‘99.

“Transform is providing the fertile ground necessary to help incubate the next generation of market leaders,” said Grover, who also is a former engineer with nearly two decades of experience helping build companies as an entrepreneur, investor, and advisor. “Advancements in deep tech present a unique interdisciplinary opportunity to re-imagine every aspect of the business world. This, I believe, will lead to creation of innovative new businesses that are re-imagined, ground up, to apply the capabilities these new technologies can enable.”"
https://mccourt.georgetown.edu/news/maggie-sullivan-msdspp-student-spotlight/,"Georgetown graduate student builds a career integrating international relations, data science and public policy","Maggie Sullivan (MS-DSPP’24), an international development specialist and emerging data scientist, has already lived and worked in three countries. She is well acquainted with the critical role that data plays in shaping U.S. foreign policy and the real-world impact of those policies on marginalized communities around the world.

As a soon-to-be-graduate of the McCourt School of Public Policy’s Master of Science in Data Science for Public Policy (MS-DSPP) program, Sullivan hopes to bridge the gap between gathering insights from data and making, and communicating, policy decisions that positively impact people’s lives.

While completing her undergraduate studies in international affairs at Western Kentucky University, Sullivan began her work with the U.S. Department of State through the highly competitive U.S. Foreign Service Internship Program, a merit and needs-based opportunity for undergraduates to experience diplomacy first-hand, in Washington, DC, and at a U.S. Embassy or Consulate abroad. She was one of 34 students selected among hundreds of qualified candidates.

As a U.S. Foreign Service intern, Sullivan kickstarted her career in international policy, dedicating seven weeks to refugee admissions in the Bureau of Population, Refugees, and Migration (PRM). There, she found data analytics, a discovery that changed her career trajectory.

“One of my initial tasks was developing a Tableau dashboard for PRM to help the team better understand where refugees were being resettled and thus, how to make more strategic funding decisions,” said Sullivan. “It was data visualization for impact.”

The following year, Sullivan spent 10 weeks working at the U.S. Embassy in Sarajevo, Bosnia, in the Political Section, followed by five months teaching English in Bulgaria. Upon returning home to the U.S., Sullivan began working with the U.S. Agency for International Development (USAID), including two years as a program analyst supporting an interagency strategy on foreign aid for vulnerable children and families. Before starting at McCourt, she spent six months as a Communications Specialist for USAID in Rabat, Morocco.

At USAID, Sullivan reflected on what she wanted to do next with her career and the skills she needed to acquire to move forward.

“I saw how the government collects data, and I wanted to learn how to better utilize it,” she said. “I didn’t have the quantitative and data analysis skills I would need to be successful, so I turned to the McCourt School without hesitation.”

Using technology in service of the common good

Sullivan had not taken a math class since high school and initially struggled to adjust to the quantitative rigor of the MS-DSPP program. With the support of her professors and the comradery of her fellow MS-DSPP classmates, Sullivan excelled.

With renewed confidence in her abilities, Sullivan delved deeper into the intersection of technology and public policy by getting involved in the Georgetown Technology Policy Initiative (GTPI) and engaging in discussions in her Public Interest Tech class, taught by Emily Tavoulareas, chair of Georgetown University’s Tech & Society initiative. Outside of the classroom, she is actualizing data for impact with the McCourt School’s Massive Data Institute (MDI) and the Beeck Center for Social Impact + Innovation. She is also working with Rebecca Johnson, assistant professor and affiliate of MDI, on a new research project that leverages advances in computing to create a first-of-its-kind systematic database of school board meeting deliberations.

As GTPI’s communications chair, Sullivan is charged with developing creative content that explains the science behind data buzzwords —“everything from AI to machine learning.”

“Many tech policy experts are talking past technologists, using different terms and definitions. I’m prepared now to help translate that work for different audiences,” she said.

“I want to help people understand that technology can be used to develop innovative solutions to the complex problems of today — all in service of the common good.”"
https://www.marktechpost.com/2024/04/14/top-data-analytics-books-to-read-in-2024/,Top Data Analytics Books to Read in 2024,"In today’s data-driven world, data analytics plays a key role in helping organizations make better decisions, identify opportunities, and mitigate risks. Data analytics enables businesses to gain insights into customer preferences and market dynamics, enhancing overall performance. As such, the demand for competent analysts has increased significantly over the past few years. This article lists the top data analytics books one should read in 2024 to augment one’s skills and stay ahead in this rapidly evolving field.

Python for Data Analysis

“Python for Data Analysis” is a comprehensive guide to manipulating, processing, and cleaning datasets in Python. It covers the tools to load, clean, transform, merge, and reshape data, focusing on libraries like Pandas and Numpy. The book also teaches how to solve real-world problems with detailed examples.

Fundamentals of Data Analytics

This book is a guide to the data analytics process, providing a five-step framework to help readers start the journey of analyzing data. The book covers the data mining and machine learning principles and provides strategies to build a problem-solving mindset.

Data Analytics for Absolute Beginners

This book is aimed at beginners and provides an introduction to data, data visualization, business intelligence, and statistics. The book consists of numerous practical and visual examples, along with coding exercises in Python. It also covers some of the machine learning concepts like regression, classification, and clustering.

Everything Data Analytics

“Everything Data Analytics” is a beginner’s guide to data literacy that helps understand the process of turning data into insights. The book covers the process of data collection, management, and storage, along with the essential machine-learning algorithms necessary for analysis, like regression, classification, and clustering.

SQL for Data Analysis

“SQL for Data Analysis” covers improving one’s SQL skills and making the most of SQL as part of their workflow. The book provides some advanced techniques for transforming data into insights, covering topics like joins, window functions, subqueries, and regular expressions.

Advancing into Analytics

This is a practical guide for Excel users to help them gain an understanding of analytics and the data stack. The author covers the key statistical concepts with spreadsheets and helps Excel users transition to performing exploratory data analysis and hypothesis testing using Python and R.

Modern Data Analytics in Excel

This book covers the features of modern Excel and the powerful tools for analytics. The author teaches how to leverage tools like Power Query and Power Pivot to build repeatable data-cleaning processes and create relational data models and analysis measures. The book also covers using AI and Python for more advanced Excel reporting.

Data Visualization with Excel Dashboards and Reports

This book teaches how to analyze large amounts of data in Excel and report them in a meaningful way. It also teaches the fundamentals of data visualization and covers how to automate redundant reporting and analyses.

Data Analysis for Business, Economics, and Policy

This book is a practical guide to using tools to carry out data analysis to support better decision-making in business, economics, and policy. The book covers topics like data wrangling, regression analysis, and causal analysis, along with numerous case studies with real-world data.

Storytelling with Data

“Storytelling with Data” is a data visualization guide for business professionals. The book teaches how to convert the data into a high-impact visual story to resonate the message with the audience.

Fundamentals of Data Visualization

This book provides a guide to making informative and compelling figures that help convey a compelling story. The book also provides extensive examples of good and bad figures.

Data Visualization: A Practical Introduction

This book covers how to create compelling visualizations using R programming language, more specifically using the ggplot2 library. It covers topics like plotting continuous and categorical variables, grouping, summarizing, and transforming data for plotting, creating maps, and refining plots to make them more understandable.

Naked Statistics

“Naked Statistics” is a beginner-friendly book focusing on the underlying intuition driving statistical analysis. The book covers topics like inference, correlation, and regression analysis in a witty and funny manner, which simplifies the learning process.

The Art of Statistics

“The Art of Statistics” is a practical guide to using data and mathematics to understand real-world problems better. The book covers how to clarify questions and assumptions and interpret the results.

Essential Math for Data Science

This book teaches the mathematics essential for excelling in data science, machine learning, and statistics. It covers topics like calculus, probability, linear algebra, and statistics, as well as their applications in algorithms like linear regression and neural networks.

Practical Statistics for Data Scientists

This book covers how to apply statistical methods to data science using programming languages like Python and R. It emphasizes the importance of exploratory data analysis and also covers the underlying statistical concepts behind supervised and unsupervised machine learning algorithms.

Business unIntelligence

This book talks about the ever-changing and complex business intelligence landscape in today’s world. It covers numerous new models that businesses can leverage to design support systems for future successful organizations.

Data Science for Business

This book covers how organizations can leverage data science to gain a competitive advantage. It talks about general concepts that are useful in extracting knowledge from data. The book also provides various real-world examples to explain different concepts.

The Model Thinker

This book guides how to organize, apply, and understand the data that is being analyzed to become a true data ninja. The book covers mathematical, statistical, and computational models such as linear regression and random walks and provides a toolkit for its readers to make them leverage data to their advantage.

Becoming a Data Head

“Becoming a Data Head” teaches how to think, speak, and understand data science and statistics. It also covers the recent trends in machine learning, text analytics, and artificial intelligence.

We make a small profit from purchases made via referral/affiliate links attached to each book mentioned in the above list."
https://www.nichd.nih.gov/about/org/od/odss,Office of Data Science and Sharing (ODSS),"ODSS was established in 2021 to lead and coordinate NICHD’s activities within data science, bioinformatics, data sharing policy and compliance, and emerging technologies.

ODSS's vision is to enable a culture of responsible and innovative use of data and biospecimens that accelerates research and improves health for NICHD populations. The office's mission is to:

Develop a diverse, secure, and interoperable research data ecosystem

Advise on best practices for data collection, standards, management, sharing, and use across the research and funding lifecycles

Advance scientific discovery in support of NICHD's mission to understand human development, improve reproductive health, enhance the lives of children and adolescents, and optimize abilities for all

ODSS is a trusted informational resource for NICHD staff and researchers on all NIH data and specimen sharing policies.

ODSS serves as NICHD's primary liaison with the NIH Office of the Director's Office of Data Science and Strategy, to ensure engagement in large NIH data-science and emerging technology programs and ensure alignment with NIH, HHS, and federal programs and policies.

Director Rebecca Rosen’s presentation (PDF 2.2 MB) from the January 2023 Council provides an overview of ODSS activities.

ODSS is a trusted informational resource for NICHD staff and researchers on all NIH data sharing policies.

The new NIH DMS Policy applies to funding applications and proposals submitted to NIH on or after January 25, 2023. The following are helpful links about the new policy for the NICHD investigator community:

Explore the NIH Scientific Data Sharing website for information on:

Getting Ready for NIH’s DMS Policy (PDF 257 KB)

2023 DMS Policy FAQs

Submitting Genomic Data

Repositories for Sharing Scientific Data

Data Sharing Policy Trainings & Events

Use NICHD’s Tips for Writing a DMS Plan (PDF 193 KB) to create a DMS plan for your NIH-funded research projects

Learn about common data standards that may be relevant to NICHD research and how adopting them can improve data usability and interoperability throughout the data lifecycle.

Search the NICHD Data Repository Finder to identify an existing data repository to include in your DMS plan. Data repositories relevant to NICHD researchers will be added to the tool, currently in beta version, on an ongoing basis

Check out the following example DMS plans developed by NICHD staff:

Human Clinical and Genomics Data (PDF 215 KB)

Human Clinical Trial Data (PDF 179 KB)

Human Survey Data (PDF 169 KB)

Model Organism (Zebrafish) Data (PDF 124 KB)

Develop informed consent language that addresses data and specimen sharing using:

Informed Consent for Secondary Research and Biospecimens: Points to Consider and Sample Language for Future Use and/or Sharing (PDF 736 KB) developed by the NIH Office of Science Policy

Consent Templates and Guidance that Address Storage, Sharing, and Future Research Using Your Specimens and Data developed by the NIH Office of Intramural Research, Office of Human Subjects Research Protections

Test and provide feedback on the Federal Demonstration Partnership (FDP) NIH DMS Plan Pilot :

Use the Alpha or Beta DMS Plan templates to develop and submit your DMS Plan and provide feedback on the templates’ effectiveness and usability. The Alpha template guides the user through a structured, modular approach to limit the need for free text entry, while the Bravo template provides detailed prompts for each type of data and options for more free text entry. Templates are available on FDP website or through the DMPTool .

Read Best Practices for Sharing Research Software Frequently Asked Questions developed by the NIH Office of Data Science Strategy

DASH is a centralized resource for researchers to store, share, and access de-identified data from studies funded or conducted by NICHD. It also serves as a portal for requesting biospecimens from selected studies within the hub.

E-updates from DASH, published quarterly, provide information on upcoming NICHD data-collection projects, studies available in DASH, including those with biospecimens, as well as other noteworthy data news.

DASH E-Updates

September 2023 Update (PDF 357 KB)

June 2023 Update (PDF 451 KB)

March 2023 Update (PDF 309 KB)

December 2022 Update (PDF 279 KB)

September 2022 Update (PDF 367 KB)

June 2022 Update (PDF 321 KB)

March 2022 Update (PDF 320 KB)

December 2021 Update (PDF 265 KB)

September 2021 Update (PDF 232 KB)

July 2021 Update (PDF 234 KB)

March 2021 Update (PDF 248 KB)

In collaboration with NICHD, NIH, and external stakeholders, ODSS is building a federated, secure research and specimen data ecosystem that will measurably and rapidly facilitate data and specimen sharing by NICHD-funded researchers and increase access to shared data and specimens for the entire research community.

The NICHD Data Ecosystem includes people, data, processes, and technologies that align with the NICHD Strategic Plan and that support NICHD communities’ data science and sharing needs. In addition, ODSS is collecting “user stories” to describe these needs, within the following contexts:

NICHD investigators share their data and biospecimens to encourage reproducibility and broad reuse.

The researcher community:

Finds and uses NICHD data and specimens to enable new and innovative research

Securely analyzes NICHD and other data using new tools, training resources, and powerful computing resources

Participant communities visualize outcomes of taking part in NICHD research and benefit faster from new discoveries.

NICHD:

Tracks researcher compliance with NIH policies and good stewardship of government funds

Assesses and visualizes the scientific return on investment in data and biospecimen sharing

Promotes successful sharing strategies, policies, and tools to encourage broader use and reuse

ODSS is currently assessing all data repositories that NICHD researchers use to share data or access shared data for secondary use. This assessment and the communities’ user stories will inform NICHD’s approach to improving sustainability and interoperability across the ecosystem to best support the institute’s needs. The office will also use information from the assessment to update the NICHD Data Repository Finder .

ODSS leads and collaborates on a variety of projects to maximize the responsible and innovative use of data across the NICHD Data Ecosystem. Reports based on these projects will be posted in this section as they become available.

Privacy Preserving Record Linkage (PPRL) for Pediatric COVID-19 Studies (PDF 4 MB)

Led by ODSS with funding from the NIH Office of Data Science Strategy and support from Booz Allen Hamilton

This report describes governance and technical approaches for PPRL based on an assessment of existing record linkage implementations. The assessment was designed to address pediatric COVID-19 use cases identified by NICHD and NIH researcher communities, given the federated nature of the NIH data ecosystem. The report proposes a set of governance and technical considerations that could inform the design of any PPRL implementation in a federated data ecosystem.

Digitizing Data Governance Metadata Towards Streamlining Patient- Centered Outcomes Research Data Linkages

Led by ODSS with funding from the HHS Office of Secretary Patient-Centered Outcomes Research Trust Fund

The project strives to develop and test a generalizable, scalable, and machine-readable data governance metadata schema that simplifies decision-making for data linkage in patient-centered outcomes research and the subsequent use of linked datasets. Building on the PPRL for Pediatric COVID-19 Studies Report, this project is driven by pediatric COVID-19 research use cases that involve the linkage of several HHS and other federally funded datasets. Documents and materials will be publicly shared as they become available."
https://edsource.org/2024/data-science-helps-students-of-color-opt-in-for-more-math/707341,Data Science helps students of color opt in for more math,
https://www.utsa.edu/today/2024/01/story/utsa-announces-initiative-for-new-college.html,"UTSA announces bold initiative to establish new college in AI, cyber, computing and data science","JANUARY 19, 2024 — UTSA today announced a pioneering initiative to reshape its academic landscape with the creation of a new college dedicated to artificial intelligence (AI), cybersecurity, computing, data science and related disciplines. This initiative aligns with the university's commitment to innovation and academic excellence while also positioning UTSA to lead in the rapidly evolving landscape of advanced technologies.

Nearly 6,000 students are enrolled in AI, cyber, computing and data science-related degree programs at UTSA, reflecting a 31% increase since 2019. UTSA graduated more than 1,000 students in these programs, currently distributed across four colleges, in 2022-2023.

""The convergence of AI, data science, computing, and cybersecurity signifies a very forward-looking endeavor as we embrace the fifth industrial revolution, now especially propelled by AI advancements,"" said UTSA President Taylor Eighmy. ""These disciplines will remain intertwined for the foreseeable future. With an escalating demand for emerging technologies, their applications, and the demand for a skilled workforce, this new college will greatly accelerate UTSA's economic and workforce impact here in San Antonio, across Texas, and nationally.""

The proliferation of artificial intelligence applications, in particular, in recent years has contributed to unprecedented advancements across industries including health care, finance, manufacturing and more, as organizations harness the power of AI and machine learning to streamline processes and drive innovation. Amidst the dynamic expansion of AI, as well as data science and cybersecurity, the demand for skilled professionals is reaching unprecedented heights.

According to Cybersecurity Ventures, there are approximately 3.5 million open positions in cybersecurity and data science globally, highlighting the critical need for expertise in safeguarding digital assets and extracting meaningful insights from vast datasets. In Texas alone, there are over 46,000 job opportunities in these fields, as reported by Cyberseek.

Computerworld's analysis indicates a significant surge in job creation, with an estimated five million roles emerging in 2022, spanning data science, AI/machine learning, cloud computing, cybersecurity, product management, and digital social media. Looking ahead, the U.S. Bureau of Labor Statistics projects a 36% increase in data scientist jobs and a 35% increase in cybersecurity jobs nationally over the next decade.

In Texas, the growth trajectory is impressive, with a forecasted 26.5% increase in AI and data science jobs, underscoring the state's pivotal role in shaping the future workforce in these transformative fields.

In an email to UTSA faculty and staff, Interim Provost and Senior Vice President for Academic Affairs Heather Shipley announced the formation of the AI, Cyber, Computing, and Data Science Planning Advisory Task Force to lead a planning exercise to establish the new college. The task force is charged with surveying student interests, regional workforce needs and partnering opportunities; exploring multidisciplinary research opportunities; and recommending a college organizational structure that aligns these programs to enhance student success, career readiness and transdisciplinary research.

Jonathon Halbesleben, dean of the Carlos Alvarez College of Business, and Jianwei Niu, interim dean of University College, will serve as task force chairs. School of Data Science Founding Director David Mongeau will guide the external benchmarking and outreach through community charettes with San Antonio stakeholders and the surveying of best practices at peer and aspiring institutions.

Shipley noted that similar initiatives led to the creation of the College for Health, Community and Policy in 2019 and the Margie and Bill Klesse College of Engineering and Integrated Design in 2021.

“Ensuring UTSA students are well-prepared for their chosen careers in the dynamic transdisciplinary workforce is our most important responsibility,” Shipley said. “This initiative is driven by our commitment to fostering innovation, advancing research, and delivering educational excellence across related disciplines. More specifically, it seeks to amplify synergies among academic and research domains, fostering the transdisciplinary collaboration that is critical to developing our students’ ability to tackle complex, multifaceted challenges as the future leaders in these fields.”

UTSA has been a trailblazer in the fields of AI, cyber, computing and data science. The School of Data Science, established in 2018, is only school of its kind at a Carnegie R1 U.S. Hispanic Serving Institution. It has achieved significant milestones, including being awarded $1.2 million for student training and research programs, hosting the national Academic Data Science Alliance annual meeting in 2023, and designing a new certificate program in data engineering, which is currently under development and review. San Pedro I, the downtown San Antonio home for the School of Data Science, now is a hub for more than 1,000 students and researchers.

Veronica Salazar, UTSA chief enterprise development officer and senior vice president for business affairs, emphasized the strategic alignment of this initiative with UTSA's investment in downtown San Antonio and the city’s tech corridor.

“Through this initiative, we are not only investing in the intellectual capital of our students but also contributing to the growth and vibrancy of downtown San Antonio,” Salazar said. “This initiative is a testament to UTSA’s dedication to providing a dynamic hub in our city’s core for education, research and engagement, further solidifying our role as a key player in the San Antonio's development."""
https://www.mtsu.edu/program/data-science-b-s/,"Data Science, B.S.","Data Science Institute

The Data Science Institute develops people for the data world. This is accomplished by facilitating interdisciplinary research, industry and government partnerships, and community outreach which puts MTSU at the forefront of data science regionally and nationally in terms of education and research. The Data Science Institute also looks to develop people through doing by offering opportunities for projects, events (data dives), and training.

Data Dives

To learn Data Science, you must DO Data Science. The Data Science Institute offers hackathon style Data dives that allow students to work together to solve real world problems using data. The Data dives have ranged from 16 hours over two days to 24 hour overnight events and have analyzed data from several non-profits such as SecondHarvest, Special Kids, Inc., and Murfreesboro Police Department.

Data Science students presenting their solution to a real-world problem to corporate sponsors, students, and faculty during a Data Dive.

Related Links"
https://www.simplilearn.com/tutorials/data-science-tutorial/how-to-become-a-data-scientist,How to Become a Data Scientist in 2024: Complete Guide,"Companies worldwide have always gathered and analyzed data about their customers to provide better service and improve their bottom lines. In today’s digital world, we are able to gather tremendous amounts of data, which require non-traditional data processing methods and software.

A data scientist is a professional who specializes in analyzing and interpreting data. They use their data science skills to help organizations make better decisions and improve their operations. Data scientists typically have a strong background in mathematics, statistics, and computer science. They use this knowledge to analyze large data sets and find trends or patterns. Additionally, data scientists may develop new ways to collect and store data.

Data Scientist vs Data Analyst

What Does a Data Scientist Do?

A Data Scientist extracts, analyzes, and interprets data to uncover valuable insights and inform strategic decisions. They collect and clean data from various sources, perform exploratory data analysis to identify patterns, and create predictive models using ML and statistical techniques.

Data Scientists also play a crucial role in feature engineering, model evaluation, and deploying models into production. Their work spans industries, aiding businesses in optimizing operations, improving products, and driving data-driven strategies for success. They are instrumental in transforming data into actionable knowledge that drives innovation and competitive advantage.

Role of a Data Scientist

Data Cleaning and Preparation: Scrubbing data to ensure its quality and readiness for analysis. This involves handling missing values, detecting outliers, and ensuring data consistency.

Data Exploration and Analysis: Using statistical methods to explore the relationships between different variables in datasets, identify patterns, and detect anomalies.

Predictive Modeling: Developing models that predict future outcomes based on historical data. This involves selecting the appropriate model, training it with data, and validating its accuracy.

Machine Learning and Advanced Analytics: Applying machine learning algorithms to build models that can automate decision-making processes or enhance predictions with increasing accuracy over time.

Data Visualization and Reporting: Creating visual representations of data findings and analysis results to make them accessible and understandable to non-technical stakeholders.

Cross-functional Collaboration: Working with other departments, such as engineering, product, and business teams, to understand their data needs and deliver insights to drive strategic decisions.

Innovative Solution Development: Identifying opportunities to apply data science techniques to new organizational areas, leading to innovative products, services, or operational improvements.

Big Data Technologies: Utilizing big data technologies and tools to handle, process, and analyze large datasets that traditional data processing applications cannot manage.

Continual Learning: Staying current with the latest technologies, algorithms, and methodologies in data science to continually improve processes and outcomes.

Ethical Oversight: Ensuring the ethical collection, handling, and use of data, including considerations for privacy, consent, and bias mitigation.

Data Science Qualifications and Eligibility Required

To become a data scientist, you will need to have strong analytical and mathematical skills. You should be able to understand and work with complex data sets. Additionally, you should be able to use statistical software packages and be familiar with programming languages such as Python or R. Data scientists also typically have a certification from an accredited program.

Read More: Switching to data science was one of the best decisions Ekta Saraogi took for her career. After a varied career in the IT field, our Data Scientist Master's Program offered her the variety she craved with a more stable environment for her career. Read all about Saraogi’s career from IT nomad to Data Science master in her Simplilearn Data Science Course Review.

Skills to Become A Data Scientist

Becoming a data scientist requires diverse skills that span technical, analytical, and soft skills. The role of a data scientist is to extract insights and knowledge from data, which involves a combination of extracting, processing, analyzing, visualizing, and interpreting data. Here's a detailed look at the key skills necessary to become a data scientist:

1. Data Visualization

The ability to transform data and findings into understandable and visually appealing formats. Tools like Tableau, Power BI, and libraries in Python (e.g., Matplotlib, Seaborn) are crucial.

2. Machine Learning

Understanding and applying machine learning algorithms, including supervised and unsupervised learning, to predict outcomes and uncover patterns in data.

3. Communication

Translating complex data findings into clear, concise, and actionable insights for technical and non-technical stakeholders.

4. Programming

Proficiency in programming languages, especially Python and R, is essential for data manipulation, statistical analysis, and machine learning.

5. Statistics and Probability

A strong foundation in statistics and probability to analyze data sets, understand distributions and apply statistical tests and models.

6. Business Acumen

Understanding business processes, goals, and strategies to align data projects with organizational objectives.

7. Computing

Familiarity with cloud computing services (like AWS, Google Cloud, Azure) and big data technologies (like Hadoop and Spark) for processing large data sets.

8. Mathematics

Knowledge of linear algebra, calculus, and optimization techniques is foundational to algorithms and machine learning models.

9. Curiosity

A natural curiosity to ask questions, explore data for hidden patterns, and a continuous desire to learn and discover new techniques and methodologies.

10. Data Wrangling

The ability to clean, structure, and enrich raw data into a desired format for analysis. This involves handling missing values, outliers, and merging datasets.

11. Deep Learning

Understanding neural networks and deep learning frameworks (like TensorFlow and PyTorch) for tasks requiring image recognition, natural language processing, etc.

12. Python

Python is a must-have for data science due to its extensive libraries (Pandas, NumPy, Scikit-learn) and versatility in handling data tasks.

13. Critical Thinking

The ability to approach problems logically, question assumptions, and evaluate the strength of arguments or methodologies.

14. Data Science Theory

Understanding the principles and theories underlying data science practices, including machine learning models and statistical methods.

15. Database Management

Knowledge of SQL and NoSQL databases for storing, querying, and managing data efficiently.

16. Model Deployment

Skills in deploying models into production environments, ensuring they are scalable, maintainable, and can provide real-time insights.

17. Business Intelligence

Using BI tools and techniques to analyze data, produce reports, and support decision-making processes.

18. Unstructured Data

Handling unstructured data (text, images, audio) using techniques like natural language processing (NLP) and computer vision.

19. Analytical Mindset

The ability to approach data analytically, identify trends and anomalies, and make data-driven decisions.

20. Data Intuition

Developing an intuition for data involves understanding what looks right or wrong and where to dig deeper.

21. Big Data

Managing and analyzing large volumes of data with big data technologies, understanding the complexities and challenges of big data environments.

22. Analytics and Modeling

Applying various analytical and modeling techniques to understand data, make predictions, and test hypotheses.

23. Data Transformation

Transforming data into a more useful and interpretable form using normalization, scaling, and feature engineering techniques.

Insightful Read: Data Science Roadmap

How to Become a Data Scientist?

Data science is the area of study that involves extracting knowledge from all of the data gathered. There is a great demand for professionals who can turn data analysis into a competitive advantage for their organizations. In a career as a data scientist, you’ll create data-driven business solutions and analytics.

Step 1: Earn a Bachelor’s Degree

A great way to get started in Data Science is to get a bachelor’s degree in a relevant field such as data science, statistics, or computer science. It is one of the most common criteria companies look at for hiring data scientists.

Step 2: Learn Relevant Programming Languages

While a Bachelor’s degree might give you a theoretical understanding of the subject, it is essential to brush up on relevant programming languages such as Python, R, SQL, and SAS. These are essential languages when it comes to working with large datasets.

Step 3: Learn Related Skills

In addition to different languages, a Data Scientist should also have knowledge of working with a few tools for Data Visualization, Machine Learning, and Big Data. When working with big datasets, it is crucial to know how to handle large datasets and clean, sort, and analyze them.

Step 4: Earn Certifications

Tool and skill-specific certifications are a great way to show your knowledge and expertise about your skills. Here are a few great certifications to help you pave the path:

Tableau Certification Training Course

Power BI Certification Course

These two are the most popular tools used by Data Scientist experts and would be a perfect addition to start your career journey.

Step 5: Internships

Internships are a great way to get your foot in the door to companies hiring data scientists. Seek jobs that include keywords such as data analyst, business intelligence analyst, statistician, or data engineer. Internships are also a great way to learn hands-on what exactly the job with entail.

Step 6: Data Science Entry-Level Jobs

Once your internship period is over, you can either join in the same company (if they are hiring), or you can start looking for entry-level positions for data scientists, data analysts, data engineers. From there you can gain experience and work up the ladder as you expand your knowledge and skills.

Data Science at Work

Did you know that media services provider Netflix uses data science extensively? The company measures user engagement and retention, including:

When you pause, rewind or fast-forward

What day of the week and what time of day you watch content

When and why you leave content

Where in the world you’re watching from

Your browsing and scrolling behavior

What device you watch on

Netflix has over 120 million users worldwide! To process all of that information, Netflix uses advanced data science metrics. This allows it to present a better movie and show recommendations to its users and also create better shows for them. The Netflix hit series House of Cards was developed using data science and big data. Netflix collected user data from the show, West Wing, another drama taking place in the White House. The company took into consideration where people stopped when they fast-forwarded and where they stopped watching the show. Analyzing this data allowed Netflix to create what it believed was a perfectly engrossing show.

Now let us explore some of the important data scientist skills that an individual should possess.

Careers in Data Science

Once you’ve mastered these skills, you’ll have a range of career opportunities available. Prepare for a job interview with our data science interview questions.

Data Scientist

Average salary: $120,931

Data scientists create data-driven business solutions and analytics by driving optimization and improvement of product development. They use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and more. Data scientists also coordinate with different functional teams to implement models and monitor outcomes.

Data Engineer

Average salary: $137,776

Data engineers assemble large, complex data sets. They identify, design, and implement internal process improvements and then build the infrastructure required for optimal data extraction, transformation, and loading. They also build analytics tools that utilize the data pipeline.

Data Architect

Average salary: $112,764

Data architects analyze the structural requirements for new software and applications and develop database solutions. They install and configure information systems and migrate data from legacy systems to new ones.

Data Analyst

Average salary: $65,470

Data analysts acquires data from primary or secondary sources and maintain databases. They interpret that data, analyze results using statistical techniques, and develop data collections systems and other solutions that help management prioritize business and information needs.

Business Analyst

Average salary: $70,170

Business analysts assist a company with planning and monitoring by eliciting and organizing requirements. They validate resource requirements and develop cost-estimate models by creating informative, actionable and repeatable reporting.

Data Administrator

Average salary: $54,364

Data administrators assist in database design and update existing databases. They are responsible for setting up and testing new database and data handling systems, sustaining the security and integrity of databases and creating complex query definitions that allow data to be extracted.

Future of Data Science

The future of data science is promising and expected to be integral to the evolution of technology, business, healthcare, and many other sectors. As data generation grows exponentially, sophisticated data analysis and interpretation demand will only increase.

Increased Demand Across Industries: Data science will continue to expand beyond tech and finance into healthcare, agriculture, education, and public services, driving innovation and efficiency across all sectors.

Advancements in AI and ML: Artificial intelligence (AI) and machine learning (ML) will become even more sophisticated, enabling more accurate predictions, automation of complex tasks, and the creation of intelligent systems that can learn and adapt over time.

Ethics, Privacy, and Data Governance: As data becomes more integral, ethical considerations, privacy concerns, and robust data governance frameworks will become increasingly important. Ensuring the ethical use of data, combating bias in AI, and protecting individual privacy will be central to the field's evolution.

Integration of IoT and Big Data: The Internet of Things (IoT) will generate vast amounts of data from connected devices, necessitating advanced data science techniques to analyze and derive value from this data. This integration will drive advancements in real-time data analysis and edge computing.

Automation in Data Science: Automation tools will streamline data processing, model development, and analysis, allowing data scientists to focus on more complex and innovative tasks. AutoML (Automated Machine Learning) will become more prevalent, making data science more accessible.

Augmented Analytics: Augmented analytics will use AI and ML to enhance data analytics, sharing, and business intelligence. This will make advanced analytics accessible to non-experts, democratizing data insights across organizations.

Quantum Computing: Though still in its infancy, quantum computing has the potential to revolutionize data science by processing complex datasets at unprecedented speeds. This could lead to cryptography, drug discovery, and complex system simulation breakthroughs.

Focus on Soft Skills: As technical skills become more common and tools become more sophisticated, soft skills like storytelling, critical thinking, and communication will become crucial for data scientists. The ability to translate complex findings into actionable business insights will be invaluable.

Data Science as a Service (DSaaS): The growth of cloud computing will lead to more organizations outsourcing data science tasks. DSaaS will become more common, providing businesses of all sizes access to advanced data analysis without needing in-house expertise.

Continuous and Interdisciplinary Learning: The field will require continuous learning in new technologies and algorithms and in understanding domain-specific knowledge. Data scientists increasingly need interdisciplinary knowledge to solve complex real-world problems.

Conclusion

Becoming a data scientist in 2024 involves continuous learning, curiosity, and skill development. As we've explored, the path to entering the field of data science involves acquiring a blend of technical skills like programming, machine learning, and data visualization alongside soft skills like communication and critical thinking. The future of data science promises exciting opportunities and challenges, making it a rewarding career choice for those willing to navigate its complexities.

For those ready to embark on this journey, the Data Science Masters course offers a detailed curriculum to equip you with the necessary knowledge and hands-on experience to thrive in the field. Whether you're starting from scratch or looking to deepen your expertise, this program covers everything from the fundamentals of data analysis to advanced concepts in machine learning and big data technologies."
https://www.chronicle.com/events/virtual/data-science-unbound,Data Science Unbound,"Data science continues to evolve beyond computer science, expanding into the liberal arts. Driven by rising student demand, this expansion faces challenges, including student access and faculty shortages.

In this upcoming virtual forum, a panel of experts led by Alex Kafka, a senior editor at The Chronicle, will discuss the benefits and obstacles of data science’s growing popularity.

Join “Data Science Unbound” on December 7 at 2 p.m. ET, to learn more about the intersection of data science and the humanities.

With Support From Microsoft"
https://www.pitt.edu/pittwire/features-articles/online-master-data-science,Pitt is making data science accessible worldwide with a new online master’s degree,"Students without any computing or STEM education and experience will be embraced in a new online master’s in data science, launching on Coursera in 2024 through the University of Pittsburgh School of Computing and Information, school officials announced Dec. 6.

Tuition for this novel master’s degree program is $15,000. In addition, the 30-credit Master of Data Science (MDS) is 38% more affordable than the average online master’s degree program, according to the latest data from the National Center for Education Statistics.

The accessible, flexible online curriculum, one of the most ambitious initiatives ever at Pitt’s School of Computing and Information (SCI), will allow students from Pennsylvania, the U.S. and across the globe to learn data science skills and analytic tools, gain abilities to pose and answer real-world questions through data and complete experiential projects to build a portfolio they can share with potential employers — all at their own pace.

Admission to the program does not require prior data or computer science work, programming experience or even an academic history beyond a bachelor’s degree. The fully accredited program is performance-based, requiring students to attain a B-average or better in an initial, three-credit course to continue toward this newly offered graduate degree.

Enrollment is scheduled to begin Feb. 12, with the first course starting in May. Admitted students can begin a full course load in fall 2024.

“Our MDS removes entry barriers, reassesses admission processes, and harnesses technology to deliver an exceptionally accessible program that embodies Pitt’s high-quality, internationally recognized education,” said Dean Bruce Childers. “SCI is embarking on this new online degree program because we realize the importance of providing access to data skills and knowledge inclusive of all learners.”

SCI builds on the results of more than a century of progress, bringing together learners of various disciplines through a shared investment in innovation and technology. Continuing that trajectory, top SCI research and teaching faculty developed the MDS curriculum so working adults could learn data approaches relevant to their current career paths or advance in data science jobs, which are among the fastest growing across the globe.

“SCI wants to place our alumni in the best possible position to secure the right job for them,” said Adam Lee, executive associate dean. “We believe the MDS program will help to make that happen.”

The MDS coursework was designed to provide schedule flexibility to working professionals while also including optional live sessions where students can interact with faculty and course staff throughout the curriculum. Students will also have access to the same kinds of resources as resident students, including student services, career resources, peer communications and the same faculty.

Coursera, a leading online learning platform founded by two Stanford professors in 2012, partners with more than 300 universities and companies to offer a broad catalog of content and credentials to learners worldwide.

“We're proud to collaborate with Pitt and bring this highly accessible degree program to life,"" said Marni Baker Stein, chief content officer at Coursera. ""Amid a growing demand for data scientists, we're creating a pathway for learners from diverse backgrounds to transform their passion into a profession. I look forward to seeing the many opportunities this program will unlock for students and witnessing the contributions they'll make to the field.”

To learn more, visit SCI’s webpage or Coursera.

— Chuck Finder, photography by Aimee Obidzinski"
https://www.meredith.edu/news/meredith-student-featured-by-international-data-science-organization/,Meredith Student Featured by International Data Science Organization,"Meredith College student Emma Brooks, ’24, has been featured on the website of Women in Data Science (WiDS) Worldwide.

Brooks is earning a degree in mathematics and computer science with a minor in data science. In the WiDs article, she discusses how her interest in data science began at Meredith.

“After learning about the data science field my second year at Meredith, I felt that the mix of math and coding involved was right up my alley. I heard about Meredith’s fairly new data science program from an upperclass student and registered for the first intro class to try it out.”

She also credited Meredith faculty member Emily Lada for supporting her interest.

“Dr. Emily Lada, my data science professor, has also played an important role in my interest in the field. She has not only been a great teacher but also a strong and accomplished female role model in the industry. I feel very fortunate to have had support from dedicated and intelligent women in data science, whether they be my classmates or professors.”"
https://www.odu.edu/article/virginia-beach-data-science-institute-offers-cutting-edge-space-for-collaboration,Virginia Beach Data Science Institute Offers Cutting-Edge Space for Collaboration,"By Kenya Godette

The Old Dominion University School of Data Science opened the Virginia Beach Institute of Data Science on Nov. 16. The new facility is designed to be a hub for data-driven research and exploration, housing dedicated training space for cybersecurity simulations; collaboration areas where students and industry leaders can discuss and test new research models; and cutting-edge research labs for data driven exploration.

The 17,617-square-foot facility is the first new physical space since the ODU School of Data Science received approval from the State Council on Higher Education for Virginia on Feb. 1, making the school the central home for academic programming in data science and research.

On opening day, the School held a ribbon-cutting ceremony for the new facility, located on the tenth floor of the Armada Hoffler Building at 222 Central Avenue in Virginia Beach.

Nearly 100 individuals representing the city of Virginia Beach, ODU and data science industries were present for the ribbon-cutting ceremony and reception. Among those who gave remarks were ODU President Brian O. Hemphill, Ph.D.; ODU Vice Provost of Academic Affairs Brian Payne; ODU alumni Justin Brunnel and Stephanie Milonas; inaugural Director of the School of Data Science Frank Liu; and Virginia Beach Mayor Bobby Dyer.

Sachin Shetty, associate professor and associate director of the Virginia Modeling, Analysis and Simulation Center, conducted tours of the facility. The institute includes incubator and accelerator spaces, research and teaching labs and state-of-the-art research equipment like drones.

The facility will provide an environment where industry-research partnerships can take place, facilitating the exchange of ideas, resources and expertise between academia and the business community.

“The Virginia Beach Institute of Data Science will be at the forefront of education, research and collaboration,” Liu said. “Not only for the region but also for the good of building a vibrant academic community that will educate new generations of builders, thinkers and leaders. Not just in Hampton Roads, but the world.”

Virginia Beach officials noted the facility is a positive and welcomed advancement for the community.

“This initiative is yet another growing opportunity between the city of Virginia Beach and also ODU to provide new programs that will benefit our local residents and our business,” Dyer said. “We passionately welcome and celebrate this excellent venture and wish it much success.”"
https://edsource.org/2023/advanced-algebra-data-science-and-more-uc-rethinks-contested-issues-of-high-school-math/701986,"Advanced algebra, data science and more: UC rethinks contested issues of high school math","Next month, a panel of University of California professors in the sciences and math will give their recommendations on the contentious issue of how much math high school students should know before taking a college-qualifying course in data science. Its answer could influence future course offerings and admissions requirements in math for UC and CSU.

“There’s a tension between the interest in adhering to math standards and ensuring students learn math and also recognizing the changes that are happening in the uses of math in industry and the world in general,” said Pamela Burdman, executive director of Just Equations, a nonprofit that promotes policies that prepare students with quantitative skills to succeed in college.

“How UC resolves this issue will have a bearing on that, and the signals that UC sends to high schools about what is and isn’t approved will have a big impact on what this next generation of students learns.”

The issue has embroiled California’s higher education decision-makers, and it mired proponents and opponents of California’s new TK-12 math framework in an acrimonious debate earlier this year.

Advocates have cited the appeal of introductory data science as a way to broaden the boundaries of math to students who were turned off by it. Traditionalists – STEM professors and professionals – countered that courses like introductory data science that include little advanced math content create the illusion that students are prepared for college-level quantitative work while discouraging them from pursuing STEM majors.

Separate from this immediate question, a second group of UC, CSU and community college math professors is revisiting a more fundamental question: How much math knowledge is essential for any high school graduate with college aspirations, and separately for those interested in pursuing STEM, the social sciences or majors needing few quantitative skills?

For the past two decades, the answer was cut-and-dried — and uniform. The CSU and UC defined foundational high school math as the topics and concepts covered by the three math courses – Algebra I, Geometry, and Advanced Algebra, which is Algebra II — that both systems require students to pass for admission.

With the state’s adoption of the Common Core math standards for K-12 in 2010, the options expanded to include Integrated I, II and III, which cover the same Common Core topics in a different order. Both UC and CSU encourage students to take a fourth year of math, and most do.

The debate has centered on Algebra II. For future science, engineering and math majors, Algebra II is the gateway to the path from trigonometry and Pre-calculus to Calculus, which they must eventually take. But for the majority of non-STEM-bound students, Algebra II can be a slog: difficult, abstract and irrelevant to the college plans.

Despite a general agreement that high school math should be more relatable and relevant, there is intense disagreement on the fix.

New course offerings in the burgeoning fields of data science and statistics “present new ways to engage students. At the same time, they can foster the quantitative literacy — or competency with numerical data — that math courses are intended to provide,” Burdman wrote in a commentary in EdSource. “They have the potential to improve equity and ensure that quantitative literacy is a right, not a privilege.”

But with 17% of Black children, 23% of Hispanic children and 23% of low-income children scoring proficient in the latest Smarter Balanced tests, the need for effective and engaging math instruction must begin long before high school. The new TK-12 math framework, approved in July after multiple revisions and four years of debate, forcefully calls for fundamental changes in math instruction.

“Arguments about what content should be included in high school mathematics fail to acknowledge the elephant in the room: We haven’t yet figured out how to teach the concepts of algebra well to most students,” wrote psychology professors Ji Song of CSU Los Angeles and James Stigler of UCLA in an Edsource commentary.

Committees of faculty senates of both UC and CSU have restated that Algebra II, along with geometry and Algebra I, provide the skills and quantitative reasoning needed for college work, in whatever paths students eventually choose.

“College and career readiness expectations include completion of these sequences or their equivalent that cover all of the Common Core standards,” the CSU Math Council wrote in a January resolution.

But in 2020, the influential UC academic senate, which is authorized to oversee course content for admissions, sent a critical mixed message. In a statement, the Board of Admissions and Relations with Schools or BOARS invited proposals for a broader range of math courses for consideration that would enable students to “complete certain mathematics courses other than Algebra II or Mathematics III in their junior year of high school to fulfill the minimum admissions requirement.” BOARS said it saw the expanded options “as both a college preparation and equity issue.”

Proponents of data science seized the opportunity, launching an end-run around what they perceived to be the inflexibility of math professors to change.

New courses

BOARS oversees policy, but the High School Articulation Unit, a small office in the UC President’s Office, does the evaluating and vetting of the tens of thousands of courses that course developers and high school teachers submit annually for approval. The office began authorizing new data science courses as meeting or “validating” the content requirements of Algebra II and Integrated III. The validation exemption presumed that the new course would build upon concepts and standards that students had covered in previous courses — in this case, Algebra II — or would be covered in the new course.

Subsequently, 368 data science and related courses received approval for 2022-23 and 435 for 2023-24. Nearly all use one of a half-dozen or so data science curricula developed for high schools.

There had been a precedent. As early as 2014, the UC had questionably validated statistics courses as satisfying Algebra II because they cover statistics standards that many Algebra II teachers frequently don’t get to, while not teaching other Algebra II content. However, extending validation to data science is more problematic since California has not established standards for the subject. As a result, there are no guidelines for what standards the courses should be teaching.

A flaw in implementation or policy?

In a detailed Nov. 12 letter to UC regents, Jelani Nelson, a professor of electrical engineering and computer sciences at UC Berkeley and a leading critic of weakening math requirements through course substitution, put the blame not on policy changes but on the course-approval process. An Articulation Unit with a small staff, none of whom had a background in STEM, was overwhelmed, he wrote.

Others agree. Rick Ford, professor emeritus and former chair of the department of mathematics at CSU Chico, said that what once was a rigorous process for course approval had become a “horrendous” pro-forma exercise, “primarily reliant on the fidelity of submitters” to follow BOARS guidelines.

The oldest and most popular course, Introduction to Data Science, developed by UCLA statistics professor Robert Gould through funding from the National Science Foundation and used throughout Los Angeles Unified, covered only the statistics standards, not other content in Algebra II. The same was the case with another popular course validated for Algebra II, “Explorations in Data Science,” developed by YouCubed, a Stanford University research center.

Most students who had taken Introduction to Data Science so far had taken Algebra II, so that was not a problem. But those who took it as juniors in lieu of Algebra II might find the course shut doors instead of opening them. Those who might later decide they want to major in biology, computer science, chemistry, neurology or statistics, all of which require passing Calculus, would find themselves struggling for lack of Algebra II; the CSU, meanwhile, no longer offers remediation courses in math.

“You’re asking a 14- or 15-year-old kid to make a lifelong decision in the spring of sophomore year,” said Ford, who chaired the influential Academic Preparation and Education Programs Committee of the CSU academic senate. “Watering down content is creating a multitrack system instead of giving all students the greatest chance of success.”

A backlash followed

News that UC was approving the substitution of data science for third-year Common Core math frustrated the faculty of CSU, which has relied on BOARS and the UC faculty for policy decisions since the two systems agreed to common course requirements, known as A-G, in 2003. Approving coursework that does not meet Common Core standards “brought to light the complete lack of control that the CSU has over the A-G high school requirements that are used for admission to our system,” the CSU senate stated in a January resolution. It called for the academic senates of both systems “to explore establishing joint decision-making” over new courses and changes to the A-G standards.

In July, during the lead-up to the anticipated approval of the final version of the updated California Math Framework by the State Board of Education, tensions came to a head. Thousands of STEM professionals and UC and CSU faculty had signed petitions sharply criticizing earlier drafts of the math guidelines. The proposed framework had discouraged districts from offering Algebra I in eighth grade, compounding the challenge of taking Calculus before high school graduation, while encouraging students to take data science over STEM professions that were described as less interesting and collaborative. One of the five authors of the drafts was Jo Boaler, a prominent professor of mathematics education at the Stanford Graduate School of Education and co-founder of YouCubed.

In the framework it adopted in July, the State Board of Education left it to districts to decide who should take Algebra in the eighth grade. The final version revised language conflating courses in data literacy, which all 21st-century students need, with math-intensive data science courses that, together with Calculus, would prepare students for a data science major in college. It also dropped a new third pathway for data science next to the traditional pathway leading to Calculus.

But the final framework hasn’t fully mollified critics, including Elizabeth Statmore, a math teacher at Lowell High in San Francisco and former software executive.

“By encouraging students to abandon algebra before they’ve solidified their understanding, the (framework) makes it even more difficult for them to get back on that track — even more so now that our community colleges and CSUs have done away with remedial courses,” she wrote in an email.

“The only way we’re going to diversify STEM fields is to keep historically excluded young students on the algebraic thinking pathway just a little bit longer. That will give them the mathematical competencies they will need to make their own decisions about whether or not they want to pursue rigorous quantitative majors and careers.”

Feeling the heat, BOARS hastily reversed positions on July 7 — days before the State Board meeting — revoking validation for meeting Algebra II requirements for all data science courses. And, in a letter to the State Board, BOARS Chair Barbara Knowlton requested wording changes to the proposed framework, which the board did, including deleting a diagram that showed data science as an option to sub for Algebra II.

“The data science courses that have to date been approved by UCOP’s high school articulation team appear not to have been designed as third- or fourth-year mathematics courses,” wrote Knowlton, a professor of psychology at UCLA.

Ten days later, BOARS met again and clarified that there might be some exceptions for granting validation to those data science courses with “a prerequisite mastery of Algebra II content.” It also reiterated that the revocation of A-G credit would exempt students who are currently taking data science courses, with credit for Algebra II, or who had taken data science courses in past years.

“It’s been unfortunate that UC’s process of determining the rules has caused far more confusion than was needed,” said Burdman, the executive director of Just Equations.

The minutes of the meeting revealed that BOARS members professed they didn’t know how the articulation unit in the President’s Office determined if courses could be substituted. Nor could they determine how many data science courses were designated as advanced math. The President’s Office said about 400 data science courses were being taught in California high schools.

The minutes said that BOARS would appoint a working group, including professors of computer science, neuroscience, statistics and math, to clarify how to enforce the July 7 revocation vote, incorporate Algebra II as a course prerequisite, and determine the criteria for course validation.

BOARS, whose meetings are not public, hasn’t disclosed who’s in the group, although it includes no CSU faculty. The group has been meeting ahead of a December deadline so that BOARS can review and take action in January; only then will its recommendations be made public, Knowlton said in an interview.

There’s pressure to complete work in time for the next course cycle for the fall of 2024, starting in February, so that applicants know the new rules. “There is a concern among some people that if we don’t send this message quickly, there will be a proliferation of these courses,” she said.

Knowlton hopes the work group will identify elements of algebra that are critical for student success and evaluate courses to see which ones don’t cover them.

“Some validated courses may leave out really very important foundational aspects of math, and we want to reiterate what those are,” she said. Course developers could choose to add concepts to qualify for validation for Algebra II; that’s what the developers of financial math have done. Or instead, they could offer courses like data science as advanced math in the fourth year of high school, with a prerequisite of Algebra II.

Knowlton said BOARS is committed to equity in college admissions. But the challenge is balancing access and preparation, she said. “We want as much access as possible, yet it has to mean that students are prepared.”

A fresh look at standards

The second committee commissioned will take a broader and longer view of math content. Its members will include math professors from the CSU and community colleges, as well as UC, as a math subcommittee of a joint faculty body, the Intersegmental Committee of Academic Senates.

Kate Stevenson, a math professor at CSU Northridge and member of the new workgroup, said, “It’s not our goal to rewrite the standards, but to emphasize what parts of the standards are really critical to all students’ success and which are critical to life sciences as opposed to engineers, physicists and chemists.”

The committee will probably not recommend dropping math standards but could look at reorganizing or de-emphasizing them, she said.

Few Algebra II teachers find time for statistics standards, she said. “So what would a third year look like with a better balance between statistics and algebraic skills? Could we repeat less of Algebra I if we did the integrated pathway?” she asked. “Or what parts of the algebra curriculum could really belong in Pre-calculus rather than in Algebra II?”

Although it is not the role of the committee, Stevenson said she thinks the Common Core standards deserve revisiting. “It’s not that I don’t like the standards. But it’s very unlikely the mathematics that we agreed to in 2013 is the mathematics that we think students should have in 2030.”

Clarification: The article was updated Dec. 15 with the exact number of data science courses that the Articulation Unit of the UC Office of the President approved for 2022 and 2023; they were fewer than the article had implied."
https://nvidianews.nvidia.com/news/nvidia-hp-supercharge-data-science-generative-ai-workstations,NVIDIA and HP Supercharge Data Science and Generative AI on Workstations,"HP Amplify — NVIDIA and HP Inc. today announced that NVIDIA CUDA-X™ data processing libraries will be integrated with HP AI workstation solutions to turbocharge the data preparation and processing work that forms the foundation of generative AI development.

Built on the NVIDIA CUDA® compute platform, CUDA-X libraries speed data processing for a broad range of data types, including tables, text, images and video. They include the NVIDIA RAPIDS™ cuDF library, which accelerates the work of the nearly 10 million data scientists using pandas software by up to 110x using an NVIDIA RTX™ 6000 Ada Generation GPU instead of a CPU-only system, without requiring any code changes.

RAPIDS cuDF and other NVIDIA software will be available as part of Z by HP AI Studio on HP AI workstations to provide a full-stack development solution that speeds data science workflows.

“Pandas is the essential tool of millions of data scientists processing and preparing data for generative AI,” said Jensen Huang, founder and CEO at NVIDIA. “Accelerating pandas with zero code changes will be a massive step forward. Data scientists can process data in minutes rather than hours, and wrangle orders of magnitude more data to train generative AI models.”

“Data science provides the foundation for AI, and developers need fast access to software and systems to power this critical work,” said Enrique Lores, president and CEO of HP Inc. “With the integration of NVIDIA AI software and accelerated GPU compute, HP AI workstations provide a powerful solution for our customers.”

NVIDIA CUDA-X Speeds Data Science on HP Workstation Solutions

Pandas provides a powerful data structure, called DataFrames, which lets developers easily manipulate, clean and analyze tabular data.

The NVIDIA RAPIDS cuDF library accelerates pandas so that it can run on GPUs with zero code changes, rather than relying on CPUs, which can slow workloads as data size grows. RAPIDS cuDF is compatible with third-party libraries and unifies GPU and CPU workflows so data scientists can develop, test and run models in production seamlessly.

As datasets continue to grow, RTX 6000 Ada Generation GPUs provide 48GB of memory per GPU to process large data science and AI workloads on Z by HP workstations. With up to four RTX 6000 GPUs, the HP Z8 Fury is one of the world’s most powerful workstations for AI creation. The close collaboration between HP and NVIDIA allows data scientists to streamline development by working on local systems to process even large generative AI workloads.

Availability

NVIDIA RAPIDS cuDF for accelerated pandas with zero code changes is expected to be available on HP AI workstations and PCs with NVIDIA RTX and GeForce RTX GPUs this month and on HP AI Studio later this year.

About NVIDIA

Since its founding in 1993, NVIDIA (NASDAQ: NVDA) has been a pioneer in accelerated computing. The company’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, ignited the era of modern AI and is fueling industrial digitalization across markets. NVIDIA is now a full-stack computing infrastructure company with data-center-scale offerings that are reshaping industry. More information at https://nvidianews.nvidia.com/.

Certain statements in this press release including, but not limited to, statements as to: the benefits, impact, and performance of NVIDIA’s products, services, and technologies, including NVIDIA CUDA-X data processing libraries, NVIDIA CUDA, NVIDIA RAPIDS cuDF, NVIDIA RTX 6000 Ada Generation GPU and NVIDIA RTX and GeForce RTX GPUs; the benefits and impact of NVIDIA’s collaboration with HP Inc., and the features and availability of its services and offerings; pandas being the essential tool of millions of data scientists processing and preparing data for generative AI; accelerating pandas with zero code changes being a massive step forward; and the ability of data scientists to process data in minutes rather than hours, and wrangle orders of magnitude more data to train generative AI models are forward-looking statements that are subject to risks and uncertainties that could cause results to be materially different than expectations. Important factors that could cause actual results to differ materially include: global economic conditions; our reliance on third parties to manufacture, assemble, package and test our products; the impact of technological development and competition; development of new products and technologies or enhancements to our existing product and technologies; market acceptance of our products or our partners' products; design, manufacturing or software defects; changes in consumer preferences or demands; changes in industry standards and interfaces; unexpected loss of performance of our products or technologies when integrated into systems; as well as other factors detailed from time to time in the most recent reports NVIDIA files with the Securities and Exchange Commission, or SEC, including, but not limited to, its annual report on Form 10-K and quarterly reports on Form 10-Q. Copies of reports filed with the SEC are posted on the company's website and are available from NVIDIA without charge. These forward-looking statements are not guarantees of future performance and speak only as of the date hereof, and, except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances.

© 2024 NVIDIA Corporation. All rights reserved. NVIDIA, the NVIDIA logo, CUDA-X, CUDA, NVIDIA RTX and RAPIDS are trademarks and/or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated. Features, pricing, availability and specifications are subject to change without notice."
https://news.uams.edu/2024/03/12/uams-to-host-health-care-technology-data-science-summer-camp-for-10th-graders-in-northwest-arkansas/,"UAMS to Host Health Care Technology, Data Science Summer Camp for 10th Graders in Northwest Arkansas","The Arkansas Technology and Data Science in Health & Medicine (AR Tech DaSH) camp will be held June 3-14 on the UAMS Northwest Regional Campus in Fayetteville. Spots are limited to 25 students, and the deadline to register is April 12. Registration is available online at https://medicine.uams.edu/neurobiology/outreach/ar-tech-dash/.

The free, 10-day summer camp incorporates imaging technologies and a data science curriculum focused on health and medicine. Students who complete the AR Tech DaSH camp will be designated as STEM Ambassadors and will be expected to participate in limited community outreach activities during off-school hours during the next academic year. Program staff will also provide a short series of college preparation sessions for the STEM Ambassadors.

The first week of camp is focused on providing students with hands-on activities, including: medical-related skills, anatomical basis of disease, clinician-patient simulations and research on various diseases. Students will learn how to use stethoscopes, blood pressure devices and hand-held ultrasound devices, as well as learning about suturing, taking a patient history, and learning about electroencephalogram (EEG), electromyography (EMG) and electrocardiogram (EKG) procedures. Students will dissect pig hearts, inspect plastinated human cadaveric specimens and embalmed human brains, and learn about computerized tomography (CT) imaging. UAMS medical students will serve as mentors during the first week.

The second week of camp focuses on providing students with an introduction to data science and data analytics using large data sets. Students will learn how infographics are used to inform the public about relevant disease information, explore population bases’ disease statistics, use software to examine summary statistics for large data sets, use the graphical user interface software program Orange for data exploration, learn about summary stats and visualization of data sets, and use Orange to learn about machine learning. University of Arkansas at Fayetteville undergraduate students will serve as mentors during the second week.

“The goal is to get students excited about STEM and data science careers so that the future workforce in these fields better reflects the diverse population in the U.S.,” said camp organizer Kevin D. Phelan, Ph.D., a professor in the Department of Neurobiology and Developmental Sciences in the UAMS College of Medicine. “While there are no specific course requirements for attendance at the camp, we are looking for highly motivated students.”

The UAMS Northwest Regional Campus includes 356 medical, pharmacy, nursing and health professions students, 76 medical and pharmacy residents, and two sports medicine fellows. The campus has 13 clinics including internal and family medicine, a student-led clinic, orthopaedics and sports medicine, behavioral health/psychiatry, geriatrics, genetics counseling, transplant follow-up, and physical, occupational and speech therapy. Faculty conduct research to reduce health disparities."
https://towardsdatascience.com/how-i-became-a-data-scientist-no-cs-degree-no-bootcamp-82c321904986,"How I Became A Data Scientist — No CS Degree, No Bootcamp","How I went from despising coding to being a fully fledged Data Scientist

It’s no lie that being a Data Scientist is arguably (in my humble opinion) one of the coolest jobs out there at the moment, especially with all the hype with AI this year.

In this article, I want to walk you through my whole journey to becoming a Data Scientist, shedding some light and advice on how you can become one yourself!

Of course, there is no best way to become a Data Scientist, all roads lead to Rome. However, I believe there are some strongly recommended tactics to increase your probability of securing that desired first job.

Quick note: My journey was to become a Data Scientist who specializes in Machine Learning. Data science means various things at different companies, so it’s important to understand what you want to be. However, for entry-level jobs, there is much muchness in this (a British saying).

My Background

I come from a heavy, and I mean heavy, maths and science family background.

My mum has a maths degree, my grandparents studied physics, and my great-grandad was an engineer. You can see how my path was already paved.

“Naturally” I gravitated towards physics, mainly from watching The Big Bang Theory when I was 12 years old!

Fortunately, I was reasonably good at maths and physics and achieved 4 A*’s (in maths, further maths, physics, and chemistry), 3 A’s, and 5 B’s. Not bad, but I am clearly not a genius by any stretch of the imagination.

Also, my work ethic was low, and my arrogance was very high. Not a great combo.

Given my grades, I went to study maths, further maths, physics, and chemistry for…"
https://towardsdatascience.com/dont-be-a-data-scientist-if-you-98764ae37bc0,Don’t Be A Data Scientist If You…,"It’s been a while since I closed the Read with Me series. During this time, I celebrated Chinese New Year with my parents in China and had a mid-year performance review with my manager. While I vlogged my experience in China with a video, I haven't yet compiled the feedback I received from my performance review, which would be a great opportunity to share in this article. After all, with a few weeks passing my third-year working anniversary, I have reached a good point to reflect on what I have picked up along the way. Although the title may seem like clickbait, it is a summary of learnings based on my journey so far.

Don’t be a data scientist — if you don’t have a growth mindset

It is very common to have imposter syndrome during early career stages — we often doubt whether we are qualified to be offered this job. It is particularly ubiquitous in the tech industry because it is a fast-growing field. Some algorithms that were used last year might already be outdated. Everyone chases the latest buzzwords, which can create a lot of stress for people looking for a job and those on the job.

There is no way to get rid of this sense of unworthiness without maintaining a growth mindset. A growth mindset believes in one's ability to develop and improve intelligence through hard work, learning, and perseverance with time. It is the opposite of a fixed mindset, which believes abilities and intelligence are innate and unchangeable traits.

Individuals with a growth mindset are more likely to embrace challenges, persist in the face of setbacks, view effort as a path to mastery, and learn from criticism.

A trick I found useful for maintaining a growth mindset is to “fake it until you make it.” I may not be very good at doing A or utilizing B, but I believe I can master it later through self-learning, learning from others, and practice."
https://www.fau.edu/research-admin/cores/biostatistics-core/fl-summer-institute-biostatistics-data-science-program-2024/,Biostatistics Collaborative Core,"Calling all undergraduate students or those recent graduates not currently in graduate programs, it’s time to discover how working with data can change your life through Florida’s Summer Institute in Biostatistics and Data Science Program (SIBDS), funded by the National Institutes of Health.

This opportunity is the key to understanding how data, driven by participants’ responses, can help draw conclusions on everything from why COVID-19 impacts certain populations more than others, to why clinical trials are important and a whole lot more.

When: May 20 to June 28, 2024

Where: FAU’s Boca Raton campus, 777 Glades Road, Boca Raton, FL

Deadline for Applications: March 15, 2024 (Applications will be reviewed continuously starting mid-December 2023, and interviews will begin late January 2024.)

Application Review: Applications will be reviewed continuously starting mid-December 2023 through March 15, 2024.

Interviews: The top 50 applicants ranked by coursework content and geographic region will be asked to provide a 3-minute video (optional) regarding their motivation, academic background and career interests. Applications and videos will be reviewed by members of the Leadership Team who will then decide which students to invite to a 15-minute zoom interview. We expect the last notification of acceptance will be early April, 2024.

NOTE: If you have not been contacted to provide a video or to schedule an interview, you have not been selected but may be put on a waitlist.

Prerequisites:

Undergraduate or have graduated and uncertain about career plans

Commit to a 35-hour week for six weeks (9 a.m. to 5 p.m.)

Administrative: students will have to allocate their own money beforehand for flights/travel, food and entertainment for three weeks; after students arrive on 5/20 and spend a few days in the Program, we will begin processing their stipends which will cover these expenses incurred during the Program. The delay is imposed to maximize the stipend amount distributed to students.

Able to acclimate to a group living situation if living on campus

Students will:

be housed on campus which is covered by grant (unless they live close by)

receive generous stipends for participation in the program (this is not a salary)

learn principles of biostatistics, epidemiology, data science, scientific communication, social determinants of health and career opportunities including working with faculty (see schedule)

be mentored by expert faculty and peers

participate in career workshops with practicing biostatisticians, epidemiologists, data scientists and population health experts

conduct group projects using real data

visit the beach, turtle rehabilitation nature center, Miami Marlins baseball, arcades and museums"
https://www.miamistudent.net/article/2024/02/mcvey-sucks,McVey Data Science building: Modern marvel or futuristic facade?,"“This looks like a community college from the Marvel cinematic universe.”

That was my first thought upon entering Miami University’s new McVey Data Science building. The new building houses the departments of Emerging Technology in Business and Design (ETBD), statistics, computer science and software engineering.

As I continued to explore, the building only continued to weird me out. The overall aesthetic of McVey is different from Miami’s traditional buildings like McGuffey or Upham, which exude a run-down charm that captures a sense of antiquity. The stark contrast between these two worlds at Miami makes me wonder, what is this for? Or better yet, who is this for?

The answer isn’t entirely clear but I know this much: It wasn’t made for students.

As a student in ETBD, it seems fairly odd that a building centered around “innovation” and “accessible design” would be so strange to navigate. While not as notoriously confusing as Bachelor Hall, McVey is one of the most unusually structured buildings I’ve ever been in.

Everything from the stairs to the bizarre classroom placement seems to have been placed with no rhyme or reason. Also, I cannot fathom why the sterile, hospital-esque appearance we’ve seen in the clinical health sciences building is in vogue. Even in the realm of health and science, a space devoid of warmth and character tends to be counterproductive, as it hinders the creative and collaborative aspects that are crucial to each of these fields.

But perhaps there's a method to this madness. As I soon discovered, McVey isn't just a new building; it's a showcase, a beacon of modernity strategically positioned to impress. Its complex layout may not cater to the needs of students trying to find their way to class, but it certainly serves as an ideal backdrop for college tours.

As Miami continues to face financial strain, with majors being axed and university staff being let go, McVey stands as a symbol of prosperity. The building is a statement to prospective students and their parents that despite any financial hardship, Miami remains at the forefront of innovation and progress. It's a carefully constructed facade designed to entice and reassure, ensuring that the allure of the institution remains at full strength — even in times of uncertainty.

McVey may not be the most student-friendly structure, but it undeniably plays a crucial role in marketing the university to potential attendees. The investment seems aimed at attracting not just students, but also more funding, as the university grapples with the harsh realities of post-COVID budget constraints.

However, I also believe the university could have used some of this funding ($20 million) in other areas that directly impact student experience. With these funds, Miami could have improved existing facilities, expanded academic resources or enhanced student services. The decision to allocate substantial funds to a structure that prioritizes aesthetic appeal over the more pressing needs of Miami’s community raises questions about the university’s priorities and whether they truly are with students.

By putting this sum toward the new McVey building, Miami is showing its broader strategy. However, that strategy’s success remains uncertain and unproven.

Camila Lopez-Diaz is a third-year majoring in media and communication with an ETBD minor from Mason, Ohio. They contribute to The Student's opinion section and are actively involved in their studies."
https://www.uncg.edu/news/student-from-egypt-wants-to-use-data-science-to-transform-medicine/,Student from Egypt Wants to Use Data Science to Transform Medicine,"Fulbright student Mostafa ABdelmegeed hopes to pair his undergraduate training in biomedical engineering with a computer science degree from UNCG to advance health care.

With implications for drug discovery, disease diagnosis, personalized treatment, hospital management and more, data science is transforming medicine. Mostafa Abdelmegeed, a UNC Greensboro master’s student in computer science, hopes to marry his undergraduate training in biomedical engineering with skills he gains at UNCG in data science to advance medical care not only in his home country, Egypt, but around the world.

Abdelmegeed is among three Fulbright students currently pursuing degrees at UNCG. The Fulbright Program is a U.S. government-funded international student exchange program, bringing top students from other countries to the U.S. and supporting selected U.S. students to study abroad.

“Fulbright is one of the most respected programs in the world for student and scholar international exchange and engagement, so hosting Fulbright scholars and students on our campus is a great honor for UNCG,” says Maria Anastasiou, UNCG’s associate provost and senior international officer.

Learning from mentors at home and at UNCG

Abdelmegeed says a prescient professor in Egypt pushed him to pursue computer science as a way to improve medicine.

“He had an idea what the future might hold for the biomedical engineering field, and he knew that software is going to be very, very important,” he says. “If you are a biomedical engineer in Egypt now, you basically work either in maintenance or in sales. But my professor armed us with programming skills to make us prepared for the industry in the future.”

Abdelmegeed was attracted to UNCG by the prospect of studying with Minjeong Kim, an assistant professor and associate head of UNCG’s Department of Computer Science.

“She’s working in the medical field with medical doctors, applying computer science, data science, and artificial intelligence to practices in the medical field,” he says. “I was going to ask for her to be my research advisor, but she was actually the one who connected with me first, emailing me and telling me that we needed to meet.”

Making campus connections

Despite a rocky start in getting adjusted to life in Greensboro when he arrived between semesters in the winter of 2022-23, Abdelmegeed found plenty of opportunities to take part in campus events and programs aimed at helping students connect with each other.

“I had this feeling that my language was going to be a barrier to making friends, but that was just in my head,” he says. “One of the main things I’m gaining from this experience is knowing that we all share the same set of emotions and problems as human beings.”

Coming from a global perspective

Abdelmegeed isn’t yet sure what he’ll tackle in his master’s research, but he wants to keep a global perspective when it comes to his future.

“I would really be glad to help contribute to my community back in Egypt, especially in healthcare management, which is a big need,” he says. “But I wouldn’t want to be limited to solving problems in just Egypt.

“As I said earlier, we all share the same set of problems — maybe they come in different shapes or are defined differently — but they are not so different. So my goal is to contribute to solving global problems.”

Learn more about Fulbright opportunities

Students and faculty members interested in pursuing Fulbright opportunities overseas can get help with the application process and with connecting with international partners from UNCG’s International Programs Center. Learn more as the center celebrates UNCG Fulbright recipients and international visitors on March 21 from 4-6 p.m. in the Alexander Room of the Elliott University Center."
https://edsource.org/2024/advanced-math-in-high-school-prepares-students-for-stem-and-data-science-careers/707087,Advanced math in high school prepares students for STEM and data science careers,"California, along with many other states and nations, has experienced a dramatic increase of student interest in data and computer science careers. Along with the broader tech industry, these fields have been undergoing exponential growth in recent years that’s expected to continue as artificial intelligence (AI), computing platforms and their applications continue to reach every aspect of society.

The U.S. Bureau of Labor Statistics projects 36% employment growth for data scientists by 2031. California businesses and other sectors are the top home for many of these high-paying careers.

It’s the responsibility of our state’s academic systems to educate future data-driven leaders in many areas — tech, finance, business, entertainment, biomedicine and health, climate and sustainability, engineering, law, social welfare, public policy, government and education itself, as well as in innovative approaches to the arts and humanities.

A report recently issued by a work group for the University of California’s Board of Admissions and Relations with Schools (BOARS) concluded that the three most popular high school data science courses being offered in the state do not “even come close to meeting the required standard to be a ‘more advanced’ course” and “are not appropriate as recommended 4th year mathematics courses.”

We applaud the faculty and staff, across the UC system, who helped develop this report and its recommendations. And we’re delighted by the quick response from the UC Office of the President this month, which shared the message with high school counselors and advisers, summarizing the report and explaining additional steps that UC is taking to implement the BOARS recommendations for the 2025-26 academic year.

This is a noteworthy example of the California educational system working well and listening to expert feedback in order to best serve its students. Hundreds of university professors in the state and beyond came out against the rapid adoption of high school data science classes that were being offered as a supposed substitute for advanced algebraic math, or Algebra II. While these introductory data science courses may whet high school students’ appetites, if they are taken at the exclusion of Algebra II, students will not be adequately prepared for science and technology majors in college. We must make sure that the prerequisites for admission to our colleges and universities adequately prepare students to pursue careers in these fields.

This could leave the impression that we don’t support data science — which is far from the truth! We believe that data science is an important discipline to study and a career path for making important contributions in our communities and world. Data science can be a route to increased data literacy, enabling students to distinguish between real information and misinformation and the skills to pursue data-driven approaches to whatever their passions and wherever their careers may lead.

Our data science program at UC Berkeley’s College for Computing, Data Science, and Society is the top-ranked program for undergraduate students in the country. We’ve been active in providing curriculum materials to other institutions in California and around the world, including community colleges and universities. We’ve hosted educators across a broad range of academic institutions, including high schools, at an annual conference on data science education for the last six years.

We know from years of study and practice that learning math is cumulative. In order for California students to be adequately prepared for the science and technology majors they may choose to pursue in college — including data and computer science — the advanced math curriculum in high school is essential. While data science and statistics courses have been rapidly added to high school options and are welcome additions, these courses cannot replace the foundational math content found in Algebra II. We also acknowledge, and encourage, innovative curricula aiming to teach Algebra II via the context of data science, as such courses could be appropriate.

We applaud UC and California decision-makers for their recognition that Algebra II is necessary student preparation for the successful completion of college degrees that require a strong grounding in math, including data and computer science. We welcome opportunities to continue this conversation and promote successful outcomes by ensuring students obtain the math knowledge and skills to pursue careers in science and technology.

•••

Jennifer Chayes is dean of the UC Berkeley College of Computing, Data Science, and Society, and professor of electrical engineering and computer sciences, information, mathematics and statistics.

Jelani Nelson is a professor of electrical engineering and computer sciences at UC Berkeley."
https://www.insurancebusinessmag.com/uk/news/claims/ageas-uk-names-new-head-of-claims-data-and-analytics-485477.aspx,Ageas UK names new head of claims data and analytics,"Ageas UK has named Philippa King (pictured above) as its new head of claims data and analytics.

King transitions to the role after a seven-year tenure in the company’s actuarial department, where she was primarily focused on Household Reserving and Analysis.

Additionally, King worked as an actuarial analyst at Lane Clark & Peacock from October 2014 to February 2017, dealing with clients across various sectors including the London Market, personal lines, MDOs, and reinsurers.

Her academic credentials include a PhD from the University of Bristol, where her research involved developing microscopy solutions to study the interaction between nanoparticles and human cells, incorporating extensive coding for data analysis and collection automation.

King’s background includes significant contributions to the Institute and Faculty of Actuaries, where she served on the General Insurance Board from September 2018 to March 2020. In this capacity, she focused on representing and advocating for early career members, promoting their involvement with the Institute.

She also chaired the Flood Working Party from August 2016 to October 2018, collaborating with Flood Re and leading research on insurance issues related to flooding.

In her new position, King will report directly to Stephen Linklater, claims director at Ageas. The role is designed to spearhead the company’s initiatives in data and analytics, incorporating advanced data science techniques and artificial intelligence to refine decision-making processes.

“I’m delighted to welcome Philippa to our team,” Linklater said. “Her depth of knowledge and experience in data science and analytics will be invaluable as we build on our solid foundations, ensuring that our Claims Data Centre of Excellence delivers our ambition to lead the market in data-driven decision making.”

“I am excited to be taking on this new position at Ageas, to further build on our strategic advantage by finding additional ways to leverage the wealth of data that exists within the business,” King said."
https://www.bu.edu/sph/conversations/health-systems/public-health-data-science-the-next-decade/,Public Health Data Science: The Next Decade .,"Melody received her B.S. summa cum laude in applied mathematics-statistics and economics (double major) from Stony Brook University. She received her M.S. in biostatistics from the Harvard T.H. Chan School of Public Health and her Ph.D. from the Department of Biostatistics at Harvard University with minors in theoretical statistics and the social determinants of health disparities. She is the Vice Dean for Research, Professor of Biostatistics, and Director of the Center for Anti-racism, Social Justice & Public Health at the New York University School of Global Public Health. The National Institutes of Health, Robert Wood Johnson Foundation, Verizon Foundation, Long Island Community Foundation, Patient Centered Outcomes Research Institute, and Susan G. Komen for the Cure have funded her work. She has over 100 peer-reviewed journal articles and two books (2018 Routledge/Taylor & Francis Group): 1) Public Health Research Methods for Partnerships and Practice and 2) Biostatistics for Clinical and Public Health Research. She is a Fellow of the American Statistical Association (2021) and the inaugural recipient of the Societal Impact Award from the Caucus for Women in Statistics (2021).

Dr. Goodman is a biostatistician and research methodologist. Her research interest is identifying the origins of health inequities and developing, as necessary, evidence-based primary prevention strategies to reduce these health inequities. Dr. Goodman’s research efforts seek to develop a more rigorous understanding of the social risk factors that contribute to health inequities in urban areas with the goal of developing culturally competent, region-specific solutions through collaborative activities with community members, community-based organizations, faith-based organizations and other community health stakeholders. The purpose of this work is not to continue to identify problems; rather, her work focuses on the development of solutions for improving health in minoritized and medically underserved communities. Dr. Goodman has two primary lines of research: 1) an applied methods track that conducts applied biostatistical and survey research for community-based interventions and health inequities research with a strong focus on measurement; and 2) a community-engaged research track with a focus on enhancing the infrastructure for community-engaged research through academic-community collaborations, as well as the implementation and evaluation of community-engaged research projects to reduce health inequities.

Dr. Hswen is an Assistant Professor in the Department of Epidemiology and Biostatistics and the Bakar Computational Health Institute at the University of California San Francisco and faculty in the joint Computational Precision Health Program with UC Berkeley. Dr. Hswen graduated with a Doctoral Degree in social and computational epidemiology at Harvard University. She is also an Associate Editor for JAMA and JAMA Network, where she leads the strategy for multimedia in AI and medicine. https://jamanetwork.com/channels/ai

Dr. Hswen’s current research is at the intersection between the digital environment and society, where she focuses on using new artificial intelligence and machine learning methods to uncover social patterns of disease and to develop unbiased and fair systems of health.

Dr. Hswen is in the pursuit of detecting uncomfortable truths and seeks to identify authentic attitudes, feelings, and beliefs that influence population behavior and health. Through the collection of unconventional and underground online social networks, Dr. Hswen captures unfiltered conversations to further understand the connections between social experiences and health.

Dr. Hswen’s research has been published in top medical and public health Journals such as, The New England Journal of Medicine, The American Journal of Public Health, Preventive Medicine, Nature npj Digital Medicine, Nature Human Behavior, Nature Scientific Data, JAMA Network Open and JAMA, and her work has been featured in CBC News, Bloomberg News, Nature Magazine, and The Wall Street Journal.

Dr. Hswen has served as Deputy Editor of the Harvard Public Health Review and is on the Editorial Board for Nature Journals Scientific Reports, and Humanities and Social Sciences Communications. Dr Hswen was previously a Kennedy Fellow at Harvard University and a Chateaubriand STEM Fellow, the Embassy of France, and The French National Research Agency for researchers to study the environment and health in France. Before joining UCSF, Dr. Hswen was a visiting Assistant Professor at Aix-Marseille School of Economics (AMSE) where she conducted research in behavioral economics in relation to the promotion of public health interventions. Dr. Hswen is interested in the application of behavioral economic theories to enhance the acceptance and adherence of healthy behaviors and the willingness to share information.

Michael R. Kosorok, PhD, is W. R. Kenan, Jr. Distinguished Professor of Biostatistics and Professor of Statistics and Operations Research at UNC-Chapel Hill.

His research expertise is in biostatistics, data science, machine learning, artificial intelligence and precision medicine, and he has written a major text on the theoretical foundations of these and related areas in biostatistics (Kosorok, 2008, Springer) as well as co-edited (with Erica E. M. Moodie, 2016, ASA-SIAM) a research monograph on dynamic treatment regimes and precision medicine.

He also has expertise in the application of biostatistics and data science to human health research, including cancer, cystic fibrosis, nutrition and chronic back pain, among other disease and health areas. He was also the contact principal investigator on an NCI program project grant (P01 CA142538) for eleven years, which focused on statistical methods for novel cancer clinical trials in precision medicine, including biomarker discovery and dynamic treatment regimes. He has pioneered machine learning and artificial intelligence tools for these and related areas.

Daniela Witten is a professor of Statistics and Biostatistics at University of Washington, and the Dorothy Gilford Endowed Chair in Mathematical Statistics. She develops statistical machine learning methods for high-dimensional data, with a focus on unsupervised learning.

Daniela is the recipient of an NIH Director’s Early Independence Award, a Sloan Research Fellowship, an NSF CAREER Award, and a Simons Investigator Award in Mathematical Modeling of Living Systems. She received the Presidents’ Award from the Committee of Presidents of Statistical Societies (COPSS), awarded annually to a statistician under age 41 in recognition of outstanding contributions to the field of statistics. She also received the Spiegelman Award from the American Public Health Association for a statistician under age 40 who has made outstanding contributions to statistics for public health, and the Leo Breiman Award for contributions to the field of statistical machine learning. She is a Fellow of the American Statistical Association and the Institute for Mathematical Statistics, and an Elected Member of the International Statistical Institute.

Daniela is a co-author (with Gareth James, Trevor Hastie, and Rob Tibshirani) of the very popular textbook “Introduction to Statistical Learning”. She has served as an Associate Editor for Biometrika, Journal of Computational and Graphical Statistics, and Journal of the American Statistical Association, and as an Action Editor for Journal of Machine Learning Research. She currently serves as Joint Editor of Journal of the Royal Statistical Society, Series B.

Daniela completed a BS in Math and Biology with Honors and Distinction at Stanford University in 2005, and a PhD in Statistics at Stanford University in 2010."
https://www.unc.edu/posts/2024/03/01/undergraduate-data-science-degree-programs-approved/,Undergraduate data science degree programs approved,"UNC-Chapel Hill will offer two new undergraduate degree programs in data science with classes starting fall 2024. The Bachelor of Science in data science degree will be in the School of Data Science and Society, while the Bachelor of Arts in data science degree will be in the College of Arts and Sciences.

The new degree programs were approved at the Feb. 29 UNC System Board of Governors meeting. Application submissions open March 1 for the B.S. program for the fall 2024 semester. The B.A. program does not require a formal application, but students are asked to complete a letter of interest.

This new B.S. degree is the first undergraduate degree for the School of Data Science and Society. This new school on the UNC-Chapel Hill campus introduced its first online graduate program last year. The Master of Applied Data Science gives students a holistic understanding of the data life cycle, preparing them to effectively — and ethically — collect, process, manage and analyze data.

The B.S. degree requires 60 to 62 credit hours and focuses on the rigorous quantitative foundations of data science; advanced computational, statistical and mathematical principles of data science; and interdisciplinary coursework.

“We are proud to launch the School of Data Science and Society’s first undergraduate degree,” said Stan Ahalt, dean of the School of Data Science and Society. “This new program will offer students an opportunity to dive into the depths of data science and look at how this science can be applied to different disciplines in order to solve our state’s greatest challenges. Data science is part of almost everything in modern society, and we hope to produce data scientists that will excel and continue to contribute to our world well into the future.”

The B.A. degree program will be based in the College of Arts and Sciences’ department of statistics and operations research. This degree emphasizes applied data science training for students pursuing a variety of career paths. It is well suited for students who want to double major or whose interests lie in fields as diverse as earth science, public policy or political science, geospatial analysis, or bioinformatics.

“When I meet with industry leaders, I hear again and again how they want to hire graduates with a firm grounding in the liberal arts but also the ability to understand, apply and interpret data,” said Jim White, Craver Family Dean of the College of Arts and Sciences. “Picture a political scientist analyzing polling data or a linguist working on large language systems for AI — these are the types of jobs our B.A. in data science will help our students prepare for.”"
https://www.utsa.edu/today/2024/01/story/2024-draper-competition.html,UTSA School of Data Science opens Draper Competition to participants across North America,"JANUARY 25, 2024 — The UTSA Draper Data Science Business Plan Competition is growing. In response to this growing demand, this spring’s second annual competition will include participants from across North America.

The final round of the competition will take place on Friday, April 12, at the San Pedro I Weston Conference Center in San Antonio.

After the success of UTSA’s first Draper Competition in 2023, universities outside the United States, including Mexico’s flagship university Tecnológico de Monterrey, contacted the UTSA School of Data Science (SDS) to express an interest in sending competitors to San Antonio, according to Amanda Mukengeshayi Brown, SDS manager of strategic initiatives.

The expansion of the competition comes on the heels of UTSA’s historic dual degree program with Tec de Monterrey and serves as a further example of UTSA’s commitment to making higher education more accessible and preparing students to become leaders on a global level.

“In that spirit, we are targeting all of North America this year, with the hope that we can further scale up international participation over time,” Brown added.

The UTSA Draper Competition was established with a $1 million donation from Timothy Draper, a third-generation venture capitalist and founder of Draper University, and his wife, Melissa Parker Draper. UTSA’s competition is one of a few in the U.S. with a sole focus on entrepreneurship in data science.

The 2023 competition culminated in four winning teams — three of which included UTSA students. All four received prizes totaling $75,000 for their innovative use of data science in business.

Purposeful adjustments are being made to this year’s Draper Data Science Business Plan Competition to align with UTSA’s commitment to experiential learning. These modifications aim to provide additional support while fostering a dynamic learning environment that is strategically equipping students for their careers.

In addition to expanding the applicant pool, Brown says the competition will grow from its 2023 format by expanding the final round into a half-day event, instead of two hours. This change offers finalists two important opportunities. The first is increased rehearsal time and a chance to get a feel for the stage before making their pitch to the panel. Secondly, and perhaps more importantly, are the networking opportunities the new set-up provides.

“We are not simply awarding prizes,” Brown said. “We believe in the importance of building genuine connections and relationships that can help further the data-driven business ideas that competitors are working on.”

In another twist for 2024, standout competitors who are not selected for the final round may still have a chance to share their ideas and practice their pitches in an opening poster session. This select group of participants will be chosen by the competition steering committee."
https://www.susqu.edu/live/news/1719-susquehanna-launches-data-science-major,Susquehanna launches data science major,"March 21, 2024

Susquehanna University will offer a data science major beginning in fall 2024. Students in data science will dive into algorithms, machine learning and advanced computational techniques in preparation for a variety of research fields.

“Data science is not just about data — it’s about extracting meaning from data and using it to make informed decisions,” said Jeffrey Graham, department head and associate professor of math and computer science at Susquehanna. “A data science major equips students with the skills to navigate through vast amounts of information, uncover patterns and derive actionable insights.”

The data science major and an option for a minor are offered by Susquehanna’s School of Natural and Social Sciences. In addition to taking courses in data structures, data mining, algorithms, machine learning, calculus, statistical methods, linear algebra and discrete structures, students will also tailor their studies with a diverse range of courses in other disciplines.

Students in Susquehanna’s data science program will learn how to apply relevant data analysis techniques such as data cleaning and statistical modeling, utilize programming languages and tools and effectively communicate to diverse stakeholders, including nontechnical audiences.

“Our world is increasingly being driven by data so organizations are in need of employees who can look at a set of data points and offer sound advice,” Graham said.

“Susquehanna’s data science program will give students the professional skills they need to pursue their career goals with the foundation of a liberal arts education, which teaches students how to be successful as communicators and lifelong learners in a rapidly evolving global economy.”"
https://www.washingtonpost.com/education/2024/03/02/data-science-algebra-ii-alternative-california-debate/,Data science under fire: What math do high-schoolers really need?,"correction

A previous version of this article quoted the founder of Just Equations as saying data showed many high school students who take Algebra II struggle in the course. The data showed they learned little, she said. The article also misstated that data science had been approved as an equivalent to an Advanced Placement statistics course. It was approved as equivalent to general statistics courses. The article also stated that Jelani Nelson of the University of California at Berkeley said geometry knowledge is necessary to help students succeed in college art classes. He said art draws on geometry, not that knowledge of it is critical to success in art in college. The article has been corrected.

OXNARD, Calif. — On a Wednesday morning in December, Dale Perizzolo’s math class at Adolfo Camarillo High School is anything but quiet. Students chat about the data analysis they’ve performed on their cellphone usage over a week, while Perizzolo walks around the room fielding their questions.

The students came up with the project themselves and designed a Google form to track their phone time, including which apps they used most. They also determined the research questions they’d ask regarding the data — such as whether social media use during class reduces comprehension and retention.

“It’s more real-world math,” said Nicolas Garcia, a senior in Perizzolo’s class. “We have the chance and freedom to choose what we’re doing our data sets on, and he teaches us how we’re going to work and complement it [in] our daily lives.”

Advertisement

Perizzolo is one of eight math teachers of an increasingly popular data science course offered at most schools in the Oxnard Union High School district, an economically diverse school system northwest of Los Angeles, where 80 percent of students identify as Hispanic. The district rolled out the class in fall 2020 in an attempt to offer an alternative math course to students who might struggle in traditional junior and senior math courses such as algebra II, pre-calculus and calculus.

California has been at the center of a heated debate over what math knowledge students really need to succeed in college and careers. With math scores falling nationwide, some educators have argued that the standard algebra-intensive math pathway needs a revamp, both to engage more students and to help them develop relevant skills in a world increasingly reliant on data. At least 17 states now offer data science — an interdisciplinary field that combines computer programming, math and statistics — as a high school math option, according to the group Data Science for Everyone. Two states, Oregon and Ohio, offer it as an alternative to algebra II.

But other math educators have decried a move away from algebra II, which they argue remains core to math instruction and necessary for students to succeed in STEM careers and beyond. In California, that disagreement erupted in October 2020, after the group that sets admission requirements for the state’s public university system (known as A-G) announced it would allow students to substitute data science for algebra II to help more students qualify for college. Math professors, advocates and even some high school educators argued that the state was watering down standards and setting students up for failure in college.

Advertisement

Then, in July, the group reversed its earlier decision, and in February it released new recommendations saying that data science courses (and even long-approved statistics classes, to the surprise of some experts) cannot be used as an alternative to algebra II. It remains unclear how the decision will reshape college admissions; additional guidance is expected in May.

In Oxnard, educators say they have been left in the dark about how these decisions affect course offerings for their students. They argue that, more than ever, students need real-world math to help them succeed in the subject. They say the expansion of data science — some 500 Oxnard district students have taken it to date — has reoriented teachers’ and students’ approach to math.

“Data science is changing their view of math,” said Jay Sorensen, Oxnard’s educational technology coordinator, who helped design the class. “It changed their perspective or their view of what math is, because they maybe didn’t enjoy math or were frustrated with math or hated math before.”

Recovery in math, reading scores is underway — but slowly

Many students in Oxnard stop taking any math after junior year of high school, and the district has been trying to fix this for almost a decade. In 2015, Tom McCoy, then the assistant superintendent of education services, jokingly asked Sonny Sajor, the district’s math instructional specialist, “Can I get some math for poets?”

Advertisement

That started a conversation on what math classes might benefit high-schoolers who struggle in the subject and who don’t plan to pursue science or math fields or attend a four-year college, said McCoy, who became Oxnard’s superintendent in 2020.

Inspired by a UCLA seminar they attended on data science for high-schoolers, Sajor and Sorensen designed the new course and partnered on it with the educational technology vendor Bootstrap World. Oxnard’s first data science classes generated enough student interest that the district expanded the course to more schools, and its popularity has continued to grow.

But not all educators in Oxnard were on board. Some math teachers, for example, questioned whether the data science course — which had been approved as an advanced statistics course equivalent to general statistics courses — was really equivalent to an advanced math course.

Advertisement

Oxnard Union’s data science teachers, though, say they’ve seen benefits.

“It’s giving kids exposure to really practical math, and it’s also creative,” said Allison Ottie Halstead, who teaches data science along with honors pre-calculus and Advanced Placement Statistics at Rancho Campana High School.

Most of Oxnard’s data science classes enroll a mix of students who are using the course to fulfill their required third year of math and those who have already taken algebra II. According to district data, students who took data science as juniors in the 2022-2023 academic year were more likely to sign up for a math class their senior year. Only about 10 percent of those students enrolled in math III, an integrated math class that’s equivalent to algebra II; larger shares enrolled in statistics, math for finance literacy and other classes.

Nizcialey Dimapilis, a senior at Channel Islands High School, said she is taking data science and AP Calculus simultaneously to prepare for computer engineering courses in college. “I thought this class would be more useful because it involves coding, which is completely kind of new to me,” Dimapilis said.

Advertisement

Some students said it helped them grasp math concepts they’d been introduced to in past classes. Jaya Richardson, a senior taking data science at Oxnard High, said she doesn’t consider herself “a math person.” As a junior, she took math III and didn’t get the grade she wanted.

Instead of having her repeat the class for a higher grade, her counselor suggested she take data science. She said she’s happy with the decision and plans to pursue a degree in biology at a University of California or California State University System campus.

“It’s still stressful. It’s still hard, but it’s more beneficial,” she said of the data science class. “We still do math in here, but it breaks it down in a way where I’m able to understand it.”

Math scores for U.S. students hit all-time low on international exam

But many STEM professors are worried about the consequences of experiments like Oxnard’s.

Advertisement

Jelani Nelson, professor of electrical engineering and computer sciences at the University of California at Berkeley, argues that most data science courses offered in high schools are low-level and don’t comply with UC and CSU college admission criteria that alternatives to algebra II build on students’ earlier math coursework.

Without an understanding of what he calls “foundational math” — algebra I, geometry and algebra II — he says, students won’t succeed in college courses in computer science, math, technology and economics. Even art can draw on foundational math, he noted. Perspective drawing, for example, uses geometry.

Introductory college classes in data science also build on those math concepts, he said, so students who have taken data science in high school but not algebra II are unlikely to succeed in the subject.

Advertisement

Adrian Mims, founder of the Calculus Project, a nonprofit that works to increase the number of Black, Hispanic, Indigenous and low-income students in advanced mathematics, said swapping out data science for algebra II has unintended consequences.

Standardized tests including the SAT and college math placement exams cover algebra II, he said. He said he worries that students who opt for data science instead will be stuck in remedial math courses “not because they can’t learn the math, but because they made decisions in high school that deprive them of the opportunity to learn the content for them to do well.”

Rather than replacing algebra II, data science concepts could be infused into algebra II courses, and data science courses that include some algebra II and geometry could be offered as electives to students who have already completed algebra II, Nelson and others said.

Advertisement

Others, though, don’t share those concerns. Pamela Burdman, founder of Just Equations, a nonprofit rethinking the role of traditional math pathways in high school, points to data showing that many students who take algebra II in high school learn little. She said emerging research suggests that courses like data science could have “more potential for bringing students into STEM” than the traditional preparatory math courses.

Despite the recent focus on the UC admissions requirements, only about 400 applicants out of roughly 206,000 in the last admissions cycle listed that they’d taken data science or statistics in lieu of algebra II, she noted.

“I do worry that the debate over data science versus algebra II is sort of a distraction,” she said.

Inside the new middle school math crisis

Teachers and school guidance counselors in Oxnard are wary of wading into the math debate with their counterparts in higher education. But they aren’t afraid to voice their discontent with what they view as a disconnect between students’ needs and higher education.

Daniel Cook, a learning, instruction and technology coach at Camarillo High, said that students come into high school behind in math and that the pandemic only made the problem worse. Yet colleges still expect students to have mastered algebra II concepts and shut the door on those who haven’t.

Cook said that at Camarillo High, some 44 percent of sophomores are not on track to be A-G-eligible because of math, so they’re getting a message early on that they’re not college material. By senior year, the figure is about 25 percent.

The traditional math curriculum “is essentially focused on preparing students for STEM pathways in college,” Cook said. The July vote and subsequent policy recommendations to nix data science as an option for college applicants, he said, is a “slap in the face to students who have interests that are not STEM-related.”

Educators in Oxnard are trying to cope with the uncertainty created by the state’s higher education system. With data science no longer counting toward college admission, Oxnard will eventually limit the course to students who have already taken, or are taking, algebra II, according to Sajor. The district is also considering a pilot course that would integrate algebra II and data science.

Such a course might ultimately be better for the district, Sajor said, because it would help more students engage with algebra II concepts while also introducing them to coding and data science.

Still, data science students such as Emma-Dai Valenzuela say the class in its current form has been invaluable. A senior at Pacifica High School, Valenzuela said the course has allowed her to fulfill her graduation requirements while actually succeeding in a math class.

She transferred into the class after struggling in math III, the integrated algebra II course, she said. Valenzuela plans to join the Navy before attending college and said her recruiters told her this course would offer a basic understanding of coding and math she can build on later.

“This is more hands-on,” she said. “We’re constantly doing new things.”

This story about data science was produced by the Hechinger Report, a nonprofit, independent news organization focused on inequality and innovation in education. Sign up for the Hechinger newsletter."
https://www.bucknell.edu/news/dominguez-center-data-science-open-bucknell-university,Dominguez Center for Data Science to Open at Bucknell University,"Harnessing the power of data is no longer a specialized skill set mastered by few. It's a necessary and critical literacy marker for individuals in nearly every profession.

Thanks to a founding gift from Michael J. Dominguez '91, Bucknell University is expanding its efforts to educate students across disciplines in the field of data science. The new Dominguez Center for Data Science will launch in 2024, and with it, programming that leverages curriculum, research and the expertise of faculty from all three of Bucknell's colleges.

The Dominguez Center for Data Science will prepare Bucknell students to solve global problems in a digital age through hands-on learning experiences that prepare them for 21st century careers. The center will also emphasize responsible data use, ensuring students understand how to ethically execute data-driven decision-making.

""Data will be an increasingly important component of any field students pursue,"" Dominguez says. ""It serves as the foundation for decision-making, drives innovation, and is critical to the future of any business or initiative.""

The launch of the new center is a tangible indicator of progress toward The Plan for Bucknell 2025, which identifies the cultivation of academic excellence across the institution as its first strategic commitment. ""The Dominguez Center for Data Science will provide students opportunities to hone their data literacy while developing skills that will carry them through the future,"" says University President John Bravman. ""We're exceedingly grateful for Michael's commitment to the founding of this center, which will become a distinctive and defining element of the Bucknell experience.""

The center's vision emerged through interdisciplinary collaboration among faculty from across the University: From the Freeman College of Management, Professor Matthew Bailey, analytics & operations management; from the College of Arts & Sciences, Professor Peter Brooksbank, mathematics; and from the College of Engineering, Professor Brian King, computer science. Through a benchmarking study of data science programs at other institutions, the team found Bucknell to be well-positioned for distinction in the field because of its three-college structure.

The University emphasizes the practical application of data through programs that apply data science in innovative ways, pushing beyond the assumed boundaries of data as a discipline. Samuel Gutekunst, the John D. and Catherine T. MacArthur Assistant Professor of Data Science, frequently partners with students and faculty colleagues from across the University on data-centric initiatives and anticipates an even broader integration of data into various disciplines through the center. ""Bucknell students have already done incredible work in data science — from academic research, to applied analytics, to solving real big-data questions for companies,"" Gutekunst says. ""This new center will open up more opportunities for cross-college collaboration on real, impactful projects.""

The center will serve as a central hub for offices that facilitate and enhance data-centric academic work, and will become a sought-after resource for the entire Bucknell community.

""Numbers are only a small part of the story of working with data,"" says Margot Vigeant, interim provost. ""Turning numerical values into meaning is at the heart of data science, and why it is absolutely critical that this center sits at the intersection of all three colleges and multiple disciplines. It is important for every member of our academic community to be able to thoughtfully process, consider and engage with data.""

Recruitment for a center director will begin at the start of the spring semester. As the critical first hire, the director will elevate cross-college programming and research, expand existing expertise in data visualization for multidisciplinary initiatives, create pathways for community engagement, and develop a summer bridge program surrounding data science challenges to attract students from under-resourced schools."
https://www.simplilearn.com/data-analytics-books-article,Best Data Analytics Books 2024: Must-Read Books,"Top Data Analytics Books of 2024

Books for data analysts are great ways for professionals who aspire to work in data analysis to learn about subjects, developments, and useful skills.

Here is a collection of the best data analytics books, from fundamentals to specifics, such as big data, AI, statistical programming languages, etc.

Storytelling with Data: A Data Visualization Guide for Business Professionals - Cole Nussbaum Knaflic, 2015

Cole Nussbaummer Knaflic, the CEO and founder of Storytelling With Data, wrote this remarkable data analyst book.

SWD is a book that emphasizes the importance of data storytelling in data analysis. Instead of just placing charts on report pages, data analysts should carefully choose the right chart and create a compelling story to engage their audience.

This piece is one of the must-read data analytics books for beginners, and it provides six useful steps for data storytelling.

Big Data: A Revolution That Will Transform How We Live, Work, and Think - Viktor Mayer-Schönberger, 2013

Viktor Mayer and Schönberger, domain experts, discuss the impact of big data on our world. Their book also focuses on the potential positive or negative changes in big data.

This book offers a good understanding of data analytics and its impact on various industries. It prepares readers for the big data revolution that is about to come. The book digs into the broader consequences of big data on societal aspects. It highlights the potential risks associated with digital technology. The book also provides a theoretical overview of big data's importance in various life stages.

Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython - Wes McKinney, 2011

The author of the Pandas library's comprehensive book Python for Data Analysis teaches learners the fundamentals of using Python for data manipulation, processing, cleaning, and crunching. Real-world case studies are covered, along with an introduction to data science tools and instructions on how to use Matplotlib to build useful visualizations. Other techniques include loading, cleaning, manipulating, combining, and reshaping data.

Naked Statistics: Stripping the Dread from the Data - Charles Wheelan, 2012

The field of statistics is rapidly evolving into a ""sexy"" discipline, with applications in various fields such as politics, game shows, and medical research. Charles Wheelan's book, Naked Statistics, focuses on the intuition behind statistical analysis, explaining key concepts like inference, correlation, and regression analysis. The book also highlights how biased parties can manipulate data and how creative researchers use natural experiment data to tackle complex questions. It is a valuable resource for those who missed Stats 101.

Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking - Tom Fawcett, 2013

This book, written by Foster Provost and Tom Fawcett, introduces the fundamental concepts of data science and data-analytic thinking. This data analytics book enables readers to extract valuable knowledge and business value from data. It educates readers on how to use data science techniques to help business decision-making and how to think analytically about data.

Business UnIntelligence: Insight and Innovation Beyond Analytics and Big Data - Barry Devlin, 2013

This book examines business intelligence's past, present, and future while stressing the advantages and disadvantages of conventional methods. Dr. Devlin discusses how big data and analytics have revolutionized business intelligence today, highlighting tried-and-true methods and providing insights into how people, processes, and information interact to create competitive advantage and propel company success. Additionally, he suggests new frameworks and models for companies to enhance their future.

The Hundred-page Machine Learning Book - Andriy Burkov, 2019

This book offers a succinct introduction to machine learning in just 140 pages, making it appropriate for readers with no prior programming or statistical knowledge. Neural networks, cluster analysis, and supervised and unsupervised learning are among the important ideas covered. The book is short enough to read in one sitting, and the companion wiki provides resources and suggestions for further reading.

Artificial Intelligence: A Guide for Thinking Humans - Melanie Mitchell, 2019

Melanie Mitchell, a computer scientist, wrote this book to help us explore the historical background and people behind artificial intelligence. The book specifically draws attention to difficult ideas like neural networks, computer vision models, and NLP. It helps readers who do not require a thorough understanding of AI understand how AI affects data analytics.

Developing Analytic Talent: Becoming a Data Scientist - Vincent Granville, 2014

With his background in big data, business analytics, and predictive modeling, Granville provides helpful information in his handbook on data science and data scientists. The book discusses the significance of key information for data scientists in big data organizations. It is divided into three sections that address technological applications, case studies, tutorials, career opportunities, and the relationship between data science and other fields.

Educating decision-makers about specialized solutions and their applications also aids in the development of stronger analytics teams. Granville's more than two decades of industrial experience offer quick suggestions for those wishing to build a data science firm.

Learning R: A Step-by-Step Function Guide to Data Analysis - Richard Cotton, 2013

This book offers a step-by-step introduction to the R language, making it an invaluable tool for non-technical learners. It covers environments, looping constructions, packages, and data structures. The book then covers the data analysis processes, including loading, cleaning, and converting data. The second section is a priceless resource for individuals unfamiliar with programming languages, as it offers further insight into exploratory analysis and modeling.

Weapons of Math Destruction - Cathy O'Neil, 2016

Cathy O'Neil's book on data bias highlights the importance of using big data responsibly. It also discusses the consequences of machines making decisions about our lives and how algorithms often reinforce discrimination. Despite disagreements, the insights are crucial for those new to data science, ensuring future data is used for the benefit of all, not just the privileged.

Data Science and Big Data Analytics: Discovering, Analyzing, Visualizing and Presenting Data, 2014

Big Data analytics offers deeper insights and supports businesses by integrating real-time data feeds and queries. This book, by EMC Education Services, introduces key techniques and tools for Big Data analytics, guiding readers from basic methods to advanced methods like classification, regression analysis, clustering time series, and text analysis. It is suitable for business analysts, database professionals, and college graduates interested in data science or data analysis as a career field.

Too Big to Ignore: The Business Case for Big Data - Phil Simon, 2013

Phil Simon's book Too Big to Ignore: The Business Case for Big Data explores businesses' and local governments' use of big data. It features case studies and quotes from professionals worldwide, providing valuable insights on turning data into intelligence and making it actionable.

The Elements of Statistical Learning - Trevor Hastie, 2001

This book thoroughly introduces statistical ideas in various industries, including marketing, biology, finance, and medicine. It employs color pictures for examples and prioritizes concepts over mathematical formulas. Classification trees, neural networks, support vector machines, boosting, and other subjects related to supervised and unsupervised learning are covered in this book, which is an invaluable tool for statisticians and data mining players.

Numsense! Data Science for the Layman: No Math Added - Kenneth Soo, 2017

This book offers a comprehensive introduction to data science, suitable for non-technical individuals. It provides clear language and visual explanations for algorithms, avoiding complex math. It is valuable for data scientists and beginners as a refresher for communicating work to business partners. The book's algorithm explanations are useful for field communication.

Head First Data Analysis: A Learner's Guide to Big Numbers, Statistics, and Good Decisions - Michael Milton, 2009

Head First Data Analysis is a book that teaches how to manage and analyze various types of data, including product development, marketing, sales, and entrepreneurship. It provides a unique approach to learning how to convert raw data into a vital business tool. The book uses the latest research in cognitive science and learning theory to create a visually rich format that caters to the brain's workings, making it an efficient way to convert raw data into a valuable business tool.

SQL QuickStart Guide: The Simplified Beginner's Guide to Managing, Analyzing, and Manipulating Data With SQL - Walter Shields, 2015

This book includes a thorough introduction to Structured Query Language (SQL), digital resources such as workbooks and reference guides, and an example database and SQL browser software. It addresses subjects like relational database communication, database structures, important SQL queries, and marketing SQL expertise to prospective employers. The book also offers suggestions on marketing newly acquired SQL abilities to possible employers.

Microsoft Excel Data Analysis and Business Modeling - Wayne L. Winston, 2004

Wayne Winston, a renowned consultant and business professor, has been teaching clients in the corporate sector and MBA students how to use Microsoft Excel for data analysis, modeling, and decision-making for over a decade. This practical guide offers real-world examples and learn-by-doing exercises to enhance data analysis and modeling expertise. The book is available as a searchable eBook and CD file for download."
https://willamette.edu/news/library/2024/02/data-science-fortune.html,Fortune names Willamette on ‘Best Master’s in Data Science Programs in 2024’ list,"Willamette University is the only school in Oregon and the Pacific Northwest named to Fortune Magazine’s “Best Master’s in Data Science Programs in 2024.” The program is ranked #22 nationally, up six places since 2022.

Fortune evaluated programs based on factors such as admissions criteria, retention, and graduation rates. Data science is the third-fastest growing occupation in the United States, according to the U.S. Bureau of Labor Statistics."
https://www.mtsu.edu/program/data-science-m-s/,"Data Science, , M.S.","Data Science uses tools of data visualization, predictive analytics, and web applications to communicate complex data, discover information, aid businesses in decision-making, and add the value of business. Data science is widely used in modern industrial production, business, and social media, and is making an increasing impact on human life.

Data scientist is ranked as one of the best careers. The MTSU Data Science Master’s Program aims to prepare students to be competitive on the job market. The courses will equip students with advanced data science skills including, but not limited to, computer programing, data visualization and manipulation, predictive modeling, business analytics and communications.

The curriculum provides both online courses and on-campus courses. Whether you are a full-time student or a working professional, you will be able to find a suitable path toward a master’s degree. Please contact the program director, Dr. Qiang Wu ([email protected]), to discuss a course plan to maximize or minimize the number of online courses according to your needs and preferences.

Research

Students in Data Science programs at MTSU have the added opportunity to work with faculty from across the university on research and data contracts. Through the Data Science Institute, the following types of projects are possible:

Data projects that help nonprofits. An opportunity to sharpen skills and use data for good.

Data projects with companies. These can be compensated opportunities for students to work on real projects for businesses that need help analyzing their data.

Data Dives (hackathons), which are events that allow all students to participate in a hackathon style event where data from a nonprofit or company is presented and then students have 24 to 36 hours to analyze the data to solve specific objectives.

Research projects with faculty. Either funded or unfunded research that is data-driven in any discipline.

Related links"
https://towardsdatascience.com/how-to-make-yourself-more-layoff-proof-as-a-data-scientist-0f92d75ac9f0,How to Make Yourself More Layoff-Proof as a Data Scientist,"Just when we thought that life is going back to normal after the pandemic outbreak, a wave of tech layoff caught all of us tech workers by surprise. In 2023, more than 240K tech workers were laid off across more than 1,000 companies; the most recent layoff at Google and Discord indicates that it’s continuing in 2024. Both my current company and my pervious company had more than one round of layoff during the last year, with some of my friends impacted.

Even though this is the not the first time layoffs happened in the industry, the cuts were deeper than in the past. Past layoffs had often focused on functions such as Sales and Recruiting that were immediately affected by slowdowns in the business and hiring. This time, however, the impact was across the board including technical functions like software engineers and data scientists.

It’s human nature wanting to distill patterns and learnings from things, especially as a data scientist (after all, that’s one of the key aspects of your job). So like a good data scientist, I sat down at the beginning of the year to conduct a “post mortem”.

While it’s hard to predict beforehand which team/who will be impacted by a layoff (unless you are one of the decision makers), I think as a data scientist, there are things you can do to make yourself more “layoff-proof”. And I will share a few here:

Stay up to date about the company and org’s strategic direction

Why? When it comes to layoffs, the decision about which teams/individuals to let go is usually highly dependent on the company’s strategy and prioritization at the moment. For example, if a company for several quarters has been trying to make dashboard building and metric reporting more self-serviceable, when a round of layoff comes, any team that focuses on dashboard making and metric reporting will be considered.

Remember, things don’t happen overnight; there are signs that you can take as a heads up. Priority shifts usually can’t be implemented overnight or even in one quarter. In the example above, before letting go of the whole team of DS who are building dashboards/reporting…"
https://www.vanderbilt.edu/undergrad-datascience/2024/03/14/student-spotlight-peyton-hudson-26/,Student Spotlight: Peyton Hudson ’26,"Today we are highlighting Peyton Hudson (’26) and her experience with Vanderbilt’s Data Science Minor!

“My experience with the Data Science Minor program began my second semester of freshman year. I came to Vanderbilt with no experience in coding or data analytics, but I was excited to learn. All of the courses have given me a better understanding of technology and taught me how to utilize data in a variety of fields. I am also involved with the Data Science Minor because I work as a grader for DS 1000. I decided to become a grader for this class because of how much I enjoyed taking it myself. By the end of the course, you can use multiple data science techniques and skills in R to create powerful visualizations. Not to mention, Professor Bisbee does an amazing job teaching the course, and I couldn’t ask for a better professor to work with. Whenever someone asks me about my studies at Vanderbilt, I make sure to talk about the Data Science Minor because I truly believe it is one of the best programs we offer. I encourage everyone to give it a try regardless of their background or prior experience. You never know; you might even discover a newfound passion for data science!”"
https://www.luc.edu/parkinson/about/newsevents/archive/humanizingdatascience.shtml,Humanizing Data Science: Loyola University Chicago,"Humanizing Data Science

Daniel P. Smith

When Nicholas Soulakis was appointed director of Loyola University Chicago’s Center for Health Outcomes and Informatics Research (CHOIR) in October 2022, he knew he wanted to host a lively event to champion data science among both University stakeholders as well as prospective Chicago area collaborators.

Eight months later, CHOIR and Loyola’s Parkinson School of Health Sciences and Public Health hosted Salon 2023: Data Science for Social Thinkers at MATTER, a healthcare incubator located in downtown Chicago. Loyola faculty, staff, and students and community partners packed the day-long event last June, a gathering carefully designed to promote informatics and data-driven research in an accessible way.

“For us, having a room full of data scientists was a great success, but having a room full of people with no exposure to data science and informatics was even better,” Soulakis says.

Now, Soulakis and CHOIR are aiming for an even better repeat performance with Salon 2024 on May 16.

‘Telling the truth’

Returning to MATTER, an ideal meeting spot given its centralized location and, even more, the innovative energy bubbling throughout its Merchandise Mart headquarters, Salon 2024 looks to empower data-driven decision-making through first-person point of views, impactful narratives, and energized personal conversations.

“We want to create an opportunity for people to look inside, ask questions, and come out better,” Soulakis says.

While the overall Salon theme of Data Science for Social Thinkers endures, Soulakis says “the social part will change each year.” For 2024, the event’s social theme is “Money on My Mind,” prompting attendees to address a “third-rail issue” rarely addressed in public health and social services training. As leaders in public health and community services, however, Soulakis reminds us that finances loom large in decisions, which elevates the importance of data and informatics to help optimize results.

“If the Salon is about anything, it’s about telling the truth,” Soulakis says. “If you don’t have the dollars column in your dataset or you do have that column and you treat it just like any other column or even if it’s the only column in your dataset, then this event will deliver a broader understanding of the dynamics of the dollars in what you do.”

Salon 2024 will feature speakers who make data-driven decisions in their daily lives as well as those who specialize in data science work, such as new Parkinson faculty member Ifeoma Ozodiegwu, an epidemiologist who models malaria interventions for healthcare leaders in Nigeria. Other speakers include the CEO of an insurance company, the chief executive of a leading investment company in independent primary care, and the vice president of analytics for New York City’s public hospitals.

Accessibility, connections, and creativity

Ditching technical barriers and scholarly jargon, Salon speakers relay who they are, what they do, and how they make challenging decisions in their respective roles, including how data influences action. Thereafter, speakers participate in panel discussions or connect one-on-one with attendees to share additional insight.

“A speaker’s Salon talk is just the beginning,” Soulakis says. “Attendees and speakers can break into their own conversations and the idea is that the side conversation might prove more powerful than the scheduled talk on stage.”

And true to a salon’s Parisian roots in the 17th century, where discussion of political and social topics stood alongside artistic discourse and entertainment, Salon 2024 will embrace the arts-meets-science vibe to feed a creative mindset. The Salon’s mid-day spotlight session, for example, will feature a photojournalist’s efforts with user-generated content related to financial literacy and local musicians whose work describes the patchwork mosaic of economic realities Chicagoans face every day.

Salon leans heavily into Loyola’s strengths in areas like social justice, diversity, global health, and community engagement, the latter being a significant point of pride for Loyola, which was one of only 40 U.S. institutions in higher education to receive the Carnegie Community Engagement Classification earlier this year. In fact, Soulakis hopes Salon 2024 ignites collaborations between CHOIR, the Loyola community, and external partners to advance thoughtful action in communities near and far.

“We want to bring people together so that we can work on hard problems,” Soulakis says. “If six months down the road, we’re building upon conversations started at Salon and starting new projects, that’s an amazing win.”

REGISTER"
https://www.kdnuggets.com/5-free-sql-courses-for-data-science-beginners,5 Free SQL Courses for Data Science Beginners,"Image by Author

If you’re interested in pivoting to a data career, you probably know that using data effectively to answer business questions is at the core of most data professions—regardless of the tools you use. By building the right skill set, you can land a job as a data analyst and gradually explore other roles such as those of a data scientist, BI analyst and the like. So where should you start?

Should you learn a programming language like Python or R? Or should you dive right into learning a BI tool like Tableau? Or is it SQL?

Well, SQL is THAT tool you should know—and inarguably the most important skill—across multiple data professions from data analyst to data scientist and data engineer. That’s why we’ve put together this list of beginner-friendly courses to learn the basics of SQL in a few hours.

1. Intro to SQL: Querying and Managing Data

Intro to SQL: Querying and Managing Data is a course you can take for free on Khan Academy. You’ll learn how to query and manipulate data within relational database tables.

This course has several bite-sized lessons followed by challenges that test your understanding. The course is organized into sections as follows:

The SQL Basics section covers basics like creating tables and inserting data, querying data and aggregating.

The More Advanced SQL Queries section covers logical operators, the IN and LIKE operators and HAVING.

The section Relational Queries in SQL focuses on using the different types of joins to use data from multiple tables to answer questions.

The Modifying Databases with SQL section teaches you how to modify table schemas with SQL.

Link: Intro to SQL: Querying and Managing Data

2. SQL and Database for Beginners

If you prefer learning from instructor-led video tutorials, then the SQL Tutorial - Full Database Course for Beginners is a good introduction to SQL.

In about 4.5 hours, you’ll learn both the fundamentals of database design as well as querying databases with SQL. You’ll use MySQL, one of the most widely used relational database management systems (RDBMS).

First, you’ll explore database schema design and performing CRUD operations with SQL. You’ll then get to learn about aggregations, nested queries, joins, unions, functions, and triggers.

Link: SQL Tutorial - Full Database Course for Beginners

3. Intro to SQL

The Intro to SQL course on Kaggle is also a good option if you prefer text-based tutorials followed by exercises.

In this introductory SQL course, you’ll learn how to query datasets with SQL using the BigQuery Python client. The topics covered include:

SQL fundamentals

Filtering

Aggregations

Joins

Writing readable SQL queries

Link: Intro to SQL

4. SQL Tutorial – W3Schools

SQL Tutorial by W3Schools is another great beginner-friendly resource to learn the basics of SQL commands and functions. The tutorial is organized into multiple bite-sized lessons, each focusing on a specific command or function. So you’ll learn what the commands are, how they work, followed by examples.

You can solve the examples in the online editor—without having to install anything in your local environment. This tutorial covers the basics of SQL as well as the different logical operators, window functions, and much more. Further, this also covers modifying database tables, constraints, and more.

This tutorial is not only a learning resource but also a concise reference. So if you want to quickly look up the syntax and example usage of a particular function, this SQL tutorial is a reference you may probably want to bookmark.

Link: SQL Tutorial

5. SQLZoo

SQLZoo is another beginner-friendly platform to learn and practice SQL. From basic SELECT statements to advanced concepts like window functions, SQLZoo offers bite-sized lessons with quick practice exercises in each of them.

The topics covered include:

SELECT statement

Aggregate functions

Types of JOINs

Understanding NULLs

Window functions

You also have a set of assessment questions with slightly more difficult SQL questions. Which you can take to test yourself.

Link: SQLZoo

Wrapping Up

I hope you found this compilation of free SQL courses useful. These courses have been designed to get you up to speed with SQL fundamentals in a few hours.

If you’re looking for free learning resources with a more expansive curriculum, here are a couple of round-ups you may find helpful:

5 Free Courses to Master SQL for Data Science

5 Free University Courses to Learn Databases and SQL

These courses also require more effort from your end and will typically take a few weeks to work through. So keep learning and practicing!"
https://www.argusmedia.com/en/solutions/analytics-and-forecasting/data-science-and-machine-learning,Data science and machine learning,"Our data science capabilities are unique. By pairing the latest data science and machine learning techniques with access to our one of a kind datasets and our decades of market knowledge, we can reveal otherwise unknown insights.

Through the insights derived from our constant market interaction, we are able to customise our algorithms. Our system provides access to a rich universe of macroeconomic and financial drivers, selected for their relevance to energy and commodity markets.

The Argus Data Science Studio is used by physical and financial market participants around the world to manage risk and to inform trading and hedging decisions. Through forward curves and probabilistic forecasting data, our clients unearth unique solutions and greater insights, faster."
