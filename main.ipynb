{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb47eef6-ccba-4a6a-89e4-1cad58a1183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5de5405f-32ae-40b8-8e91-46a4b693b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('articles.csv')\n",
    "reddit = pd.read_csv('reddit_posts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39038914-8a5b-4f91-a486-f377fa631781",
   "metadata": {},
   "source": [
    "# Processing text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac9c67c3-ce57-4e49-b723-04e1f2aca123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weekly Entering &amp; Transitioning - Thread 15 Ap...</td>\n",
       "      <td>\\n\\nWelcome to this week's entering &amp; transit...</td>\n",
       "      <td>https://www.reddit.com//r/datascience/comments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job hunt update.</td>\n",
       "      <td>I made this [post](https://www.reddit.com/r/da...</td>\n",
       "      <td>https://www.reddit.com//r/datascience/comments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You know Gen AI != You know Deep Learning</td>\n",
       "      <td>Hi,\\n\\nI'm a student learning data science. \\n...</td>\n",
       "      <td>https://www.reddit.com//r/datascience/comments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What kind of language is R</td>\n",
       "      <td>I hate R, its syntax is not at all consistent,...</td>\n",
       "      <td>https://www.reddit.com//r/datascience/comments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learning OOP, stick with Python or learn using...</td>\n",
       "      <td>I’m starting a Master’s program in the fall an...</td>\n",
       "      <td>https://www.reddit.com//r/datascience/comments...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Weekly Entering & Transitioning - Thread 15 Ap...   \n",
       "1                                   Job hunt update.   \n",
       "2          You know Gen AI != You know Deep Learning   \n",
       "3                         What kind of language is R   \n",
       "4  Learning OOP, stick with Python or learn using...   \n",
       "\n",
       "                                                text  \\\n",
       "0   \\n\\nWelcome to this week's entering & transit...   \n",
       "1  I made this [post](https://www.reddit.com/r/da...   \n",
       "2  Hi,\\n\\nI'm a student learning data science. \\n...   \n",
       "3  I hate R, its syntax is not at all consistent,...   \n",
       "4  I’m starting a Master’s program in the fall an...   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.reddit.com//r/datascience/comments...  \n",
       "1  https://www.reddit.com//r/datascience/comments...  \n",
       "2  https://www.reddit.com//r/datascience/comments...  \n",
       "3  https://www.reddit.com//r/datascience/comments...  \n",
       "4  https://www.reddit.com//r/datascience/comments...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce3eefe7-92fa-4788-af91-63677cfca8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 170 entries, 0 to 169\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   170 non-null    object\n",
      " 1   text    167 non-null    object\n",
      " 2   link    170 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.1+ KB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "51a90cd6-a251-41fc-800a-ac360b875b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def text_processing(text):\n",
    "    \n",
    "    text = str(text).replace('\\n', ' ')\n",
    "    text = str(text).replace('e.g.', ' ')\n",
    "    \n",
    "    text = re.sub('http\\S+', '', text)\n",
    "    text = re.sub('-', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = ' '.join([word for word in text.split() if word not in (stop_words)])\n",
    "    text = ''.join([word for word in text if not word.isdigit()])\n",
    "    text = re.sub(r'\\bds\\b', 'data science', text)\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    stemmed_words = []\n",
    "    for word in text:\n",
    "        stemmed_words.append(stemmer.stem(word))\n",
    "\n",
    "    text = ' '.join(stemmed_words)\n",
    "\n",
    "    return text\n",
    "\n",
    "reddit['text'] = reddit['text'].apply(lambda x: text_processing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c8f056e6-d911-4502-ad01-8e4ad63343d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcom week enter transit thread thread question get start studi transit data scienc field topic includ learn resourc book tutori video tradit educ school degre elect altern educ onlin cours bootcamp job search question resum appli career prospect elementari question start next wait answer commun check faq resourc page wiki also search answer past weekli thread'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit['text'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
